<!-- livebook:{"persist_outputs":true} -->

# Chapter 5: Pretraining on unlabeled data

```elixir
Mix.install([
  {:nx, "~> 0.5"},
  {:exla, "~> 0.5"},
  {:axon, "~> 0.5"},
  {:tiktoken, "~> 0.3.2"},
  {:table_rex, "~> 3.1.1"},
  {:kino_vega_lite, "~> 0.1.11"}
])
```

## Introduction

This section covers:

* Pretraining the LLM.
* Implementing the training code.
* Evaluating the performance process.
* Saving and loading model weights.

In the context of LLMs and other deep learning models, weights refer to the trainable
parameters that the learning process adjusts. These weights are also known as
weight parameters or simply parameters.

```elixir
tokenizer = "gpt-3.5-turbo"
gpt_config_124m = [
  vocab_size: 50257,
  context_length: 1024,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0.1,
  qkv_bias: false
]
```

<!-- livebook:{"output":true} -->

```
[
  vocab_size: 50257,
  context_length: 1024,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0.1,
  qkv_bias: false
]
```

```elixir
defmodule Transformer.Layers do
  import Nx.Defn
  
  def attention(%Axon{} = input, opts \\ []) do
    #opts = Keyword.validate!(opts, [:name, :d_in, :d_out, :num_heads])
    head_dim = div(opts[:d_out], opts[:num_heads])
    w_query = Axon.param("w_query", fn _ -> {opts[:d_in], opts[:d_out]} end)
    w_key = Axon.param("w_key", fn _ -> {opts[:d_in], opts[:d_out]} end)
    w_value = Axon.param("w_value", fn _ -> {opts[:d_in], opts[:d_out]} end)
    out_proj = Axon.param("out_proj", fn _ -> {opts[:d_out], opts[:d_out]} end)

    Axon.layer(
      &attention_impl/6,
      [input, w_query, w_key, w_value, out_proj],
      name: opts[:name],
      op_name: :causal_attention,
      head_dim: head_dim,
      num_heads: opts[:num_heads]
    )
  end

  #defnp attention_impl(input, w_query, w_key, w_value, head_dim, num_heads, _opts \\ []) do
  defnp attention_impl(input, w_query, w_key, w_value, out_proj, opts \\ []) do
    {b, num_tokens, _d_in} = Nx.shape(input)
    keys = Nx.dot(input, w_key)
    queries = Nx.dot(input, w_query)
    values = Nx.dot(input, w_value)
    d_k = Nx.axis_size(keys, -1)

    keys_reshaped = 
      keys
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])
    
    queries_reshaped = 
      queries
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])
    
    values_reshaped = 
      values
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])

    attn_score =
      keys_reshaped
      |> Nx.transpose(axes: [0, 1, 3, 2])
      |> then(&Nx.dot(queries_reshaped, [3], [0, 1], &1, [2], [0, 1]))

    simple_mask =
      attn_score
      |> then(&Nx.broadcast(Nx.Constants.infinity(), &1))
      |> Nx.triu(k: 1)

    masked = Nx.multiply(simple_mask, -1) |> Nx.add(attn_score)

    attn_weights =
      masked
      |> Nx.divide(Nx.pow(d_k, 0.5))
      |> Axon.Activations.softmax(axis: -1)
    
    context_vec =
      attn_weights
      |> Nx.dot([3], [0, 1], values_reshaped, [2], [0, 1])
      |> Nx.transpose(axes: [0, 2, 1, 3])

    context_vec
    |> Nx.reshape({b, num_tokens, opts[:num_heads] * opts[:head_dim]})
    |> Nx.dot(out_proj)
  end

  def shortcut(x, layer_impl, opts \\ []) when is_function(layer_impl) do
    with {:arity, arity} <- Function.info(layer_impl, :arity),
          layer_output <- execute_layer(x, layer_impl, opts, arity),
          output <- shortcut_impl(x, layer_output, opts) do
      output
    end    
  end

  defp execute_layer(x, layer_impl, _opts, 1), do: layer_impl.(x)
  defp execute_layer(x, layer_impl, opts, _arity), do: layer_impl.(x, opts)
  defp shortcut_impl(x, layer_output, opts) do
    use_shortcut? = Keyword.get(opts, :use_shortcut, false)
    if use_shortcut?, 
      do: Axon.add(x, layer_output),
      else: layer_output
  end

  def normalization(%Axon{} = input, opts \\ []) do
    #opts = Keyword.validate!(opts, [:name, :eps, :emb_dim])
    eps = Keyword.get(opts, :eps, 1.00e-5)
    scale = Axon.param("scale", {opts[:emb_dim]}, initializer: &ones(&1, type: &2))
    shift = Axon.param("shift", {opts[:emb_dim]}, initializer: &zeros(&1, type: &2))

    Axon.layer(
      &normalization_impl/4,
      [input, scale, shift],
      name: opts[:name],
      op_name: :normalization,
      eps: eps
    )
  end

  defp ones(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(1)
  end

  defp zeros(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(0)
  end

  defnp normalization_impl(input, scale, shift, opts \\ []) do
    mean = Nx.mean(input, axes: [-1], keep_axes: true)
    variance = Nx.variance(input, axes: [-1], keep_axes: true)
    denominator = variance |> Nx.add(opts[:eps]) |> Nx.sqrt()

    input
    |> Nx.subtract(mean)
    |> Nx.divide(denominator)
    |> Nx.multiply(scale)
    |> Nx.add(shift)
  end

  def pos_embedding(%Axon{} = x, vocab_size, embedding_size, opts \\ []) do
    opts = Keyword.validate!(opts, [:name, kernel_initializer: :uniform])

    kernel_shape = &Axon.Shape.embedding_kernel(&1, vocab_size, embedding_size)

    kernel = Axon.param("kernel", kernel_shape, initializer: opts[:kernel_initializer])

    Axon.layer(&pos_embedding_impl/3, [x, kernel], name: opts[:name], op_name: :pos_embedding)
  end

  defnp pos_embedding_impl(x, kernel, _opts \\ []) do
    {_batch_size, sequence_size} = Nx.shape(x)
    input = Nx.iota({1, sequence_size})
    Nx.take(kernel, input, axis: 0)
  end

  def feedforward(input, emb_dim) do
    input
    |> Axon.dense(4*emb_dim)
    |> Axon.activation(:gelu)
    |> Axon.dense(emb_dim)
  end

  def feedforward_block(input, opts) do
    input
    |> normalization(opts)
    |> feedforward(opts[:emb_dim])
    |> Axon.dropout(rate: opts[:drop_rate])
  end

  def attention_block(input, opts) do
    input
    |> normalization(opts)
    |> attention(d_in: opts[:emb_dim], d_out: opts[:emb_dim], num_heads: opts[:n_heads] )
    |> Axon.dropout(rate: opts[:drop_rate])
  end

  def block(input, opts \\ []) do
    input
    |> shortcut(&attention_block(&1, opts), use_shortcut: true)
    |> shortcut(&feedforward_block(&1, opts), use_shortcut: true)
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, Transformer.Layers, <<70, 79, 82, 49, 0, 0, 51, ...>>, {:block, 2}}
```

```elixir
defmodule MyGPT do
  @gpt_config_124m gpt_config_124m
  def model(input_shape \\ {2, 4, 768}, opts \\ @gpt_config_124m) do
    Axon.input("sequence", shape: input_shape)
    |> embedding_block(opts)
    |> Axon.dropout(rate: opts[:drop_rate])
    |> transformer_blocks(12, opts)
    |> Transformer.Layers.normalization(opts)
    |> Axon.dense(opts[:vocab_size], use_bias: false)
  end

  def embedding_block(input, opts) do
    token_emb = Axon.embedding(input, opts[:vocab_size], opts[:emb_dim])
    pos_emb = Transformer.Layers.pos_embedding(input, opts[:context_length], opts[:emb_dim])

    Axon.add(token_emb, pos_emb)
  end

  def transformer_blocks(input, n_blocks, transformer_opts) do
    for _n_block <- 1..n_blocks, reduce: input do
      model_acc ->
        Transformer.Layers.block(model_acc, transformer_opts)
    end
  end

  def text_to_token_ids(tokenizer, texts) when is_list(texts) do
    token_ids_list = 
      for text <- texts do
        {:ok, token_ids} = text_to_token_ids(tokenizer, text)
        token_ids
      end
    Nx.stack(token_ids_list, axis: 1) |> Nx.squeeze()
  end

  def text_to_token_ids(tokenizer, text) do
    {:ok, tokens} = Tiktoken.encode(tokenizer, text)
    {:ok, Nx.tensor(tokens, type: :s64) |> Nx.new_axis(0)}
  end

  def token_ids_to_text(tokenizer, token_ids) do
    tokens_ids = Nx.to_flat_list(token_ids)
    Tiktoken.decode(tokenizer, tokens_ids)
  end

  def generate_tokens(predict_fn, model_params, input, max_new_token) when is_function(predict_fn) do
    generate_tokens_impl(predict_fn, model_params, input, max_new_token)
  end

  def generate_tokens_with_model(model, model_params, input, max_new_token) when model_params == %{} do
    {init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
    template = Nx.template(Nx.shape(input), :s64)
    init_model_params = init_fn.(template, model_params)
    generate_tokens_impl(predict_fn, init_model_params, input, max_new_token)
  end

  def generate_tokens_with_model(model, model_params, input, max_new_token) do
    {_init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
    generate_tokens_impl(predict_fn, model_params, input, max_new_token)
  end

  defp generate_tokens_impl(predict_fn, model_params, input, max_new_token) do
    for _new_token_index <- 1..max_new_token, reduce: input do
      input_acc ->
        logit = predict_fn.(model_params, input_acc)

        # Get last element of the vector.
        predicted_new_token =
          logit[[.., -1]]
          |> Axon.Layers.softmax(axis: -1)
          |> Nx.argmax(axis: -1)
          |> Nx.new_axis(0)

        Nx.concatenate([input_acc, predicted_new_token], axis: 1)
    end
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, MyGPT, <<70, 79, 82, 49, 0, 0, 25, ...>>, {:generate_tokens_impl, 4}}
```

## 5.1 Evaluating generative text models

```elixir
gpt_config_124m = [
  vocab_size: 50257,
  context_length: 256,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0,
  qkv_bias: false
]
```

<!-- livebook:{"output":true} -->

```
[
  vocab_size: 50257,
  context_length: 256,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0,
  qkv_bias: false
]
```

```elixir
model = MyGPT.model()
{init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
template = Nx.template({1, 4}, :s64)
params = init_fn.(template, %{})
```

<!-- livebook:{"output":true} -->

```
%{
  "pos_embedding_0" => %{
    "kernel" => #Nx.Tensor<
      f32[1024][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48358>
      [
        [-0.007802169304341078, -0.005925748031586409, 0.0029231260996311903, 0.008802282623946667, -0.0033047914039343596, -0.0028766130562871695, 0.004937546327710152, 0.0024654578883200884, 0.0024760651867836714, -7.982063107192516e-4, -0.003003764199092984, -2.7061699074693024e-4, 0.009432892315089703, -0.00763684744015336, 0.009704637341201305, -0.0015836501261219382, -0.004628846421837807, -0.008926344104111195, -0.009070269763469696, -0.004606935661286116, 0.004819416906684637, -0.0011076522059738636, 0.0047597335651516914, 0.007662024348974228, 0.0040115308947861195, -0.007707891520112753, -0.0042680311016738415, -0.008119473233819008, 0.0071457671001553535, -0.008498439565300941, -1.3729094644077122e-4, -0.00961955077946186, -0.009308225475251675, -4.4703244930133224e-4, 0.0011604928877204657, -0.005743157584220171, 0.003473002929240465, 0.007441236637532711, 4.610776886693202e-5, -7.46016507036984e-4, -0.005293312016874552, 0.004093134310096502, 0.0032777786254882812, -0.0016254710499197245, -0.009917018003761768, -0.00853837188333273, 0.00836600549519062, -0.009477117098867893, ...],
        ...
      ]
    >
  },
  "normalization_6" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48350>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48351>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_4" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48295>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48296>
      [
        [0.0143307289108634, 0.010580526664853096, 0.0104606868699193, -0.02559646964073181, 0.009863147512078285, -6.537181325256824e-4, -0.01680818572640419, 0.025526540353894234, 0.010642237029969692, 0.021169940009713173, 0.021915894001722336, -0.01774008199572563, -0.0027098413556814194, 0.01400348823517561, -0.009669222868978977, 0.025990208610892296, -0.02979547716677189, 0.03150387108325958, 0.034338586032390594, -0.014997386373579502, 0.03936626389622688, 0.021366983652114868, -0.01579568348824978, 0.022184185683727264, -0.0155216995626688, 0.034139957278966904, -0.022214513272047043, 9.72100009676069e-4, -0.02074851281940937, -0.0037692200858145952, 0.013103285804390907, 0.0037815659306943417, 0.010797446593642235, 0.018356431275606155, -0.03860890492796898, 0.03508230671286583, 0.007252383977174759, -0.030813049525022507, -0.007826033048331738, -0.011767907068133354, -0.024431586265563965, 0.020503368228673935, 0.012139017693698406, 0.00240386207588017, 0.029928058385849, ...],
        ...
      ]
    >
  },
  "normalization_5" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48348>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48349>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_20" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48284>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48285>
      [
        [-0.018812060356140137, -0.03924758359789848, 0.02155037224292755, -0.026325121521949768, -0.015148015692830086, 0.011906491592526436, 0.0024114579427987337, 0.002157811773940921, 0.0282367505133152, 0.008190358057618141, 0.023791363462805748, 0.026304226368665695, -0.012741467915475368, -0.039492398500442505, 0.0035190421622246504, -0.015423809178173542, 0.032296765595674515, 0.024016113951802254, 0.003701044712215662, 0.005321594420820475, 0.03559984266757965, -0.019799333065748215, 0.03694286569952965, -0.011885455809533596, -0.0024706993717700243, -0.028849303722381592, 0.015437888912856579, 0.007672114763408899, -0.0310528501868248, -0.0211213119328022, 0.030936602503061295, 0.0020093880593776703, -0.030064107850193977, -0.03464455530047417, 0.0014787799445912242, 0.031096089631319046, 0.03593894839286804, -0.002195019042119384, 0.02508695237338543, -9.386625606566668e-6, 0.020896343514323235, 0.015424072742462158, -0.03529473766684532, ...],
        ...
      ]
    >
  },
  "normalization_1" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48310>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48311>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_9" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48356>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48357>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_22" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48288>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48289>
      [
        [-0.004496391396969557, 0.030565746128559113, 0.03506261855363846, -0.004746579099446535, -0.014866896905004978, -0.026874661445617676, -0.03147212043404579, 0.038591280579566956, -0.014253619126975536, 0.027264000847935677, 0.010454269126057625, -0.01838478073477745, -0.0358288437128067, -0.014387387782335281, -0.030452540144324303, -0.006617533043026924, 0.01416156254708767, 0.03676412254571915, 0.009025023318827152, 7.997574284672737e-4, -0.01759558729827404, -0.03342297300696373, 0.011902108788490295, 0.03144102171063423, 0.028473827987909317, 0.03561338409781456, -0.013112644664943218, 0.022563712671399117, 0.011794332414865494, 0.024156121537089348, -0.003572864457964897, -0.010892283171415329, 0.025589175522327423, 0.01731342263519764, 0.025113821029663086, 0.030329864472150803, -0.024754680693149567, -0.02900947816669941, -0.017232542857527733, -0.01940448209643364, ...],
        ...
      ]
    >
  },
  "causal_attention_0" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48210>
      [
        [-0.05168329179286957, 0.010059177875518799, 0.019774675369262695, 0.00594368577003479, 0.01043325662612915, 0.055833518505096436, 0.04112796485424042, 0.007299691438674927, 0.03173026442527771, -0.046106889843940735, 0.05411553382873535, 0.025890931487083435, 0.036792635917663574, -0.040961578488349915, 0.05846737325191498, 0.019989922642707825, -0.043679505586624146, -0.06143490970134735, -0.018081754446029663, 0.04860818386077881, 0.047573015093803406, -0.04661116003990173, 0.025244921445846558, -0.002906784415245056, 0.060348063707351685, 0.015140429139137268, 0.03278784453868866, 0.0023211240768432617, 0.058901429176330566, -0.010960325598716736, 0.015119686722755432, 0.033309802412986755, -0.04846186935901642, -0.04813393950462341, -0.026864737272262573, -0.036068424582481384, 0.03180406987667084, 0.012295246124267578, 0.05005541443824768, -0.029574409127235413, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48211>
      [
        [0.011109888553619385, -0.050530821084976196, -0.06157231330871582, 0.016298651695251465, -6.612837314605713e-4, -0.033195242285728455, -0.024938255548477173, -0.04216407239437103, 0.01225888729095459, 0.05764468014240265, -0.03845098614692688, -0.042014122009277344, -0.007179871201515198, -0.03171195089817047, 0.014533981680870056, 0.043558672070503235, -0.02181778848171234, 0.04349507391452789, -0.009802952408790588, -0.006684616208076477, -0.026896372437477112, 0.023478150367736816, -0.02239614725112915, -0.023372679948806763, 0.009752750396728516, -0.02003273367881775, -0.007440552115440369, -0.0568956583738327, -0.035385921597480774, 0.04601798951625824, -6.69524073600769e-4, -0.02599245309829712, 0.01792687177658081, -0.024464741349220276, 0.060626208782196045, -0.038771435618400574, -0.06029154360294342, -0.03245207667350769, -0.05814908444881439, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48212>
      [
        [-0.025673598051071167, 0.034405142068862915, 0.030214637517929077, 0.006944432854652405, -0.005547434091567993, 0.054583460092544556, 0.028492391109466553, -0.04774905741214752, 0.03974701464176178, -0.00645524263381958, -0.005777835845947266, 0.016998842358589172, -0.009915247559547424, -0.04695869982242584, 0.015466183423995972, 0.045666858553886414, 0.05778352916240692, 0.05472971498966217, 0.039784014225006104, -0.058806777000427246, -0.004975989460945129, 0.03460472822189331, -0.023395150899887085, 0.003587767481803894, 0.03095446527004242, 0.009445279836654663, -0.05995866656303406, -0.05202735960483551, -0.01512010395526886, -0.008118480443954468, 0.05702352523803711, 0.024070948362350464, 0.0255698561668396, 0.057483360171318054, -0.05281904339790344, 0.011647909879684448, -0.047379255294799805, -0.02713349461555481, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48213>
      [
        [-0.05879880487918854, -0.014693856239318848, -0.014421403408050537, 0.004853248596191406, 0.004178658127784729, 0.036174505949020386, -0.015441149473190308, -0.020166262984275818, -0.010628163814544678, -0.003709167242050171, 0.007059141993522644, -0.05558307468891144, -0.046983301639556885, -0.016492918133735657, -0.013326868414878845, 0.042464256286621094, -0.03951188921928406, -0.0212947279214859, -0.037966400384902954, 0.009180694818496704, -0.03427682816982269, -0.04014366865158081, 0.010726675391197205, 0.045897841453552246, 0.02713976800441742, 0.030045494437217712, -0.007136672735214233, -0.057705894112586975, -0.014252141118049622, -0.047367408871650696, 0.057623639702796936, -0.05843654274940491, -0.008438929915428162, 0.016101300716400146, -0.008333966135978699, 0.05319003760814667, 0.02593192458152771, ...],
        ...
      ]
    >
  },
  "normalization_14" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48320>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48321>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_7" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48352>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48353>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_11" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48314>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48315>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_2" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48332>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48333>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_12" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48266>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48267>
      [
        [-0.013080610893666744, 0.010362730361521244, 0.023400375619530678, -0.01279867347329855, -0.012144681997597218, -0.017838679254055023, -0.037057776004076004, -0.022105351090431213, -0.0173113401979208, 0.010033491998910904, -0.03168774023652077, -0.021556932479143143, -0.024596700444817543, -0.020690996199846268, -0.010002344846725464, -0.03362084552645683, 0.03507685661315918, 0.02580883726477623, -0.021943913772702217, -0.03608079254627228, -0.011865146458148956, 0.008848167024552822, -3.7329740735003725e-5, -0.022490929812192917, 0.015613868832588196, -0.024812564253807068, -0.03495711088180542, -0.005081189330667257, -0.013344303704798222, -0.034468621015548706, -0.006470268592238426, -5.818388308398426e-4, -0.009341313503682613, -0.019173510372638702, ...],
        ...
      ]
    >
  },
  "dense_23" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48290>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48291>
      [
        [-0.020839542150497437, -0.026680879294872284, 0.03339849039912224, -0.017854416742920876, 0.018775390461087227, -0.020582551136612892, -0.03399556875228882, 0.004748265724629164, 0.03763587400317192, -0.027464793995022774, -0.023426679894328117, -0.02289319783449173, 0.0016577194910496473, -0.02716611884534359, -0.03306937217712402, -0.008527673780918121, 0.036414600908756256, -0.035645898431539536, -0.02243957668542862, -0.014041288755834103, -0.010277035646140575, -0.034429002553224564, -0.001578121678903699, 0.029834531247615814, 3.933240950573236e-4, 0.020401274785399437, 0.035564471036195755, 0.03374066948890686, -0.015404338017106056, 0.02721782959997654, 0.022114483639597893, 0.010404848493635654, 0.03568222001194954, ...],
        ...
      ]
    >
  },
  "embedding_0" => %{
    "kernel" => #Nx.Tensor<
      f32[50257][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48307>
      [
        [-0.009233672171831131, 2.701234770938754e-4, -9.955167479347438e-5, -0.003290309803560376, -0.0016442585038021207, 0.0014625906478613615, 0.00714142294600606, 0.004707043059170246, 0.004617862403392792, 0.0038680124562233686, -0.0028466605581343174, -0.001904711709357798, 0.003502461826428771, 0.0056878686882555485, 0.0072561907581985, -0.0011320828925818205, 0.0038784693460911512, 0.0027695440221577883, 0.0014714241260662675, 0.006201310083270073, 0.00828084722161293, -0.007973573170602322, -0.0083962082862854, 0.004439790267497301, 0.007286577019840479, -0.0023415207397192717, -3.256320997024886e-5, -0.00713191507384181, 0.0074021886102855206, 7.072305306792259e-4, 0.0025892327539622784, 0.0019160102820023894, -0.006413790863007307, ...],
        ...
      ]
    >
  },
  "normalization_19" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48330>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48331>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_6" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48242>
      [
        [0.026115387678146362, -0.062431469559669495, 0.007059052586555481, 0.025247514247894287, 0.025371208786964417, 0.03977841138839722, 0.03136608004570007, 0.030012711882591248, 0.03549790382385254, 0.007612764835357666, -0.00434720516204834, -0.0013636201620101929, 0.037442803382873535, -0.02996039390563965, -0.04562897980213165, -0.021656721830368042, -0.0073239803314208984, -0.03087802231311798, 0.03897020220756531, 0.001008749008178711, -0.028378158807754517, -0.03222179412841797, 0.013578414916992188, 1.436471939086914e-4, 0.0036016255617141724, 0.04744879901409149, 0.026923999190330505, 0.010571300983428955, 0.029101714491844177, -0.043797001242637634, -0.007994472980499268, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48243>
      [
        [0.05103318393230438, -0.04400874674320221, -0.022491827607154846, 0.031131982803344727, 0.015176668763160706, -0.03974750638008118, 0.029064536094665527, 0.04666516184806824, -0.04683242738246918, -0.005637526512145996, 0.02794407308101654, 0.0326671302318573, -0.034318387508392334, 0.05253021419048309, 0.049837708473205566, -0.010492220520973206, -0.0028796792030334473, 0.04162617027759552, 0.05385619401931763, 0.0335671603679657, 0.013555794954299927, 0.026811853051185608, -0.026253893971443176, -0.025728359818458557, 0.028488710522651672, -0.059259116649627686, 0.05619722604751587, -0.03594955801963806, -0.01245899498462677, -0.032883912324905396, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48244>
      [
        [-0.04231342673301697, -0.015791326761245728, 0.06014569103717804, -0.01253509521484375, -0.03669476509094238, 0.03343106806278229, 0.044196486473083496, 0.038254350423812866, -0.0188169926404953, 0.013049855828285217, -0.06096439063549042, -0.012609541416168213, 0.03058318793773651, -0.014779359102249146, -0.04854334890842438, -0.04684346914291382, 0.0020504146814346313, -0.021867841482162476, -0.017359256744384766, -0.008014917373657227, -0.0509466677904129, -0.03069475293159485, -0.04132099449634552, -0.05023378133773804, -0.06192082166671753, 0.002379700541496277, 0.02478910982608795, 0.006460204720497131, -0.05743385851383209, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48245>
      [
        [-0.021699845790863037, 0.04605276882648468, 0.05886639654636383, 0.017819076776504517, -0.0026299208402633667, -0.014753371477127075, 0.034597501158714294, 0.055889204144477844, -0.015686243772506714, 0.01640315353870392, -0.048541247844696045, -0.0178794264793396, -0.03390926122665405, 0.02851836383342743, -0.036170780658721924, -0.026439517736434937, -0.025835096836090088, 0.03521448373794556, -0.024391263723373413, -0.03239910304546356, 0.017331525683403015, 0.041145771741867065, 0.026065096259117126, 0.04956373572349548, -0.03212665021419525, 0.04107430577278137, -0.05436892807483673, 0.027760371565818787, ...],
        ...
      ]
    >
  },
  "causal_attention_7" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48246>
      [
        [-0.022313207387924194, 0.03597383201122284, -0.056498587131500244, -0.026568308472633362, 0.06116384267807007, -0.019824877381324768, 0.019029751420021057, -0.021577909588813782, 0.04641753435134888, 0.01522316038608551, 0.007169544696807861, 9.9945068359375e-4, 0.05751509964466095, 0.050010234117507935, -0.026949673891067505, 0.018063142895698547, -0.039811089634895325, 0.01826472580432892, 0.0573771595954895, -0.008172422647476196, 0.05520936846733093, 0.05166591703891754, -0.039644449949264526, 0.00193747878074646, 0.061643391847610474, -0.06119611859321594, -0.05526109039783478, 0.013777956366539001, -0.002461180090904236, -0.05016873776912689, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48247>
      [
        [-0.01170419156551361, 0.04986801743507385, -0.012306585907936096, 0.055284738540649414, -0.023441433906555176, -0.05351841449737549, 0.012148737907409668, -0.046659886837005615, 0.03499172627925873, 0.03688977658748627, 0.04679524898529053, 0.04153142869472504, 0.04633857309818268, 0.04209192097187042, -0.06225171685218811, 0.05813795328140259, 0.02562721073627472, -0.04751616716384888, 0.0014916211366653442, 0.0605095773935318, -0.01629692316055298, -0.060174837708473206, -0.05907650291919708, -0.06171265244483948, 0.05325661599636078, 0.016080185770988464, 0.04007597267627716, -0.01883760094642639, -0.04208442568778992, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48248>
      [
        [-0.04748232662677765, 0.0383162647485733, 0.04062032699584961, -0.0059366971254348755, 0.04349586367607117, -0.04269242286682129, 0.0048902034759521484, -0.02832561731338501, -0.01224711537361145, 0.01649506390094757, -0.017946675419807434, -0.03979519009590149, -0.05212780833244324, -0.016109168529510498, -0.05625757575035095, 0.01382535696029663, 0.011292323470115662, -0.036108970642089844, -0.045045435428619385, -0.014424383640289307, -0.013747140765190125, -0.021949738264083862, 0.051565393805503845, 0.01813843846321106, -0.011133506894111633, -0.02475123107433319, 0.06247544288635254, 0.01960568130016327, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48249>
      [
        [0.05345436930656433, -0.061884403228759766, -0.006642952561378479, -0.04398755729198456, -0.053075000643730164, 0.02928459644317627, 0.04951377213001251, -0.0597088485956192, 0.03557467460632324, 0.056165486574172974, 0.04880759119987488, 0.015218526124954224, -0.03789214789867401, 0.0578588992357254, -0.038778647780418396, 0.03154279291629791, 0.013613030314445496, -0.010974004864692688, -0.04521055519580841, -0.03599075973033905, -0.05323311686515808, 0.03578318655490875, 0.042868390679359436, -0.047821447253227234, -0.06178624927997589, 5.468577146530151e-4, 0.019813403487205505, ...],
        ...
      ]
    >
  },
  "causal_attention_1" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48214>
      [
        [0.031186625361442566, -0.041564762592315674, -0.0054755061864852905, 0.031153321266174316, 0.06112530827522278, -0.0011445581912994385, 0.021112486720085144, 0.006158500909805298, -0.011338204145431519, -0.04585514962673187, -0.030230611562728882, -0.04087269306182861, 0.04129500687122345, -0.027099907398223877, 0.051862433552742004, -0.030702412128448486, -0.0538879930973053, 0.03468000888824463, 0.020081564784049988, 0.016770437359809875, 0.03683991730213165, 0.011441051959991455, 0.05327916145324707, -0.016935542225837708, 0.030221596360206604, 0.020736947655677795, 0.039309799671173096, -0.019636452198028564, 0.017957478761672974, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48215>
      [
        [0.018918201327323914, 2.0869076251983643e-4, 0.008455097675323486, -0.03417833149433136, -0.029236868023872375, -0.013562113046646118, -0.0613894909620285, -0.0443921834230423, 0.043029412627220154, -0.05056668817996979, -0.03315797448158264, -0.004519715905189514, -0.06198309361934662, -0.061979830265045166, 0.055343568325042725, 0.06161864101886749, 0.00840042531490326, 0.02474839985370636, 0.020267054438591003, 0.022432729601860046, -0.03555011749267578, 0.02040150761604309, -0.049514397978782654, -0.02020817995071411, 0.042250856757164, -0.02343146502971649, 0.0029643476009368896, -0.004491284489631653, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48216>
      [
        [0.009435310959815979, 0.011291012167930603, -0.025670126080513, -0.04794791340827942, 0.05513794720172882, 0.004967987537384033, 0.015606552362442017, 0.01646701991558075, -0.042143091559410095, -0.029665246605873108, 0.011877626180648804, -0.036619558930397034, -0.037188783288002014, 0.05479446053504944, 0.056472763419151306, -0.034100890159606934, 0.015600025653839111, 0.026484668254852295, 0.028480812907218933, -0.047336146235466, -0.016757473349571228, 0.002289220690727234, -0.0030492693185806274, -0.055996835231781006, -0.003762662410736084, 0.04287724196910858, -0.027283743023872375, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48217>
      [
        [0.03189055621623993, -0.03050108253955841, 0.02169017493724823, -0.001004830002784729, -0.019276708364486694, 0.025574922561645508, 0.05513383448123932, -0.03241130709648132, 0.05890975892543793, -0.013686299324035645, -0.023119866847991943, -0.0043182820081710815, 0.03188617527484894, -0.004135295748710632, -0.05686536431312561, 0.06176477670669556, 0.05795496702194214, 0.035450518131256104, 0.02700813114643097, 0.036256298422813416, 0.06145629286766052, 7.927417755126953e-6, -0.039068013429641724, -0.03144541382789612, 0.025397121906280518, 0.03764919936656952, ...],
        ...
      ]
    >
  },
  "dense_15" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48272>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48273>
      [
        [-0.027422582730650902, -0.03254063054919243, -0.026317883282899857, 0.03700612112879753, 0.03715880215167999, 0.004745193757116795, 0.016256852075457573, -0.01610984280705452, 0.03029325045645237, 0.012680275365710258, 0.03603992983698845, -0.009490255266427994, -0.026665102690458298, -0.006015130318701267, 0.03579896688461304, 0.010328482836484909, 0.019228793680667877, -0.03297141566872597, -0.0027467000763863325, -0.01644737459719181, 0.007214347366243601, 0.037710051983594894, -0.02692943625152111, 0.02370133250951767, -0.004068357404321432, 0.017146838828921318, 0.002383778803050518, ...],
        ...
      ]
    >
  },
  "dense_9" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48305>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48306>
      [
        [-0.0016488040564581752, 0.0196771752089262, 0.020105227828025818, -0.024142956361174583, -0.028604043647646904, -0.007251780480146408, -0.021407198160886765, 0.011198781430721283, 0.004257795866578817, -0.022603560239076614, -0.02750295400619507, -2.235355059383437e-4, 0.00328151136636734, 0.03356964513659477, 0.02328065037727356, 0.02328999899327755, -0.024555345997214317, -0.005628233775496483, 0.028924575075507164, 0.002953526098281145, -0.017909709364175797, 0.013182554394006729, -0.03914628177881241, -0.038084980100393295, -0.02785731852054596, 0.030823839828372, ...],
        ...
      ]
    >
  },
  "normalization_8" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48354>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48355>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_10" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48218>
      [
        [0.03435508906841278, -0.045475468039512634, -0.057347118854522705, 0.050174832344055176, -0.027708128094673157, 0.019674867391586304, -0.027895107865333557, -0.04580971598625183, -0.0596996545791626, -0.03660862147808075, 0.0392034649848938, 0.04565897583961487, 0.03990358114242554, -0.04003746807575226, -0.01529395580291748, 0.035237789154052734, -0.036279499530792236, -0.019215047359466553, -0.057615041732788086, 0.044489115476608276, -0.04212196171283722, 0.004485815763473511, 0.019323214888572693, -0.0500207394361496, -0.012979969382286072, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48219>
      [
        [2.1107494831085205e-4, 0.024232223629951477, -0.0023142844438552856, 0.024566516280174255, 0.004591256380081177, 0.020652562379837036, -0.010007217526435852, 0.05224484205245972, 0.053776130080223083, 0.02273106575012207, 0.009758025407791138, 0.014426201581954956, 0.05054831504821777, 0.053338319063186646, -0.03229723870754242, -0.015222817659378052, -0.02901218831539154, -0.04374814033508301, -0.060532525181770325, 0.018568366765975952, 0.02660273015499115, -0.009944885969161987, -0.03716352581977844, 0.0065151602029800415, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48220>
      [
        [-0.006918385624885559, 0.03817842900753021, 0.022818490862846375, 0.006789341568946838, 0.008181795477867126, -0.030902594327926636, 0.045423224568367004, -0.05237530171871185, -0.002263873815536499, 0.039539799094200134, -0.06002795696258545, -0.04546022415161133, -0.021745845675468445, -6.696432828903198e-4, 0.045621320605278015, -0.05660414695739746, -0.017272353172302246, -0.010488852858543396, -0.05700196325778961, -0.046275392174720764, 0.03322720527648926, -0.045595526695251465, -0.018080607056617737, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48221>
      [
        [0.015805184841156006, 0.030856862664222717, -0.057419925928115845, -0.02980661392211914, 0.05120733380317688, -0.04059262573719025, -0.026228442788124084, -0.04172526299953461, -0.034627899527549744, -0.044921696186065674, -0.019021987915039062, -0.01264183223247528, 0.06190921366214752, -0.025908425450325012, 0.03216943144798279, -0.007690638303756714, 0.053304120898246765, -0.05624043941497803, -0.03258061408996582, 0.05379179120063782, 0.014663085341453552, -0.029300779104232788, ...],
        ...
      ]
    >
  },
  "causal_attention_8" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48250>
      [
        [-0.06167149543762207, -5.9857964515686035e-5, -0.044524699449539185, 0.049650222063064575, 0.008422508835792542, 0.039262861013412476, -0.05940528213977814, 0.010881364345550537, 0.013115182518959045, 0.040625423192977905, 0.01980842649936676, 0.02735680341720581, -8.444339036941528e-4, 0.018677949905395508, 0.04540391266345978, 0.05588521063327789, 0.06199990212917328, 0.02912713587284088, 0.002449214458465576, -0.009149312973022461, 0.036151424050331116, -0.04245014488697052, 0.06086994707584381, 0.049970149993896484, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48251>
      [
        [-0.02915187180042267, -0.03253704309463501, 0.0592157244682312, -0.032063111662864685, -0.02380712330341339, 0.03842546045780182, 0.03796142339706421, 0.0054466575384140015, 0.05183681845664978, -0.02952311933040619, 0.06074407696723938, 0.031840890645980835, -0.033060431480407715, 0.05262918770313263, 0.002438664436340332, 0.011166408658027649, 0.028813928365707397, -0.058970868587493896, -0.041010260581970215, 0.039035484194755554, -0.005820900201797485, 0.02388109266757965, -0.002785712480545044, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48252>
      [
        [0.04918965697288513, -0.04960779845714569, 0.03322528302669525, -0.05750422179698944, -0.051704615354537964, 0.0358271449804306, -0.02959299087524414, 0.006245717406272888, -0.022167235612869263, -0.04897983372211456, 0.023015126585960388, 0.061299100518226624, -0.03877703845500946, -0.060830920934677124, -0.02221125364303589, -0.00465257465839386, 0.05202469229698181, -0.044652342796325684, -0.049580782651901245, 0.05392199754714966, -0.04099567234516144, 0.0023981183767318726, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48253>
      [
        [-0.03350187838077545, 0.04625767469406128, 0.03218376636505127, -0.041653022170066833, 0.03958559036254883, 0.01528097689151764, 0.05063734948635101, -0.01555044949054718, -0.030909672379493713, -0.006847962737083435, -0.0056197792291641235, 0.017392292618751526, 0.04601135849952698, 0.04092732071876526, -0.058930426836013794, -0.03280340135097504, -0.05146346986293793, -0.06091766059398651, 0.0216350257396698, 0.008228063583374023, -0.017123639583587646, ...],
        ...
      ]
    >
  },
  "normalization_12" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48316>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48317>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_3" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48293>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48294>
      [
        [0.013521942310035229, 0.023809758946299553, 0.028659431263804436, 0.015801988542079926, 0.025014659389853477, 0.024148525670170784, 0.013223747722804546, -0.021664557978510857, 0.03903472423553467, -0.031480252742767334, -0.0026576684322208166, 0.020373858511447906, 0.00571583304554224, -0.017286837100982666, -0.010058862157166004, 0.011919666081666946, 0.006950852461159229, -0.035795848816633224, -0.0014983353903517127, 0.03426104038953781, -0.020756995305418968, ...],
        ...
      ]
    >
  },
  "dense_18" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48278>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48279>
      [
        [-0.03540608659386635, -0.004268237855285406, -4.916292382404208e-4, -0.029093382880091667, -0.005408317316323519, 0.018060432747006416, -0.030845968052744865, 0.02399810403585434, -0.017279675230383873, 0.013004858046770096, 0.03260364383459091, -0.019856294617056847, -0.021998245269060135, -0.0325106605887413, 0.03155849501490593, -0.039057862013578415, -0.0314631387591362, -0.027912309393286705, -0.02735348418354988, 0.03621766343712807, ...],
        ...
      ]
    >
  },
  "dense_5" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48297>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48298>
      [
        [0.03456203639507294, 0.0020828412380069494, -0.0015930309891700745, 0.032944172620773315, 0.03545960783958435, 0.012734531424939632, 0.02969660609960556, -0.03233125060796738, 0.0018821597332134843, -0.006619106978178024, -0.031686022877693176, 0.02410890720784664, -0.007769929710775614, 0.027593493461608887, -0.02576638013124466, -0.03105168230831623, 0.013754591345787048, 0.005891803652048111, 0.008551451377570629, ...],
        ...
      ]
    >
  },
  "dense_11" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48264>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48265>
      [
        [0.016712961718440056, 0.02353096939623356, -0.004528415389358997, 0.015683826059103012, -0.03524163365364075, 0.014222207479178905, 0.0022580111399292946, -0.03126528486609459, -0.03555884584784508, 0.02368653565645218, -0.014401835389435291, 0.01845245622098446, 0.017625311389565468, 0.00875104870647192, 0.029845425859093666, -0.03625665232539177, 0.02988857962191105, 0.0067049250937998295, ...],
        ...
      ]
    >
  },
  "normalization_18" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48328>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48329>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_6" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48299>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48300>
      [
        [-0.018401047214865685, -0.021326931193470955, 0.036095380783081055, 0.0035970848985016346, 0.018928280100226402, 0.007233478594571352, -0.03569026663899422, 0.026783529669046402, -0.035831037908792496, -0.0039030644111335278, 0.008015320636332035, 0.021867793053388596, 0.015069954097270966, -0.020455671474337578, 0.03381155803799629, 0.037314992398023605, ...],
        ...
      ]
    >
  },
  "normalization_15" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48322>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48323>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_23" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48340>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48341>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_10" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48262>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48263>
      [
        [0.014445922337472439, -0.007776997983455658, -0.018882308155298233, -1.1739878391381353e-4, 0.03130829706788063, -0.03198053315281868, 0.0369340255856514, 0.005838989745825529, 0.028342878445982933, 0.02452733740210533, 0.0027868947945535183, 0.013925963081419468, -0.014545499347150326, ...],
        ...
      ]
    >
  },
  "dense_13" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48268>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48269>
      [
        [-0.022168032824993134, -0.022905562072992325, 0.02072705328464508, -0.034930046647787094, -0.008836357854306698, -0.036431510001420975, -0.019643576815724373, -0.006480107549577951, 0.024773556739091873, -0.009336459450423717, 0.0139111103489995, -0.01944747567176819, ...],
        ...
      ]
    >
  },
  "dense_21" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48286>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48287>
      [
        [0.002374759642407298, 0.027441421523690224, 0.01369320135563612, -0.026752684265375137, 0.03344820439815521, -0.026635199785232544, 0.012835334055125713, 0.002115996088832617, -0.037206925451755524, 0.028106987476348877, 0.033937305212020874, ...],
        ...
      ]
    >
  },
  "dense_8" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48303>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48304>
      [
        [0.022212186828255653, -0.020968684926629066, -0.011825602501630783, 0.02030869945883751, 0.015789218246936798, -0.03517530485987663, -0.023946233093738556, -0.03478687256574631, 0.015022709965705872, 0.001400793669745326, ...],
        ...
      ]
    >
  },
  "dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48258>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48259>
      [
        [0.01964486949145794, 0.0027669246774166822, -0.03209010139107704, 0.005356002599000931, -0.019535640254616737, -0.020455246791243553, -0.014536697417497635, -0.014182060025632381, -0.03824502229690552, ...],
        ...
      ]
    >
  },
  "dense_2" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48282>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48283>
      [
        [0.016505984589457512, -0.01261783018708229, 0.037803106009960175, 0.018692022189497948, 0.037927620112895966, -0.019871769472956657, 0.028127163648605347, -0.010651642456650734, ...],
        ...
      ]
    >
  },
  "causal_attention_3" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48230>
      [
        [-0.013939529657363892, 0.06082350015640259, -0.045787692070007324, 0.04676558077335358, 0.036864206194877625, -0.0247325599193573, 0.033958688378334045, 0.04714769124984741, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48231>
      [
        [-0.038647204637527466, -0.030064880847930908, 0.00644373893737793, 0.038542091846466064, 0.022690579295158386, -0.06145331263542175, -0.028634950518608093, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48232>
      [
        [-0.04419335722923279, -0.05638234317302704, -0.01100565493106842, -0.03666827082633972, -0.06030870974063873, -0.051022499799728394, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48233>
      [
        [-0.004164531826972961, -0.04003196954727173, -0.012327104806900024, -0.012349948287010193, 0.03490932285785675, ...],
        ...
      ]
    >
  },
  "normalization_21" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48336>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48337>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_5" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48238>
      [
        [-0.0601714551448822, -7.512122392654419e-4, 0.010596036911010742, 0.04309704899787903, 0.004145115613937378, 0.02065950632095337, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48239>
      [
        [-0.0171688050031662, 0.04019123315811157, -0.042904287576675415, 0.003659859299659729, -0.023451879620552063, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48240>
      [
        [-0.024169564247131348, 0.044654399156570435, -0.006017208099365234, 0.005254611372947693, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48241>
      [
        [-0.02115751802921295, 0.05745324492454529, 0.018603786826133728, ...],
        ...
      ]
    >
  },
  "dense_24" => %{
    "kernel" => #Nx.Tensor<
      f32[768][50257]
      EXLA.Backend<host:0, 0.80407116.422182936.48292>
      [
        [0.008929653093218803, -0.005332522559911013, -4.522862218436785e-5, -0.004508986137807369, -0.007431369740515947, ...],
        ...
      ]
    >
  },
  "dense_14" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48270>
      [0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.80407116.422182936.48271>
      [
        [0.004612659104168415, 0.03564397618174553, -0.023996813222765923, ...],
        ...
      ]
    >
  },
  "causal_attention_4" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48234>
      [
        [0.009016022086143494, -0.05768324434757233, -0.0022973865270614624, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48235>
      [
        [0.016868695616722107, -0.06027361750602722, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48236>
      [
        [-0.015798315405845642, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48237>
      [
        ...
      ]
    >
  },
  "normalization_10" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48312>
      [1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48313>
      [0.0, ...]
    >
  },
  "dense_7" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48301>
      [0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.80407116.422182936.48302>
      [
        ...
      ]
    >
  },
  "normalization_22" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.80407116.422182936.48338>
      [...]
    >,
    ...
  },
  "causal_attention_2" => %{...},
  ...
}
```

**5.1.1 Using GPT to generate text**

Generating text involves encoding text into token IDs that the LLM processes into logit vectors. The
logit vectors are then converted back into token IDs, detokenized into a text representation.

```elixir
{:ok, input} = MyGPT.text_to_token_ids(tokenizer, "I know everything")
```

<!-- livebook:{"output":true} -->

```
{:ok,
 #Nx.Tensor<
   s64[1][3]
   [
     [40, 1440, 4395]
   ]
 >}
```

```elixir
# Nx data accessing example..
example = Nx.iota({2,3,4}) |> IO.inspect()
example[0][0][..]
example[[0,..,0]]
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3][4]
  [
    [
      [0, 1, 2, 3],
      [4, 5, 6, 7],
      [8, 9, 10, 11]
    ],
    [
      [12, 13, 14, 15],
      [16, 17, 18, 19],
      [20, 21, 22, 23]
    ]
  ]
>
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[3]
  [0, 4, 8]
>
```

```elixir
token_ids = MyGPT.generate_tokens(predict_fn, params, input, 6)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[1][9]
  EXLA.Backend<host:0, 0.80407116.422182936.48457>
  [
    [40, 1440, 4395, 16711, 4680, 4680, 4680, 16711, 16711]
  ]
>
```

```elixir
{:ok, text} = MyGPT.token_ids_to_text(tokenizer, token_ids)
IO.puts(text)
```

<!-- livebook:{"output":true} -->

```
I know everythingunogygygyunouno
```

<!-- livebook:{"output":true} -->

```
:ok
```

**5.1.2 Calculating the text generation loss**

```elixir
texts = ["every effort moves", "I really like"]
inputs = MyGPT.text_to_token_ids(tokenizer, texts)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3]
  [
    [30115, 5149, 11031],
    [40, 2216, 1093]
  ]
>
```

```elixir
texts = [" effort moves you", " really like chocolate"]
targets = MyGPT.text_to_token_ids(tokenizer, texts)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3]
  [
    [5149, 11031, 499],
    [2216, 1093, 18414]
  ]
>
```

```elixir
# Predict next token
logits = predict_fn.(params, inputs)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][3][50257]
  EXLA.Backend<host:0, 0.80407116.422182936.48459>
  [
    [
      [0.01167576014995575, -0.034008853137493134, -0.334558367729187, -0.2146407663822174, 0.03478096425533295, 0.1686250865459442, 0.13836795091629028, 0.21438083052635193, -0.15167038142681122, 0.1367613822221756, -0.01024571806192398, -0.11574561148881912, -0.10123006999492645, 0.2418353408575058, 0.04462456703186035, -0.22372260689735413, -0.04136794060468674, -0.11844000965356827, -0.0979822427034378, 0.12649178504943848, 0.1110108494758606, 0.08768841624259949, -0.041244760155677795, 0.047213830053806305, -0.2530650496482849, -0.2698386609554291, -0.06300882995128632, 0.2564893960952759, 0.3095315098762512, -0.0640779435634613, 0.005592864006757736, -0.029598519206047058, -0.1326846033334732, -0.05887247622013092, -0.2516477406024933, 0.10970117151737213, -0.07099281251430511, -0.06018777936697006, -0.04295181855559349, -0.17571185529232025, -0.06300459057092667, -0.08543603867292404, 0.17373892664909363, 0.35789188742637634, -0.21594178676605225, -0.12878556549549103, -0.191578209400177, 0.1957072764635086, 0.06131259351968765, 0.11764466762542725, ...],
      ...
    ],
    ...
  ]
>
```

```elixir
predicted_new_token =
  logits
  |> Axon.Layers.softmax(axis: -1)
  |> Nx.argmax(axis: -1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3]
  EXLA.Backend<host:0, 0.80407116.422182936.48473>
  [
    [8300, 31580, 44978],
    [16711, 16711, 32792]
  ]
>
```

```elixir
{:ok, targets_text} = MyGPT.token_ids_to_text(tokenizer, targets[0])
{:ok, outputs_text} = MyGPT.token_ids_to_text(tokenizer, predicted_new_token[0])

IO.puts("Targets batch 1: #{targets_text}")
IO.puts("Outputs batch 1: #{outputs_text}")
```

<!-- livebook:{"output":true} -->

```
Targets batch 1:  effort moves you
Outputs batch 1: DrawJsENTS
```

<!-- livebook:{"output":true} -->

```
:ok
```

Before training, the model produces random next-token probability vectors. The goal of model training is to ensure that the probability values corresponding to the highlighted target token IDs are maximized.

```elixir
probas = Axon.Layers.softmax(logits, axis: -1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][3][50257]
  EXLA.Backend<host:0, 0.80407116.422182936.48483>
  [
    [
      [1.982103640330024e-5, 1.893589251267258e-5, 1.4020347407495137e-5, 1.580659591127187e-5, 2.028433846135158e-5, 2.3189351850305684e-5, 2.2498215912492014e-5, 2.4275044779642485e-5, 1.683395021245815e-5, 2.246209987788461e-5, 1.9391256500966847e-5, 1.7449699953431264e-5, 1.770483868313022e-5, 2.4950739316409454e-5, 2.048499482043553e-5, 1.56636924657505e-5, 1.8797052689478733e-5, 1.7402746379957534e-5, 1.7762435163604096e-5, 2.223260344180744e-5, 2.189107362937648e-5, 2.1386427761171944e-5, 1.8799368262989447e-5, 2.053810385405086e-5, 1.5210759556794073e-5, 1.4957747225707863e-5, 1.8394637663732283e-5, 2.531905920477584e-5, 2.669828973012045e-5, 1.8374981664237566e-5, 1.970083212654572e-5, 1.901959149108734e-5, 1.7156609828816727e-5, 1.847088242357131e-5, 1.5232333680614829e-5, 2.186241908930242e-5, 1.8248359992867336e-5, 1.8446604372002184e-5, 1.876730311778374e-5, 1.6434063581982628e-5, 1.8394715880276635e-5, 1.7986689272220246e-5, 2.330824099772144e-5, 2.8021160687785596e-5, 1.578604496899061e-5, 1.722363413136918e-5, 1.6175372365978546e-5, 2.3825949028832838e-5, 2.0829715140280314e-5, 2.2036776499589905e-5, ...],
      ...
    ],
    ...
  ]
>
```

```elixir
t = Nx.iota({3, 1000}, type: :s64)
Nx.take_along_axis(t, Nx.tensor([[0], [0], [0]]), axis: 1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[3][1]
  [
    [0],
    [1000],
    [2000]
  ]
>
```

```elixir
text_index = 0
target_1 = Nx.reshape(targets[text_index], {3,1}) |> IO.inspect()
target_probas_1 = Nx.take_along_axis(probas[text_index], target_1, axis: 1) |> Nx.reshape({3})

text_index = 1
target_2 = Nx.reshape(targets[text_index], {3,1}) |> IO.inspect()
target_probas_2 = Nx.take_along_axis(probas[text_index], target_2, axis: 1) |> Nx.reshape({3})

IO.puts("Text 1: #{inspect(Nx.to_flat_list(target_probas_1))}")
IO.puts("Text 2: #{inspect(Nx.to_flat_list(target_probas_2))}")
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[3][1]
  [
    [5149],
    [11031],
    [499]
  ]
>
#Nx.Tensor<
  s64[3][1]
  [
    [2216],
    [1093],
    [18414]
  ]
>
Text 1: [2.3870217773946933e-5, 1.8255625036545098e-5, 1.4669954907731153e-5]
Text 2: [1.8440296116750687e-5, 2.0773528376594186e-5, 1.9396786228753626e-5]
```

<!-- livebook:{"output":true} -->

```
:ok
```

The goal of training an LLM is to maximize the likelihood of the correct token, which
involves increasing its probability relative to other tokens. This way, we ensure the
LLM consistently picks the target token essentially the next word in the sentence as the next token it generates.

Backpropagation requires a loss function, which calculates the difference between
the models predicted output (here, the probabilities corresponding to the target
token IDs) and the actual desired output. This loss function measures how far off the
models predictions are from the target values.

```elixir
# Working with logarithms of probability scores is more manageable in mathematical
# optimization than handling the scores directly.

log_probas =
  [target_probas_1, target_probas_2]
  |> Nx.concatenate()
  |> Nx.log()
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[6]
  EXLA.Backend<host:0, 0.80407116.422182936.48559>
  [-10.642878532409668, -10.91103744506836, -11.129709243774414, -10.900972366333008, -10.781830787658691, -10.85040283203125]
>
```

```elixir
avg_log_probas = Nx.mean(log_probas)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.80407116.422182936.48563>
  -10.86947250366211
>
```

```elixir
neg_avg_log_probas = Nx.multiply(avg_log_probas, -1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.80407116.422182936.48565>
  10.86947250366211
>
```

The goal is to get the average log probability as close to 0 as possible by updating the
models weights as part of the training process.

However, the common practice isnt to push the average log probability up to 0 but rather to bring the
negative average log probability down to 0. The negative average log probability is
simply the average log probability multiplied by 1.

In deep learning, the term for turning this negative value, is known as cross entropy loss.

The cross entropy loss is popular measure in machine learning and deep learning that measures the difference between two probability distribution.

```elixir
IO.inspect(logits.shape, label: "Logits shape:")
IO.inspect(targets.shape, label: "Targets shape:")
```

<!-- livebook:{"output":true} -->

```
Logits shape:: {2, 3, 50257}
Targets shape:: {2, 3}
```

<!-- livebook:{"output":true} -->

```
{2, 3}
```

```elixir
logits_flat = Nx.flatten(logits, axes: [0,1])
targets_flat = Nx.flatten(targets)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[6]
  [5149, 11031, 499, 2216, 1093, 18414]
>
```

```elixir
IO.inspect(logits_flat.shape, label: "Flatten Logits shape:")
IO.inspect(targets_flat.shape, label: "Flatten Targets shape:")
```

<!-- livebook:{"output":true} -->

```
Flatten Logits shape:: {6, 50257}
Flatten Targets shape:: {6}
```

<!-- livebook:{"output":true} -->

```
{6}
```

```elixir
y_true = Nx.tensor([0, 2, 1])
y_pred = Nx.tensor([[0.2, 0.8, 0.0], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7]])
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[3][3]
  [
    [0.20000000298023224, 0.800000011920929, 0.0],
    [0.10000000149011612, 0.20000000298023224, 0.699999988079071],
    [0.10000000149011612, 0.20000000298023224, 0.699999988079071]
  ]
>
```

```elixir
loss = Axon.Losses.categorical_cross_entropy(
  targets_flat, logits_flat, reduction: :mean, from_logits: true, sparse: true)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.80407116.422182936.48666>
  10.86947250366211
>
```

**Perplexity**

Perplexity is a measure often used alongside cross entropy loss to evaluate the performance of models in tasks like language modeling. It can provide a more interpretable way to understand the uncertainty of a model in predicting the next token in a
sequence.

Perplexity measures how well the probability distribution predicted by the model
matches the actual distribution of the words in the dataset. Similar to the loss, a lower
perplexity indicates that the model predictions are closer to the actual distribution.

Perplexity is often considered more interpretable than the raw loss value because it signifies the effective vocabulary size about which the model is uncertain at each step. In
the given example, this would translate to the model being unsure about which among
48,725 tokens in the vocabulary to generate as the next token.

```elixir
perplexity = Nx.exp(loss)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.80407116.422182936.48669>
  52547.484375
>
```
