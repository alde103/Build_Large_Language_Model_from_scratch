<!-- livebook:{"persist_outputs":true} -->

# Chapter 5: Pretraining on unlabeled data

```elixir
Mix.install([
  {:nx, "~> 0.5"},
  {:exla, "~> 0.5"},
  {:axon, "~> 0.5"},
  {:tiktoken, "~> 0.3.2"},
  {:table_rex, "~> 3.1.1"},
  {:kino_vega_lite, "~> 0.1.11"}
])
```

## Introduction

This section covers:

* Pretraining the LLM.
* Implementing the training code.
* Evaluating the performance process.
* Saving and loading model weights.

In the context of LLMs and other deep learning models, weights refer to the trainable
parameters that the learning process adjusts. These weights are also known as
weight parameters or simply parameters.

```elixir
tokenizer = "gpt-3.5-turbo"
gpt_config_124m = [
  vocab_size: 50257,
  context_length: 1024,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0.1,
  qkv_bias: false
]
```

<!-- livebook:{"output":true} -->

```
[
  vocab_size: 50257,
  context_length: 1024,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0.1,
  qkv_bias: false
]
```

```elixir
defmodule Transformer.Layers do
  import Nx.Defn
  
  def attention(%Axon{} = input, opts \\ []) do
    #opts = Keyword.validate!(opts, [:name, :d_in, :d_out, :num_heads])
    head_dim = div(opts[:d_out], opts[:num_heads])
    w_query = Axon.param("w_query", fn _ -> {opts[:d_in], opts[:d_out]} end)
    w_key = Axon.param("w_key", fn _ -> {opts[:d_in], opts[:d_out]} end)
    w_value = Axon.param("w_value", fn _ -> {opts[:d_in], opts[:d_out]} end)
    out_proj = Axon.param("out_proj", fn _ -> {opts[:d_out], opts[:d_out]} end)

    Axon.layer(
      &attention_impl/6,
      [input, w_query, w_key, w_value, out_proj],
      name: opts[:name],
      op_name: :causal_attention,
      head_dim: head_dim,
      num_heads: opts[:num_heads]
    )
  end

  #defnp attention_impl(input, w_query, w_key, w_value, head_dim, num_heads, _opts \\ []) do
  defnp attention_impl(input, w_query, w_key, w_value, out_proj, opts \\ []) do
    {b, num_tokens, _d_in} = Nx.shape(input)
    keys = Nx.dot(input, w_key)
    queries = Nx.dot(input, w_query)
    values = Nx.dot(input, w_value)
    d_k = Nx.axis_size(keys, -1)

    keys_reshaped = 
      keys
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])
    
    queries_reshaped = 
      queries
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])
    
    values_reshaped = 
      values
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])

    attn_score =
      keys_reshaped
      |> Nx.transpose(axes: [0, 1, 3, 2])
      |> then(&Nx.dot(queries_reshaped, [3], [0, 1], &1, [2], [0, 1]))

    simple_mask =
      attn_score
      |> then(&Nx.broadcast(Nx.Constants.infinity(), &1))
      |> Nx.triu(k: 1)

    masked = Nx.multiply(simple_mask, -1) |> Nx.add(attn_score)

    attn_weights =
      masked
      |> Nx.divide(Nx.pow(d_k, 0.5))
      |> Axon.Activations.softmax(axis: -1)
    
    context_vec =
      attn_weights
      |> Nx.dot([3], [0, 1], values_reshaped, [2], [0, 1])
      |> Nx.transpose(axes: [0, 2, 1, 3])

    context_vec
    |> Nx.reshape({b, num_tokens, opts[:num_heads] * opts[:head_dim]})
    |> Nx.dot(out_proj)
  end

  def shortcut(x, layer_impl, opts \\ []) when is_function(layer_impl) do
    with {:arity, arity} <- Function.info(layer_impl, :arity),
          layer_output <- execute_layer(x, layer_impl, opts, arity),
          output <- shortcut_impl(x, layer_output, opts) do
      output
    end    
  end

  defp execute_layer(x, layer_impl, _opts, 1), do: layer_impl.(x)
  defp execute_layer(x, layer_impl, opts, _arity), do: layer_impl.(x, opts)
  defp shortcut_impl(x, layer_output, opts) do
    use_shortcut? = Keyword.get(opts, :use_shortcut, false)
    if use_shortcut?, 
      do: Axon.add(x, layer_output),
      else: layer_output
  end

  def normalization(%Axon{} = input, opts \\ []) do
    #opts = Keyword.validate!(opts, [:name, :eps, :emb_dim])
    eps = Keyword.get(opts, :eps, 1.00e-5)
    scale = Axon.param("scale", {opts[:emb_dim]}, initializer: &ones(&1, type: &2))
    shift = Axon.param("shift", {opts[:emb_dim]}, initializer: &zeros(&1, type: &2))

    Axon.layer(
      &normalization_impl/4,
      [input, scale, shift],
      name: opts[:name],
      op_name: :normalization,
      eps: eps
    )
  end

  defp ones(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(1)
  end

  defp zeros(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(0)
  end

  defnp normalization_impl(input, scale, shift, opts \\ []) do
    mean = Nx.mean(input, axes: [-1], keep_axes: true)
    variance = Nx.variance(input, axes: [-1], keep_axes: true)
    denominator = variance |> Nx.add(opts[:eps]) |> Nx.sqrt()

    input
    |> Nx.subtract(mean)
    |> Nx.divide(denominator)
    |> Nx.multiply(scale)
    |> Nx.add(shift)
  end

  def pos_embedding(%Axon{} = x, vocab_size, embedding_size, opts \\ []) do
    opts = Keyword.validate!(opts, [:name, kernel_initializer: :uniform])

    kernel_shape = &Axon.Shape.embedding_kernel(&1, vocab_size, embedding_size)

    kernel = Axon.param("kernel", kernel_shape, initializer: opts[:kernel_initializer])

    Axon.layer(&pos_embedding_impl/3, [x, kernel], name: opts[:name], op_name: :pos_embedding)
  end

  defnp pos_embedding_impl(x, kernel, _opts \\ []) do
    {_batch_size, sequence_size} = Nx.shape(x)
    input = Nx.iota({1, sequence_size})
    Nx.take(kernel, input, axis: 0)
  end

  def feedforward(input, emb_dim) do
    input
    |> Axon.dense(4*emb_dim)
    |> Axon.activation(:gelu)
    |> Axon.dense(emb_dim)
  end

  def feedforward_block(input, opts) do
    input
    |> normalization(opts)
    |> feedforward(opts[:emb_dim])
    |> Axon.dropout(rate: opts[:drop_rate])
  end

  def attention_block(input, opts) do
    input
    |> normalization(opts)
    |> attention(d_in: opts[:emb_dim], d_out: opts[:emb_dim], num_heads: opts[:n_heads] )
    |> Axon.dropout(rate: opts[:drop_rate])
  end

  def block(input, opts \\ []) do
    input
    |> shortcut(&attention_block(&1, opts), use_shortcut: true)
    |> shortcut(&feedforward_block(&1, opts), use_shortcut: true)
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, Transformer.Layers, <<70, 79, 82, 49, 0, 0, 51, ...>>, {:block, 2}}
```

```elixir
defmodule MyGPT do
  @gpt_config_124m gpt_config_124m
  def model(input_shape \\ {2, 4, 768}, opts \\ @gpt_config_124m) do
    Axon.input("sequence", shape: input_shape)
    |> embedding_block(opts)
    |> Axon.dropout(rate: opts[:drop_rate])
    |> transformer_blocks(12, opts)
    |> Transformer.Layers.normalization(opts)
    |> Axon.dense(opts[:vocab_size], use_bias: false)
  end

  def embedding_block(input, opts) do
    token_emb = Axon.embedding(input, opts[:vocab_size], opts[:emb_dim])
    pos_emb = Transformer.Layers.pos_embedding(input, opts[:context_length], opts[:emb_dim])

    Axon.add(token_emb, pos_emb)
  end

  def transformer_blocks(input, n_blocks, transformer_opts) do
    for _n_block <- 1..n_blocks, reduce: input do
      model_acc ->
        Transformer.Layers.block(model_acc, transformer_opts)
    end
  end

  def text_to_token_ids(tokenizer, texts) when is_list(texts) do
    token_ids_list = 
      for text <- texts do
        {:ok, token_ids} = text_to_token_ids(tokenizer, text)
        token_ids
      end
    Nx.stack(token_ids_list, axis: 1) |> Nx.squeeze()
  end

  def text_to_token_ids(tokenizer, text) do
    {:ok, tokens} = Tiktoken.encode(tokenizer, text)
    {:ok, Nx.tensor(tokens, type: :s64) |> Nx.new_axis(0)}
  end

  def token_ids_to_text(tokenizer, token_ids) do
    tokens_ids = Nx.to_flat_list(token_ids)
    Tiktoken.decode(tokenizer, tokens_ids)
  end

  def generate_tokens(predict_fn, model_params, input, max_new_token) when is_function(predict_fn) do
    generate_tokens_impl(predict_fn, model_params, input, max_new_token)
  end

  def generate_tokens_with_model(model, model_params, input, max_new_token) when model_params == %{} do
    {init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
    template = Nx.template(Nx.shape(input), :s64)
    init_model_params = init_fn.(template, model_params)
    generate_tokens_impl(predict_fn, init_model_params, input, max_new_token)
  end

  def generate_tokens_with_model(model, model_params, input, max_new_token) do
    {_init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
    generate_tokens_impl(predict_fn, model_params, input, max_new_token)
  end

  defp generate_tokens_impl(predict_fn, model_params, input, max_new_token) do
    for _new_token_index <- 1..max_new_token, reduce: input do
      input_acc ->
        logit = predict_fn.(model_params, input_acc)

        # Get last element of the vector.
        predicted_new_token =
          logit[[.., -1]]
          |> Axon.Layers.softmax(axis: -1)
          |> Nx.argmax(axis: -1)
          |> Nx.new_axis(0)

        Nx.concatenate([input_acc, predicted_new_token], axis: 1)
    end
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, MyGPT, <<70, 79, 82, 49, 0, 0, 25, ...>>, {:generate_tokens_impl, 4}}
```

## 5.1 Evaluating generative text models

```elixir
gpt_config_124m = [
  vocab_size: 50257,
  context_length: 256,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0,
  qkv_bias: false
]
```

<!-- livebook:{"output":true} -->

```
[
  vocab_size: 50257,
  context_length: 256,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0,
  qkv_bias: false
]
```

```elixir
model = MyGPT.model()
{init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
template = Nx.template({1, 4}, :s64)
params = init_fn.(template, %{})
```

<!-- livebook:{"output":true} -->

```
%{
  "pos_embedding_0" => %{
    "kernel" => #Nx.Tensor<
      f32[1024][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180683>
      [
        [0.0077318595722317696, -0.005257546901702881, 0.0055906507186591625, -0.0028027009684592485, 0.009292509406805038, -0.005205206573009491, 0.0037132762372493744, 0.0024974511470645666, -0.009079880081117153, -0.00549595570191741, 0.00897140707820654, -0.0014951109187677503, 0.009282090701162815, 0.0036399743985384703, -0.007245824206620455, -2.6857852935791016e-4, -0.003582477569580078, 0.0055953096598386765, 0.005810535047203302, 0.009268462657928467, 0.00501592131331563, -0.003076486522331834, 0.004535443615168333, 0.006220667157322168, -0.0034490919206291437, 0.0017234706319868565, -2.9032229576841928e-5, 0.0029373574070632458, 0.007918906398117542, 0.00951975118368864, -0.006746442057192326, 0.007965330965816975, 0.003882465185597539, 0.0025654935743659735, 0.006666292902082205, 0.0017197512788698077, -0.005652403924614191, -0.007785887457430363, 0.004929478280246258, 0.00680773239582777, 0.009451624937355518, -0.0059967041015625, -0.0062972973100841045, -0.00611378438770771, -0.004314355552196503, 0.009038102813065052, 0.006874177139252424, -0.0010198830859735608, ...],
        ...
      ]
    >
  },
  "normalization_6" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180675>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180676>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_4" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180620>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180621>
      [
        [-0.016148878261446953, -0.014840490184724331, -0.013926058076322079, 0.019414067268371582, 0.01830415427684784, 0.03502250835299492, 0.007946353405714035, -0.026665272191166878, -0.030626824125647545, 0.03479188680648804, -0.001013906323350966, 0.02819540537893772, -0.015203100629150867, -0.0075075565837323666, 9.070627856999636e-4, 0.03660527616739273, -0.03677726164460182, -0.02131606452167034, 0.016707448288798332, 0.021644050255417824, 0.015444805845618248, -0.03670639917254448, 0.002971837529912591, -0.00747350649908185, 0.023399028927087784, 0.013180367648601532, 0.0061000436544418335, 0.012488028965890408, -0.004679298494011164, -0.020657144486904144, 0.032204605638980865, -0.002939163474366069, -0.00805789977312088, 0.013074221089482307, 0.003085014410316944, 0.03883887827396393, 0.029479799792170525, 0.027975574135780334, -0.012192510068416595, 0.031185714527964592, -0.020919395610690117, -0.018187331035733223, -0.01308861281722784, 0.008923768997192383, 0.006430601701140404, ...],
        ...
      ]
    >
  },
  "normalization_5" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180673>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180674>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_20" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180609>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180610>
      [
        [-5.896987277083099e-4, -0.005735849961638451, 0.01885833404958248, -0.03877842053771019, 0.034597933292388916, 0.012202820740640163, 0.024213554337620735, 0.030056031420826912, -0.03346363827586174, -0.027872679755091667, 0.005955851636826992, 0.03334861621260643, 0.02315874584019184, 0.024373117834329605, 0.030379295349121094, -0.017190568149089813, -0.00975542701780796, 0.014576232060790062, 0.014987783506512642, -0.02961798757314682, -0.020148834213614464, -0.024757497012615204, -0.01636221632361412, 0.028842998668551445, 0.015733228996396065, -0.0029824022203683853, -0.019074970856308937, -0.03696736693382263, -0.003487772075459361, 0.037933990359306335, -0.024189455434679985, 0.01849869266152382, -0.034248922020196915, -0.02798386663198471, 0.030318809673190117, -0.033449240028858185, 0.002367512322962284, -0.032014358788728714, 0.009850971400737762, 0.0047944639809429646, -0.03646615520119667, -0.02577616274356842, 0.026577938348054886, ...],
        ...
      ]
    >
  },
  "normalization_1" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180635>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180636>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_9" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180681>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180682>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_22" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180613>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180614>
      [
        [0.016082437708973885, 0.01520540937781334, -0.0077116782777011395, -0.03073425218462944, 0.017589066177606583, -0.005499148741364479, 0.024801133200526237, -0.015484416857361794, 0.02342919632792473, -0.037729039788246155, 0.016301166266202927, 0.029913224279880524, 0.03816244751214981, 0.005433631129562855, 0.006881612353026867, -0.010639466345310211, 0.02815450355410576, -0.03019752725958824, 0.02377862110733986, 0.017034217715263367, 0.03566452115774155, -0.002733430592343211, 0.00444650836288929, -0.021734032779932022, -0.03891237825155258, -0.039361778646707535, -0.03500570356845856, -0.017624245956540108, 0.03469621017575264, 0.025144459679722786, 0.03266434371471405, -0.026591753587126732, 0.013634695671498775, -0.012556731700897217, -0.0012003099545836449, -0.012306082993745804, -0.013451948761940002, -0.008731503039598465, -0.012201812118291855, 0.029391899704933167, ...],
        ...
      ]
    >
  },
  "causal_attention_0" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180535>
      [
        [0.034585148096084595, -0.04261672496795654, -0.016539201140403748, 0.009025529026985168, 0.011034980416297913, -0.05826513469219208, -4.540383815765381e-5, 0.00747951865196228, -0.027294456958770752, 0.019962191581726074, -2.7674436569213867e-4, 0.05887827277183533, -0.05928298830986023, 0.05296309292316437, -0.054687947034835815, -0.01873493194580078, -0.06134159862995148, -0.03547586500644684, 0.03471839427947998, -0.0508447140455246, 0.019207432866096497, -0.059233903884887695, -0.018133506178855896, 0.02591603994369507, -0.048388466238975525, -0.026128709316253662, -0.029295966029167175, -0.05214647948741913, 0.011360123753547668, 0.05773606896400452, 0.006880015134811401, -0.016269370913505554, 0.0035202056169509888, -0.05477052927017212, -0.0318976491689682, 0.008234798908233643, -0.006709262728691101, 0.02909064292907715, -0.02625085413455963, -0.03689722716808319, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180536>
      [
        [-0.009196177124977112, 0.026425033807754517, 0.02335461974143982, 0.044783204793930054, -0.02983175218105316, -0.046726152300834656, -0.024089381098747253, 0.049806609749794006, -0.035629212856292725, -0.058591753244400024, 0.012432634830474854, 0.04266269505023956, -0.04372633993625641, 0.03931407630443573, -0.029659688472747803, -0.056867778301239014, 0.02655567228794098, 0.062302157282829285, -0.03463231027126312, 0.045396581292152405, -0.027446851134300232, 0.05563744902610779, -0.015892744064331055, -0.03601944446563721, -0.001065865159034729, -0.053676143288612366, 0.057741641998291016, 0.022515103220939636, -0.014295265078544617, 0.00878480076789856, 0.022680923342704773, 0.05680316686630249, 0.0403766930103302, 0.012771308422088623, -0.03357900679111481, -0.024788260459899902, 0.025448381900787354, 0.03264161944389343, 0.0071820467710494995, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180537>
      [
        [0.0019395053386688232, 0.001183435320854187, 0.017731234431266785, -0.05847477912902832, 0.04535207152366638, -0.0326017290353775, -0.06240713596343994, 0.03375101089477539, 0.0212632417678833, -0.05425235629081726, 0.01004435122013092, -0.04608713090419769, -0.03331676125526428, -0.04245087504386902, 0.025085851550102234, -0.04998962581157684, 0.03766663372516632, -0.04465055465698242, -0.013292565941810608, 0.04420022666454315, -0.005949109792709351, 0.025164008140563965, 0.015668421983718872, -0.012863099575042725, -0.004498600959777832, 0.032402291893959045, 0.008101686835289001, -0.014333263039588928, 0.04176674783229828, -0.058778539299964905, -0.005472272634506226, -0.043054670095443726, 0.040869250893592834, -0.04463489353656769, -0.054578810930252075, -0.031747981905937195, 0.03646188974380493, -0.03440470993518829, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180538>
      [
        [0.05764779448509216, 0.019915863871574402, 0.04528437554836273, -0.02195724844932556, -0.001949995756149292, -0.03237925469875336, -0.030074939131736755, -0.031184017658233643, -0.03702017664909363, -0.058783456683158875, 0.05560371279716492, 0.0013141483068466187, 0.009311094880104065, 0.016575738787651062, 0.03370888531208038, -0.03880222141742706, 0.0399041622877121, 0.03293459117412567, -0.011443302035331726, -0.03067857027053833, 0.012827426195144653, -0.014567598700523376, 0.002179935574531555, 0.036056339740753174, 0.02695026993751526, -0.023645177483558655, 0.01811528205871582, 0.053089872002601624, -0.04955144226551056, -0.05254814028739929, -0.002276778221130371, 0.05355042219161987, 0.038458794355392456, 0.013291478157043457, -0.03522442281246185, -0.04675950109958649, -0.006428360939025879, ...],
        ...
      ]
    >
  },
  "normalization_14" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180645>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180646>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_7" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180677>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180678>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_11" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180639>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180640>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_2" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180657>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180658>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_12" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180591>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180592>
      [
        [0.010097210295498371, -0.01463150605559349, 0.03266848996281624, 0.0261318851262331, 0.020852210000157356, -0.03601878881454468, -0.01007429976016283, -0.016935016959905624, -0.03260653465986252, -0.018548933789134026, 0.020140917971730232, -0.030207177624106407, 0.0053735035471618176, -0.008583729155361652, -0.019104938954114914, -0.028250254690647125, -0.0036515009123831987, 0.020169105380773544, 0.016276681795716286, 0.011492329649627209, -0.013386656530201435, -0.0282912515103817, 0.031838275492191315, -0.008365528658032417, -0.028151657432317734, -0.003238498931750655, -0.013437180779874325, -0.02286081574857235, 0.01740678958594799, -0.036413274705410004, 0.00773135619238019, -0.038421135395765305, -0.032039493322372437, 0.005893094930797815, ...],
        ...
      ]
    >
  },
  "dense_23" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180615>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180616>
      [
        [0.0030493338126689196, -0.0016611217288300395, -0.024992654100060463, -0.006609757896512747, -0.002880939980968833, 0.02133236825466156, -0.024294434115290642, 0.00785160157829523, 0.002559203188866377, 0.03247906267642975, -0.012869732454419136, -0.009595119394361973, 0.022193478420376778, -0.010751191526651382, 0.02658906765282154, 0.008795117028057575, -0.027100609615445137, 0.03907352313399315, -0.027872689068317413, -0.020925238728523254, 0.017966339364647865, 0.025618230924010277, 0.011748426593840122, 0.026461990550160408, 0.008145385421812534, -0.01240339782088995, -0.016862912103533745, -0.034014180302619934, 0.031935401260852814, 0.03171229735016823, 0.027485480532050133, -0.035951048135757446, -0.02276885323226452, ...],
        ...
      ]
    >
  },
  "embedding_0" => %{
    "kernel" => #Nx.Tensor<
      f32[50257][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180632>
      [
        [0.006193456705659628, 9.909438667818904e-4, 7.606911240145564e-4, 0.0027745317202061415, 2.851581375580281e-4, -0.003744430374354124, 0.00961273442953825, -8.777451585046947e-4, -0.007919933646917343, -0.007603509351611137, 2.921462000813335e-4, -0.007598021067678928, 0.001527359476312995, 0.007481202948838472, 0.004020495340228081, -0.007914116606116295, -0.0044707609340548515, 0.0018580961041152477, 0.00725650554522872, -0.006027636583894491, 0.008344034664332867, 8.658719016239047e-4, 0.0040307496674358845, 9.31596732698381e-4, 0.009387945756316185, 0.0022305964957922697, 0.005701668094843626, -0.006340291351079941, 2.7173280250281096e-4, 0.006278121378272772, -0.00796880666166544, 0.0022779558785259724, 0.0032165192533284426, ...],
        ...
      ]
    >
  },
  "normalization_19" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180655>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180656>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_6" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180567>
      [
        [0.03611791133880615, 0.006852373480796814, 0.01618422567844391, 0.03482261300086975, -0.05885253846645355, -0.057941898703575134, 0.045551300048828125, -0.061193257570266724, -0.06019110977649689, -0.020824238657951355, 0.04071594774723053, -0.030543699860572815, 0.00449468195438385, -0.05295145511627197, 0.026382967829704285, 0.021105453372001648, -0.04896897077560425, 0.03152535855770111, 0.021192744374275208, -0.004860788583755493, 0.005134403705596924, 0.016286298632621765, -0.04627455770969391, 0.04043227434158325, -0.03298830986022949, 0.010725155472755432, -0.02491496503353119, 0.05798336863517761, 0.059480711817741394, 0.03982539474964142, 0.018792524933815002, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180568>
      [
        [-0.017237618565559387, 0.03926241397857666, -0.003312230110168457, -0.011963561177253723, 0.02829672396183014, -0.002811223268508911, 0.03696693480014801, 0.05618949234485626, 0.012282758951187134, 0.019045397639274597, -0.04620979726314545, -0.035103216767311096, 0.056177809834480286, 0.02966950833797455, 0.030942052602767944, -0.014856800436973572, 0.05652262270450592, 0.04847678542137146, 0.01730424165725708, 0.053379908204078674, 0.05873018503189087, -0.009840831160545349, 0.04553718864917755, -0.027292951941490173, 0.014556869864463806, 0.058296531438827515, -0.029507100582122803, -0.016966283321380615, 0.023847565054893494, 0.05207681655883789, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180569>
      [
        [-0.005153223872184753, 0.04288795590400696, 0.05938401818275452, -0.03259932994842529, -0.05712650716304779, 0.04762865602970123, 0.048109203577041626, -0.054965704679489136, -0.02598637342453003, -0.05786886811256409, -0.029315635561943054, -0.003994882106781006, -0.04367624223232269, -0.056926727294921875, -0.04455290734767914, 0.023904934525489807, -0.034892916679382324, -0.011289745569229126, 0.028390467166900635, -0.04931221902370453, 0.029581665992736816, -0.009209319949150085, 0.020306184887886047, 0.0578276664018631, -0.05813990533351898, 0.0055899471044540405, 0.027609512209892273, 0.051757946610450745, 0.050081655383110046, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180570>
      [
        [-0.046017467975616455, 0.03440643846988678, -0.06110985577106476, 0.049447059631347656, 0.027189865708351135, -0.0034376829862594604, -0.003696754574775696, -0.05297066271305084, 0.04115770757198334, 0.059224069118499756, -0.029030010104179382, 0.011395841836929321, 1.0600686073303223e-4, -0.03760810196399689, 0.040508121252059937, -0.025478512048721313, -0.0464203804731369, 0.06155863404273987, 0.05625312030315399, 0.032936543226242065, 0.012743815779685974, 0.050260141491889954, -0.005364179611206055, 0.020125940442085266, 0.016040444374084473, -0.024600565433502197, -0.01726222038269043, -0.04477575421333313, ...],
        ...
      ]
    >
  },
  "causal_attention_7" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180571>
      [
        [-0.02323545515537262, 0.051628753542900085, 0.033514633774757385, -0.04381707310676575, -0.044767826795578, 0.05302669107913971, 0.022239655256271362, 0.05512422323226929, -0.05701442062854767, 0.005875289440155029, -0.058475181460380554, -0.04379802942276001, 0.04303300380706787, 0.054860204458236694, -0.01617354154586792, 0.022587016224861145, -0.0048463791608810425, 0.04651257395744324, -0.03269381821155548, 0.04813699424266815, -0.022878721356391907, -0.027351990342140198, 0.0018782168626785278, 0.006644546985626221, -0.031519815325737, 0.013715177774429321, -0.04889003932476044, 0.005279958248138428, 0.012032955884933472, 0.03586137294769287, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180572>
      [
        [0.03551097214221954, 0.0034480541944503784, -0.03325758874416351, 0.05900968611240387, -0.019965633749961853, -0.04945850372314453, -0.05148264765739441, -0.04480926692485809, -0.05695487558841705, 0.015325993299484253, 0.02994707226753235, 0.01838192343711853, -0.03955090045928955, -0.04866783320903778, -0.05919851362705231, -0.042546868324279785, -0.04589161276817322, -0.05712461471557617, 0.007971987128257751, 0.02342289686203003, -0.044640541076660156, 0.042993560433387756, 0.010886996984481812, 0.01995450258255005, 0.011314153671264648, -0.056645721197128296, -0.062431663274765015, 0.04850170016288757, -0.06184649467468262, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180573>
      [
        [0.026023119688034058, -0.01646825671195984, -0.03746393322944641, 0.014834195375442505, 0.017858177423477173, 0.0336950421333313, -0.012776106595993042, 0.02457660436630249, -0.0031520724296569824, -0.02632857859134674, 0.04703955352306366, -0.01145896315574646, 0.04978740215301514, 0.011469915509223938, 0.0035194307565689087, -0.029521003365516663, -0.026720821857452393, 0.044487595558166504, -6.656497716903687e-4, 0.02744656801223755, -0.014136090874671936, -0.010515779256820679, 0.05725935101509094, -0.060986801981925964, 0.05877973139286041, 0.03624372184276581, 0.05110029876232147, -0.018161743879318237, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180574>
      [
        [-0.050480931997299194, 0.04737496376037598, 0.0076857805252075195, 0.03344695270061493, 0.04679267108440399, -0.004239529371261597, -0.05505499243736267, 0.017636656761169434, 0.03175802528858185, -0.055080145597457886, 0.03959985077381134, -0.021733388304710388, 0.052627354860305786, 0.05066691339015961, 0.028143689036369324, -0.041505515575408936, 0.014543458819389343, -0.02630549669265747, 0.028613463044166565, -0.0062089115381240845, 0.02535116672515869, -0.025743067264556885, 0.05048811435699463, 0.02585144340991974, 0.024156004190444946, 0.037751033902168274, -0.04605357348918915, ...],
        ...
      ]
    >
  },
  "causal_attention_1" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180539>
      [
        [0.03712904453277588, 0.03924751281738281, -0.007418379187583923, 0.01422932744026184, 0.0614473819732666, 0.02088649570941925, 0.019091859459877014, -0.012615904211997986, -0.04992055892944336, -0.03724576532840729, -0.05684831738471985, -0.027137860655784607, 0.05073632299900055, -0.022290781140327454, 0.009355872869491577, -0.02221977710723877, 0.007718890905380249, -0.024620309472084045, -0.0013895630836486816, 0.04039366543292999, 0.04438084363937378, -0.016877025365829468, -0.05370175838470459, -0.05188782513141632, 0.0400332510471344, -0.011018261313438416, -0.0288839191198349, 0.04398404061794281, -0.04217417538166046, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180540>
      [
        [-0.0019405931234359741, 0.058425143361091614, 0.0163661390542984, -0.019455865025520325, -0.024736404418945312, 0.01423954963684082, 0.03711584210395813, -0.052373260259628296, -0.039123132824897766, -0.04541417956352234, 0.028041958808898926, 0.01756909489631653, 0.04732842743396759, -0.003934189677238464, 0.04269285500049591, -0.037498921155929565, 0.017295941710472107, -0.03078731894493103, -0.019626468420028687, 0.06087397038936615, -0.002902776002883911, 0.025272861123085022, -0.05093628168106079, 0.01705750823020935, 0.027190551161766052, -0.02253583073616028, -0.01863865554332733, -0.022550180554389954, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180541>
      [
        [0.05787651240825653, 0.014542445540428162, 0.010843530297279358, 0.020697742700576782, 0.0342453271150589, 0.05810083448886871, -0.02266871929168701, -0.03292305767536163, 0.022356465458869934, -0.05711276829242706, 0.05091342329978943, -0.05329717695713043, -0.06063041090965271, -0.057459309697151184, 0.007425412535667419, 0.017856433987617493, -0.04381503164768219, -0.02605956792831421, 0.020387351512908936, 0.037182509899139404, 0.030833229422569275, -0.0389457643032074, -0.004200547933578491, 0.03913438320159912, -0.052682340145111084, -0.03975589573383331, -0.0246669203042984, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180542>
      [
        [-0.018168628215789795, -0.04376170039176941, -0.001942455768585205, 0.00821763277053833, 0.008898645639419556, 0.027182936668395996, 0.022662505507469177, 0.0498204231262207, -0.01861715316772461, -0.010150939226150513, 0.03014214336872101, -0.021435528993606567, 0.03125523030757904, 0.0106697678565979, -0.04448975622653961, 0.01607772707939148, -0.015051007270812988, 0.03714151680469513, -0.013123169541358948, -0.0618465393781662, 0.007821515202522278, -0.023626461625099182, -0.03556753695011139, 0.041106224060058594, 0.011591121554374695, -0.051805973052978516, ...],
        ...
      ]
    >
  },
  "dense_15" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180597>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180598>
      [
        [-0.02487862855195999, -0.017849290743470192, 0.0017523020505905151, 0.02229803241789341, -0.0031428232323378325, -0.028924565762281418, 0.019618583843111992, 0.026651890948414803, -0.02572059817612171, 0.012709829956293106, -0.03215853124856949, 0.026681246235966682, 0.028103245422244072, -0.007076365873217583, 0.0303930826485157, 0.0017592005897313356, -0.008039974607527256, -0.008680611848831177, 6.458770949393511e-4, 0.013417747803032398, 0.01748323068022728, -0.00846374873071909, -0.004853441379964352, -0.019639186561107635, -0.016760488972067833, -0.00872925017029047, 0.03688632696866989, ...],
        ...
      ]
    >
  },
  "dense_9" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180630>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180631>
      [
        [-0.02049286849796772, -0.018731331452727318, -0.0373472161591053, -0.006967458408325911, 0.009437262080609798, -0.03672831878066063, 0.030532656237483025, -0.019636189565062523, 0.01440429501235485, 0.02463548071682453, 0.018052129074931145, 0.03722939267754555, -0.031961675733327866, -0.024396780878305435, -0.009515220299363136, -0.00980892963707447, -0.004664106760174036, 0.0074799624271690845, -0.0035236694384366274, -0.01271015964448452, 0.02262766659259796, 0.003655100939795375, -0.022180436179041862, 0.026832658797502518, -0.0319414883852005, -0.012094223871827126, ...],
        ...
      ]
    >
  },
  "normalization_8" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180679>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180680>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_10" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180543>
      [
        [0.02078750729560852, 0.007415741682052612, -0.047732874751091, -0.055748239159584045, 0.04126277565956116, 0.0037894994020462036, -0.027394980192184448, 0.062115758657455444, -0.0018527209758758545, -0.012752339243888855, 0.008404076099395752, -0.05888493359088898, 0.014748543500900269, -0.01796180009841919, -0.025534823536872864, 0.0031326264142990112, -0.03902892768383026, -0.02167874574661255, 0.024089902639389038, -0.05484314262866974, 0.0611918568611145, -0.046846628189086914, -0.015903949737548828, 0.04943782091140747, -0.006929174065589905, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180544>
      [
        [0.061318784952163696, -0.012640580534934998, 0.0621202290058136, 0.03695724904537201, -0.011088714003562927, 0.01879046857357025, -0.058595210313797, -0.011772364377975464, 0.018001049757003784, 0.0315169095993042, 0.033891260623931885, -0.04861891269683838, -0.04001043736934662, -0.035471111536026, -0.03245764970779419, -0.0492997020483017, -0.0319942831993103, 0.06229761242866516, 0.05052292346954346, 0.03158695995807648, -0.0021551400423049927, 0.012499824166297913, -0.03819398581981659, 0.05912822484970093, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180545>
      [
        [0.022077977657318115, 0.05395375192165375, -0.05929628014564514, -0.01312325894832611, -0.028069987893104553, -1.7270445823669434e-4, 0.010598495602607727, 6.794482469558716e-4, -0.05728539824485779, 0.0029573291540145874, -0.032078444957733154, -0.04552197456359863, 0.029843956232070923, -0.02633202075958252, -0.01736368238925934, -0.0453086793422699, 0.02974240481853485, -0.053865402936935425, -0.055321142077445984, 0.05416591465473175, -0.06024613976478577, -0.04884219169616699, 0.012481927871704102, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180546>
      [
        [-0.017062559723854065, -0.028513431549072266, -0.015430629253387451, -0.056202083826065063, -0.0434751957654953, 0.008435085415840149, 0.057447925209999084, 0.00671754777431488, 0.005260244011878967, 0.013695776462554932, -0.054355934262275696, -0.05143165588378906, -0.052027150988578796, -0.03343561291694641, -0.007083594799041748, -0.05863198637962341, -0.025873035192489624, 0.019429698586463928, 0.00859968364238739, -0.013936802744865417, 0.0425068736076355, -0.03341442346572876, ...],
        ...
      ]
    >
  },
  "causal_attention_8" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180575>
      [
        [0.04733365774154663, 0.012578874826431274, -0.030197083950042725, 0.04800425469875336, 0.021483108401298523, -0.022861629724502563, 0.03570760786533356, 0.05394791066646576, -0.04334890842437744, 0.030869022011756897, 0.001620948314666748, -0.016122877597808838, 0.06249906122684479, 0.015774741768836975, -0.04879431426525116, -0.02656078338623047, 0.061087965965270996, -0.008701905608177185, -0.015302374958992004, 0.04934120178222656, -0.027402669191360474, -0.042116835713386536, -0.034471288323402405, -0.05601826310157776, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180576>
      [
        [-0.0560561865568161, 0.006991773843765259, 0.011048391461372375, -0.052109599113464355, -0.01689046621322632, 0.040570273995399475, 0.03750014305114746, 0.05505019426345825, 0.03719624876976013, 0.008592888712882996, -0.023363202810287476, 0.02137438952922821, -0.0018629878759384155, 0.04786024987697601, 7.873773574829102e-4, -0.03704707324504852, 0.05902045965194702, -0.05102279782295227, -0.05195489525794983, -0.035974398255348206, -0.010429397225379944, -0.009729906916618347, 0.05126321315765381, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180577>
      [
        [0.04077829420566559, -0.0026055872440338135, 0.028544515371322632, 0.019124791026115417, 0.04688112437725067, -0.028332993388175964, 0.05856113135814667, -0.03891809284687042, -0.037036240100860596, 0.0010223537683486938, -0.035707175731658936, 0.024816185235977173, 0.03673604130744934, 0.060671091079711914, 0.040707021951675415, -8.936226367950439e-4, 0.022293314337730408, -0.005413800477981567, -0.05215202271938324, 0.025374874472618103, 0.02356646955013275, -0.022669240832328796, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180578>
      [
        [0.02427603304386139, -0.010232418775558472, 0.014508634805679321, 0.020032092928886414, -0.04409678280353546, 0.06218615174293518, 0.031331345438957214, -0.0438736230134964, 0.016528263688087463, 0.03825032711029053, -0.0172908753156662, 0.03370766341686249, 0.030314818024635315, -0.019572928547859192, -0.008543923497200012, 0.021742403507232666, -0.05292774736881256, -0.026023805141448975, -6.29723072052002e-5, -0.03114590048789978, 0.025510743260383606, ...],
        ...
      ]
    >
  },
  "normalization_12" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180641>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180642>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_3" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180618>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180619>
      [
        [-0.010814466513693333, 0.02753930352628231, -0.005950856488198042, -0.0015460600843653083, 0.017821310088038445, -0.012646593153476715, 0.01808459684252739, 0.03499773144721985, 0.006739276461303234, 0.018353302031755447, -0.035644758492708206, -0.023581257089972496, 0.03161902725696564, -0.0020826528780162334, -0.033549562096595764, -0.03260260447859764, 0.030497437343001366, -0.029431650415062904, 0.028711019083857536, 0.03250144422054291, -0.03186161816120148, ...],
        ...
      ]
    >
  },
  "dense_18" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180603>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180604>
      [
        [0.02268061228096485, -0.007435668259859085, -0.02796171046793461, -0.004562427755445242, -0.01702522672712803, 0.022193582728505135, -0.030669299885630608, 0.02768305316567421, -0.011996295303106308, 0.0024309756699949503, -0.013511001132428646, 0.00695049436762929, 0.015598837286233902, 0.028385182842612267, 0.011737965978682041, 0.016438685357570648, 0.029394425451755524, -0.010620693676173687, 0.012423660606145859, -0.005387112498283386, ...],
        ...
      ]
    >
  },
  "dense_5" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180622>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180623>
      [
        [-0.030716288834810257, -0.0033435330260545015, -0.034788019955158234, -0.03302709758281708, -0.03673141077160835, -0.029277006164193153, -0.019647423177957535, -0.01672535575926304, -0.019285283982753754, 0.014391185715794563, -0.034892112016677856, 0.014926053583621979, 0.035307951271533966, 0.02698298543691635, -0.011066935025155544, -0.024217164143919945, -0.022421330213546753, 0.010786759667098522, 0.010848140344023705, ...],
        ...
      ]
    >
  },
  "dense_11" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180589>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180590>
      [
        [-0.03721558675169945, 0.009675688110291958, 0.012033314444124699, 0.016668139025568962, -0.036216605454683304, 0.02492518536746502, 0.029477057978510857, -0.033923208713531494, 0.03601089119911194, 0.010389232076704502, 0.024445580318570137, -0.021742703393101692, 0.007160958368331194, 0.005016717594116926, -0.03758576139807701, -0.02688971348106861, -0.01179259829223156, -0.02261774241924286, ...],
        ...
      ]
    >
  },
  "normalization_18" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180653>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180654>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_6" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180624>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180625>
      [
        [-0.013173714280128479, -0.017342912033200264, -0.004954978823661804, 0.026256058365106583, -0.012947332113981247, 0.0021475485991686583, -0.027773402631282806, 0.024536581709980965, -0.03507352992892265, 0.00375176640227437, 0.017084073275327682, -0.010761200450360775, 0.008548463694751263, -0.027134254574775696, -0.009741649031639099, 0.00619439035654068, ...],
        ...
      ]
    >
  },
  "normalization_15" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180647>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180648>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_23" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180665>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180666>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_10" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180587>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180588>
      [
        [-0.010725189931690693, -0.03484483063220978, 0.0010479469783604145, 0.026630043983459473, -0.006414363626390696, -0.02339288406074047, -0.011754646897315979, -0.019264012575149536, -0.03493670001626015, 0.01775195635855198, -0.0027900519780814648, -0.027944199740886688, 0.02704511024057865, ...],
        ...
      ]
    >
  },
  "dense_13" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180593>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180594>
      [
        [0.0342264361679554, -0.016572387889027596, 0.032968588173389435, -6.305814022198319e-4, -0.007704760879278183, -0.0046464079059660435, 0.005615463946014643, 0.020521821454167366, 0.035898357629776, -0.008253783918917179, 0.007769383490085602, -0.02151721715927124, ...],
        ...
      ]
    >
  },
  "dense_21" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180611>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180612>
      [
        [-0.02343817800283432, -0.037608757615089417, 0.03564184531569481, 0.015376592986285686, 0.026597436517477036, -0.029294583946466446, 0.02324674092233181, 0.030990632250905037, 0.007756519131362438, 0.035814378410577774, -0.037550684064626694, ...],
        ...
      ]
    >
  },
  "dense_8" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180628>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180629>
      [
        [0.031187552958726883, 0.012436524964869022, -0.0055414829403162, -0.03231416642665863, 0.03269248455762863, -0.03234219178557396, -0.003917427267879248, -0.019490912556648254, 0.031053462997078896, -0.011995702050626278, ...],
        ...
      ]
    >
  },
  "dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180583>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180584>
      [
        [0.01682250015437603, 0.025896530598402023, -0.007329276762902737, 0.036022577434778214, -0.01747722737491131, -0.0035124828573316336, -0.01532265730202198, -0.021435385569930077, -0.028667686507105827, ...],
        ...
      ]
    >
  },
  "dense_2" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180607>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180608>
      [
        [0.015953851863741875, 0.01719898357987404, -0.005947218742221594, -0.014274116605520248, -0.005022522993385792, -0.00961918942630291, 0.027453778311610222, -0.026688862591981888, ...],
        ...
      ]
    >
  },
  "causal_attention_3" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180555>
      [
        [0.044574350118637085, 0.007363379001617432, 0.022981896996498108, -0.02263297140598297, -0.02567470073699951, -0.0036739856004714966, 0.01527760922908783, 0.012361094355583191, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180556>
      [
        [-0.0540858656167984, 0.010529935359954834, -0.04199293255805969, -0.026374533772468567, 0.040459439158439636, 0.01632995903491974, -0.019241750240325928, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180557>
      [
        [0.0528557151556015, -0.01676809787750244, -0.012651681900024414, -0.011812284588813782, 0.024289265275001526, 0.0257892906665802, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180558>
      [
        [-0.013727977871894836, 0.03731583058834076, 0.0483844131231308, -0.018293991684913635, -0.040663138031959534, ...],
        ...
      ]
    >
  },
  "normalization_21" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180661>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180662>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_5" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180563>
      [
        [-0.019161701202392578, -0.044397979974746704, -0.04579922556877136, 0.0030121952295303345, -0.019005849957466125, -0.03874172270298004, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180564>
      [
        [0.058563753962516785, -0.05424666404724121, 0.011958777904510498, -0.030611485242843628, -0.0025979727506637573, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180565>
      [
        [0.04086941480636597, -0.055052727460861206, -0.03948777914047241, -0.02288515865802765, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180566>
      [
        [-0.06090943515300751, -0.04955203831195831, -0.0010215342044830322, ...],
        ...
      ]
    >
  },
  "dense_24" => %{
    "kernel" => #Nx.Tensor<
      f32[768][50257]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180617>
      [
        [-0.006909642834216356, -0.006121983751654625, 0.003781540784984827, -0.007170807104557753, -0.01045084185898304, ...],
        ...
      ]
    >
  },
  "dense_14" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180595>
      [0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180596>
      [
        [-0.03589756414294243, -0.0257802065461874, -0.03231015056371689, ...],
        ...
      ]
    >
  },
  "causal_attention_4" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180559>
      [
        [-0.004403740167617798, -0.012496992945671082, -0.050429508090019226, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180560>
      [
        [-0.0545945018529892, 0.005050212144851685, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180561>
      [
        [0.042504891753196716, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180562>
      [
        ...
      ]
    >
  },
  "normalization_10" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180637>
      [1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180638>
      [0.0, ...]
    >
  },
  "dense_7" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180626>
      [0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180627>
      [
        ...
      ]
    >
  },
  "normalization_22" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.4241110313.4077256728.180663>
      [...]
    >,
    ...
  },
  "causal_attention_2" => %{...},
  ...
}
```

**5.1.1 Using GPT to generate text**

Generating text involves encoding text into token IDs that the LLM processes into logit vectors. The
logit vectors are then converted back into token IDs, detokenized into a text representation.

```elixir
{:ok, input} = MyGPT.text_to_token_ids(tokenizer, "I know everything")
```

<!-- livebook:{"output":true} -->

```
{:ok,
 #Nx.Tensor<
   s64[1][3]
   [
     [40, 1440, 4395]
   ]
 >}
```

```elixir
# Nx data accessing example..
example = Nx.iota({2,3,4}) |> IO.inspect()
example[0][0][..]
example[[0,..,0]]
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3][4]
  [
    [
      [0, 1, 2, 3],
      [4, 5, 6, 7],
      [8, 9, 10, 11]
    ],
    [
      [12, 13, 14, 15],
      [16, 17, 18, 19],
      [20, 21, 22, 23]
    ]
  ]
>
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[3]
  [0, 4, 8]
>
```

```elixir
token_ids = MyGPT.generate_tokens(predict_fn, params, input, 6)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[1][9]
  EXLA.Backend<host:0, 0.4241110313.4077256728.180782>
  [
    [40, 1440, 4395, 49599, 49599, 49599, 49599, 49599, 49599]
  ]
>
```

```elixir
{:ok, text} = MyGPT.token_ids_to_text(tokenizer, token_ids)
IO.puts(text)
```

<!-- livebook:{"output":true} -->

```
I know everything/Desktop/Desktop/Desktop/Desktop/Desktop/Desktop
```

<!-- livebook:{"output":true} -->

```
:ok
```

**5.1.2 Calculating the text generation loss**

```elixir
texts = ["every effort moves", "I really like"]
inputs = MyGPT.text_to_token_ids(tokenizer, texts)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3]
  [
    [30115, 5149, 11031],
    [40, 2216, 1093]
  ]
>
```

```elixir
texts = [" effort moves you", " really like chocolate"]
targets = MyGPT.text_to_token_ids(tokenizer, texts)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3]
  [
    [5149, 11031, 499],
    [2216, 1093, 18414]
  ]
>
```

```elixir
# Predict next token
logits = predict_fn.(params, inputs)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][3][50257]
  EXLA.Backend<host:0, 0.4241110313.4077256728.180784>
  [
    [
      [-0.3024662435054779, 0.1065794825553894, 0.21984794735908508, 0.10435643047094345, -0.12580233812332153, -0.07861894369125366, -0.025969065725803375, -0.10180142521858215, 0.22475823760032654, -0.19456292688846588, -0.15361368656158447, -0.21066060662269592, -0.17144626379013062, -0.26952773332595825, -0.05540868267416954, -0.14063957333564758, 0.11485347151756287, 0.021454080939292908, 0.09094792604446411, 0.04267115890979767, 0.14798423647880554, -0.07881300151348114, 0.22647175192832947, -0.04798988997936249, -0.2008969932794571, 0.2875390648841858, -0.286720871925354, -0.20932987332344055, 0.32938969135284424, -0.27727434039115906, -0.20884019136428833, 0.3947686553001404, -0.23257248103618622, 0.17554175853729248, 0.13805244863033295, -0.0741996169090271, 0.04001861810684204, 0.04697423428297043, 0.03854319453239441, -0.26484620571136475, -0.13143672049045563, 0.3384990990161896, 0.008573025465011597, -0.12250800430774689, 0.1331934779882431, -0.08491745591163635, 0.290213942527771, -0.06398656219244003, -0.28733381628990173, 0.007627855986356735, ...],
      ...
    ],
    ...
  ]
>
```

```elixir
predicted_new_token =
  logits
  |> Axon.Layers.softmax(axis: -1)
  |> Nx.argmax(axis: -1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][3]
  EXLA.Backend<host:0, 0.4241110313.4077256728.180798>
  [
    [20748, 49599, 49599],
    [18790, 49599, 49599]
  ]
>
```

```elixir
{:ok, targets_text} = MyGPT.token_ids_to_text(tokenizer, targets[0])
{:ok, outputs_text} = MyGPT.token_ids_to_text(tokenizer, predicted_new_token[0])

IO.puts("Targets batch 1: #{targets_text}")
IO.puts("Outputs batch 1: #{outputs_text}")
```

<!-- livebook:{"output":true} -->

```
Targets batch 1:  effort moves you
Outputs batch 1:  emissions/Desktop/Desktop
```

<!-- livebook:{"output":true} -->

```
:ok
```

Before training, the model produces random next-token probability vectors. The goal of model training is to ensure that the probability values corresponding to the highlighted target token IDs are maximized.

```elixir
probas = Axon.Layers.softmax(logits, axis: -1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][3][50257]
  EXLA.Backend<host:0, 0.4241110313.4077256728.180808>
  [
    [
      [1.4499427379632834e-5, 2.1827154341735877e-5, 2.444494020892307e-5, 2.1778687369078398e-5, 1.730115218379069e-5, 1.813704329833854e-5, 1.911754225147888e-5, 1.772141877154354e-5, 2.4565268176957034e-5, 1.6151492673088796e-5, 1.6826612409204245e-5, 1.589357270859182e-5, 1.65292094607139e-5, 1.4984969311626628e-5, 1.856293238233775e-5, 1.7046346329152584e-5, 2.2008503947290592e-5, 2.004599809879437e-5, 2.1488616766873747e-5, 2.047585803666152e-5, 2.2749874915461987e-5, 1.813352355384268e-5, 2.4607399609521963e-5, 1.8701159206102602e-5, 1.6049511032178998e-5, 2.615693665575236e-5, 1.4729533177160192e-5, 1.5914736650302075e-5, 2.7274852982372977e-5, 1.4869334336253814e-5, 1.5922532838885672e-5, 2.9117636586306617e-5, 1.5549101590295322e-5, 2.338552258152049e-5, 2.2525046006194316e-5, 1.8217375327367336e-5, 2.0421617591637187e-5, 2.056415905826725e-5, 2.0391509679029696e-5, 1.5055286894494202e-5, 1.72039453900652e-5, 2.7524443794391118e-5, 1.978944055736065e-5, 1.7358241166220978e-5, 2.241586298623588e-5, 1.8023167285718955e-5, 2.6226998670608737e-5, 1.840438380895648e-5, 1.4720507351739798e-5, 1.97707431652816e-5, ...],
      ...
    ],
    ...
  ]
>
```

```elixir
t = Nx.iota({3, 1000}, type: :s64)
Nx.take_along_axis(t, Nx.tensor([[0], [0], [0]]), axis: 1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[3][1]
  [
    [0],
    [1000],
    [2000]
  ]
>
```

```elixir
text_index = 0
target_1 = Nx.reshape(targets[text_index], {3,1}) |> IO.inspect()
target_probas_1 = Nx.take_along_axis(probas[text_index], target_1, axis: 1) |> Nx.reshape({3})

text_index = 1
target_2 = Nx.reshape(targets[text_index], {3,1}) |> IO.inspect()
target_probas_2 = Nx.take_along_axis(probas[text_index], target_2, axis: 1) |> Nx.reshape({3})

IO.puts("Text 1: #{inspect(Nx.to_flat_list(target_probas_1))}")
IO.puts("Text 2: #{inspect(Nx.to_flat_list(target_probas_2))}")
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[3][1]
  [
    [5149],
    [11031],
    [499]
  ]
>
#Nx.Tensor<
  s64[3][1]
  [
    [2216],
    [1093],
    [18414]
  ]
>
Text 1: [2.2141335648484528e-5, 2.1825522708240896e-5, 2.063043757516425e-5]
Text 2: [2.504389703972265e-5, 2.343880078115035e-5, 2.654806485224981e-5]
```

<!-- livebook:{"output":true} -->

```
:ok
```

The goal of training an LLM is to maximize the likelihood of the correct token, which
involves increasing its probability relative to other tokens. This way, we ensure the
LLM consistently picks the target token essentially the next word in the sentence as the next token it generates.

Backpropagation requires a loss function, which calculates the difference between
the models predicted output (here, the probabilities corresponding to the target
token IDs) and the actual desired output. This loss function measures how far off the
models predictions are from the target values.

```elixir
# Working with logarithms of probability scores is more manageable in mathematical
# optimization than handling the scores directly.

log_probas =
  [target_probas_1, target_probas_2]
  |> Nx.concatenate()
  |> Nx.log()
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[6]
  EXLA.Backend<host:0, 0.4241110313.4077256728.180825>
  [-10.718064308166504, -10.732430458068848, -10.788743019104004, -10.594880104064941, -10.661117553710938, -10.536553382873535]
>
```

```elixir
avg_log_probas = Nx.mean(log_probas)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.4241110313.4077256728.180829>
  -10.671963691711426
>
```

```elixir
neg_avg_log_probas = Nx.multiply(avg_log_probas, -1)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.4241110313.4077256728.180831>
  10.671963691711426
>
```

The goal is to get the average log probability as close to 0 as possible by updating the
models weights as part of the training process.

However, the common practice isnt to push the average log probability up to 0 but rather to bring the
negative average log probability down to 0. The negative average log probability is
simply the average log probability multiplied by 1.

In deep learning, the term for turning this negative value, is known as cross entropy loss.

The cross entropy loss is popular measure in machine learning and deep learning that measures the difference between two probability distribution.

```elixir
IO.inspect(logits.shape, label: "Logits shape:")
IO.inspect(targets.shape, label: "Targets shape:")
```

<!-- livebook:{"output":true} -->

```
Logits shape:: {2, 3, 50257}
Targets shape:: {2, 3}
```

<!-- livebook:{"output":true} -->

```
{2, 3}
```

```elixir
logits_flat = Nx.flatten(logits, axes: [0,1])
targets_flat = Nx.flatten(targets)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[6]
  [5149, 11031, 499, 2216, 1093, 18414]
>
```

```elixir
IO.inspect(logits_flat.shape, label: "Flatten Logits shape:")
IO.inspect(targets_flat.shape, label: "Flatten Targets shape:")
```

<!-- livebook:{"output":true} -->

```
Flatten Logits shape:: {6, 50257}
Flatten Targets shape:: {6}
```

<!-- livebook:{"output":true} -->

```
{6}
```

```elixir
y_true = Nx.tensor([0, 2, 1])
y_pred = Nx.tensor([[0.2, 0.8, 0.0], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7]])
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[3][3]
  [
    [0.20000000298023224, 0.800000011920929, 0.0],
    [0.10000000149011612, 0.20000000298023224, 0.699999988079071],
    [0.10000000149011612, 0.20000000298023224, 0.699999988079071]
  ]
>
```

```elixir
loss = Axon.Losses.categorical_cross_entropy(
  targets_flat, logits_flat, reduction: :mean, from_logits: true, sparse: true)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.4241110313.4077256728.180855>
  10.671965599060059
>
```

**Perplexity**

Perplexity is a measure often used alongside cross entropy loss to evaluate the performance of models in tasks like language modeling. It can provide a more interpretable way to understand the uncertainty of a model in predicting the next token in a
sequence.

Perplexity measures how well the probability distribution predicted by the model
matches the actual distribution of the words in the dataset. Similar to the loss, a lower
perplexity indicates that the model predictions are closer to the actual distribution.

Perplexity is often considered more interpretable than the raw loss value because it signifies the effective vocabulary size about which the model is uncertain at each step. In
the given example, this would translate to the model being unsure about which among
48,725 tokens in the vocabulary to generate as the next token.

```elixir
perplexity = Nx.exp(loss)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32
  EXLA.Backend<host:0, 0.4241110313.4077256728.180857>
  43129.6328125
>
```

**5.1.3 Calculating the training and validation set losses**

```elixir
path = 
  "/home/alde/Documents/MyDevelopment/Build_A_Large_Language_Model/the-verdict.txt"
{:ok, raw_text} = File.read(path)
```

<!-- livebook:{"output":true} -->

```
{:ok,
 "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n\n\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it's going to send the value of my picture 'way up; but I don't think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing's lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn's \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\n\nWell!--even through the prism of Hermia's tears I felt able to face the fact with equanimity. Poor Jack Gisburn! The women had made him--it was fitting that they should mourn him. Among his own sex fewer regrets were heard, and in his own trade hardly a murmur. Professional jealousy? Perhaps. If it were, the honour of the craft was vindicated by little Claude Nutley, who, in all good faith, brought out in the Burlington a very handsome \"obituary\" on Jack--one of those showy articles stocked with random technicalities that I have heard (I won't say by whom) compared to Gisburn's painting. And so--his resolve being apparently irrevocable--the discussion gradually died out, and, as Mrs. Thwing had predicted, the price of \"Gisburns\" went up.\n\nIt was not till three years later that, in the course of a few weeks' idling on the Riviera, it suddenly occurred to me to wonder why Gisburn had given up his painting. On reflection, it really was a tempting problem. To accuse his wife would have been too easy--his fair sitters had been denied the solace of saying that Mrs. Gisburn had \"dragged him down.\" For Mrs. Gisburn--as such--had not existed till nearly a year after Jack's resolve had been taken. It might be that he had married her--since he liked his ease--because he didn't want to go on painting; but it would have been hard to prove that he had given up his painting because he had married her.\n\nOf course, if she had not dragged him down, she had equally, as Miss Croft contended, failed to \"lift him up\"--she had not led him back to the easel. To put the brush into his hand again--what a vocation for a wife! But Mrs. Gisburn appeared to have disdained it--and I felt it might be interesting to find out why.\n\nThe desultory life of the Riviera lends itself to such purely academic speculations; and having, on my way to Monte Carlo, caught a glimpse of Jack's balustraded terraces between the pines, I had myself borne thither the next day.\n\nI found the couple at tea beneath their palm-trees; and Mrs. Gisburn's welcome was so genial that, in the ensuing weeks, I claimed it frequently. It was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. It was just because she was _not_ interesting--if I may be pardoned the bull--that I found her so. For Jack, all his life, had been surrounded by interesting women: they had fostered his art, it had been reared in the hot-house of their adulation. And it was therefore instructive to note what effect the \"deadening atmosphere of mediocrity\" (I quote Miss Croft) was having on him.\n\nI have mentioned that Mrs. Gisburn was rich; and it was immediately perceptible that her husband was extracting from this circumstance a delicate but substantial satisfaction. It is, as a rule, the people who scorn money who get most out of it; and Jack's elegant disdain of his wife's big balance enabled him, with an appearance of perfect good-breeding, to transmute it into objects of art and luxury. To the latter, I must add, he remained relatively indifferent; but he was buying Renaissance bronzes and eight" <> ...}
```

```elixir
{:ok, ids} = Tiktoken.encode(tokenizer, raw_text)
```

<!-- livebook:{"output":true} -->

```
{:ok,
 [40, 473, 1846, 2744, 3463, 7762, 480, 285, 22464, 4856, 264, 12136, 35201, 313, 4636, 264, 1695,
  12637, 3403, 313, 708, 433, 574, 912, 2294, 13051, 311, 757, 311, 6865, 430, 11, 304, 279, 2673,
  315, 813, 27025, 11, 568, 1047, 12504, 813, 19354, 11, 12502, 264, 9257, ...]}
```

```elixir
String.length(raw_text) |> IO.inspect(label: "Characters")
Enum.count(ids) |> IO.inspect(label: "Tokens")
```

<!-- livebook:{"output":true} -->

```
Characters: 20479
Tokens: 4943
```

<!-- livebook:{"output":true} -->

```
4943
```

When preparing the data loaders, we split the input text into training and validation set portions. Then we tokenize the text and divide the tokenized text into
chunks of a user-specified length. Finally, we shuffle the rows and organize the chunked text into batches, which we can use for model training

```elixir
train_ratio = 0.90

split_index = floor(train_ratio * String.length(raw_text))

{train_data, validation_data} = String.split_at(raw_text, split_index)

String.length(train_data) |> IO.inspect(label: "Train Characters")
String.length(validation_data) |> IO.inspect(label: "Validation Characters")
```

<!-- livebook:{"output":true} -->

```
Train Characters: 18431
Validation Characters: 2048
```

<!-- livebook:{"output":true} -->

```
2048
```

We split the input text into training and validation set portions. Then
we tokenize the text and divide the tokenized text into
chunks of a user-specified length. Finally, we shuffle the rows and organize the chunked text into batches, which we can use for model training.

However, in practice, it can also be
beneficial to train an LLM with variable-length inputs to help the LLM to better generalize across different types of inputs when it is being used.

```elixir
defmodule MyGPT.DatasetV1 do
  def build(txt, tokenizer_model, max_length, stride) do
    {:ok, token_ids} = Tiktoken.encode(tokenizer_model, txt)

    token_ids_tensor = Nx.tensor(token_ids)
    text_length = length(token_ids)

    linespace =
      Enum.to_list(0..(length(token_ids) - max_length - 1)) |> Enum.take_every(stride)

    for i <- linespace, reduce: %{input_ids: [], target_ids: []} do
      %{input_ids: input_ids, target_ids: target_ids} = acc ->

        
        {input_ids, target_ids} =
          cond do
            i + max_length > text_length - 1 ->
              {input_ids, target_ids}

            i + max_length + 1 > text_length - 1 ->
              {input_ids, target_ids}

            true ->
              input_chunk = token_ids_tensor[i..(i + max_length - 1)]
              target_chunk = token_ids_tensor[(i + 1)..(i + max_length)]
              {input_ids ++ [input_chunk], target_ids ++ [target_chunk]}
          end

        %{acc | input_ids: input_ids, target_ids: target_ids}
    end
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, MyGPT.DatasetV1, <<70, 79, 82, 49, 0, 0, 12, ...>>, {:build, 4}}
```

```elixir
context_length = gpt_config_124m[:context_length]
train_dataset = MyGPT.DatasetV1.build(train_data, tokenizer, context_length, context_length)
validation_dataset = MyGPT.DatasetV1.build(validation_data, tokenizer, context_length, context_length)
```

<!-- livebook:{"output":true} -->

```
%{
  input_ids: [
    #Nx.Tensor<
      s64[256]
      [361, 6, 29368, 1093, 264, 3838, 315, 7563, 13, 1283, 3287, 956, 21423, 261, 11, 499, 3619, 11, 8009, 4610, 3023, 313, 383, 1120, 11203, 1070, 30666, 10307, 11, 323, 389, 813, 23726, 11, 1555, 279, 18004, 48788, 11, 358, 9508, 311, 6865, 279, 3488, 25, 364, 11787, ...]
    >,
    #Nx.Tensor<
      s64[256]
      [364, 10655, 6, 555, 1063, 832, 1501, 88, 0, 2468, 1176, 358, 574, 16984, 1364, 8434, 956, 1095, 757, 1022, 313, 438, 520, 856, 289, 1220, 6, 842, 358, 12090, 2895, 58863, 13, 7566, 11, 433, 574, 358, 889, 3940, 2895, 58863, 25, 358, 3309, 18083, 13, ...]
    >
  ],
  target_ids: [
    #Nx.Tensor<
      s64[256]
      [6, 29368, 1093, 264, 3838, 315, 7563, 13, 1283, 3287, 956, 21423, 261, 11, 499, 3619, 11, 8009, 4610, 3023, 313, 383, 1120, 11203, 1070, 30666, 10307, 11, 323, 389, 813, 23726, 11, 1555, 279, 18004, 48788, 11, 358, 9508, 311, 6865, 279, 3488, 25, 364, 11787, ...]
    >,
    #Nx.Tensor<
      s64[256]
      [10655, 6, 555, 1063, 832, 1501, 88, 0, 2468, 1176, 358, 574, 16984, 1364, 8434, 956, 1095, 757, 1022, 313, 438, 520, 856, 289, 1220, 6, 842, 358, 12090, 2895, 58863, 13, 7566, 11, 433, 574, 358, 889, 3940, 2895, 58863, 25, 358, 3309, 18083, 13, ...]
    >
  ]
}
```

```elixir
input_ids = Nx.stack(train_dataset[:input_ids])
target_ids = Nx.stack(train_dataset[:target_ids])

{input_ids[0], target_ids[0]}
```

<!-- livebook:{"output":true} -->

```
{#Nx.Tensor<
   s64[256]
   [40, 473, 1846, 2744, 3463, 7762, 480, 285, 22464, 4856, 264, 12136, 35201, 313, 4636, 264, 1695, 12637, 3403, 313, 708, 433, 574, 912, 2294, 13051, 311, 757, 311, 6865, 430, 11, 304, 279, 2673, 315, 813, 27025, 11, 568, 1047, 12504, 813, 19354, 11, 12502, 264, 9257, 57896, ...]
 >,
 #Nx.Tensor<
   s64[256]
   [473, 1846, 2744, 3463, 7762, 480, 285, 22464, 4856, 264, 12136, 35201, 313, 4636, 264, 1695, 12637, 3403, 313, 708, 433, 574, 912, 2294, 13051, 311, 757, 311, 6865, 430, 11, 304, 279, 2673, 315, 813, 27025, 11, 568, 1047, 12504, 813, 19354, 11, 12502, 264, 9257, 57896, ...]
 >}
```

```elixir
v_input_ids = Nx.stack(validation_dataset[:input_ids])
v_target_ids = Nx.stack(validation_dataset[:target_ids])

{v_input_ids[0], v_target_ids[0]}
```

<!-- livebook:{"output":true} -->

```
{#Nx.Tensor<
   s64[256]
   [361, 6, 29368, 1093, 264, 3838, 315, 7563, 13, 1283, 3287, 956, 21423, 261, 11, 499, 3619, 11, 8009, 4610, 3023, 313, 383, 1120, 11203, 1070, 30666, 10307, 11, 323, 389, 813, 23726, 11, 1555, 279, 18004, 48788, 11, 358, 9508, 311, 6865, 279, 3488, 25, 364, 11787, 499, ...]
 >,
 #Nx.Tensor<
   s64[256]
   [6, 29368, 1093, 264, 3838, 315, 7563, 13, 1283, 3287, 956, 21423, 261, 11, 499, 3619, 11, 8009, 4610, 3023, 313, 383, 1120, 11203, 1070, 30666, 10307, 11, 323, 389, 813, 23726, 11, 1555, 279, 18004, 48788, 11, 358, 9508, 311, 6865, 279, 3488, 25, 364, 11787, 499, ...]
 >}
```

```elixir
stream = Nx.to_batched(input_ids, 1)
x = Enum.at(stream, 0)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[1][256]
  [
    [40, 473, 1846, 2744, 3463, 7762, 480, 285, 22464, 4856, 264, 12136, 35201, 313, 4636, 264, 1695, 12637, 3403, 313, 708, 433, 574, 912, 2294, 13051, 311, 757, 311, 6865, 430, 11, 304, 279, 2673, 315, 813, 27025, 11, 568, 1047, 12504, 813, 19354, 11, 12502, 264, 9257, 57896, 11, ...]
  ]
>
```

```elixir
defmodule MyGPT.Dataset do
  def build(txt, tokenizer_model, max_length, stride, batch_size \\ 2, is_shuffle? \\ true) do
    {:ok, token_ids} = Tiktoken.encode(tokenizer_model, txt)

    token_ids_tensor = Nx.tensor(token_ids)
    text_length = length(token_ids)

    linespace =
      Enum.to_list(0..(length(token_ids) - max_length - 1)) |> Enum.take_every(stride)

    %{input_ids: input_ids, target_ids: target_ids} =
      for i <- linespace, reduce: %{input_ids: [], target_ids: []} do
        %{input_ids: input_ids, target_ids: target_ids} = acc ->
          {input_ids, target_ids} =
            cond do
              i + max_length > text_length - 1 ->
                {input_ids, target_ids}

              i + max_length + 1 > text_length - 1 ->
                {input_ids, target_ids}

              true ->
                input_chunk = token_ids_tensor[i..(i + max_length - 1)]
                target_chunk = token_ids_tensor[(i + 1)..(i + max_length)]
                {input_ids ++ [input_chunk], target_ids ++ [target_chunk]}
            end

          %{acc | input_ids: input_ids, target_ids: target_ids}
      end

    {shuffled_input_ids, shuffled_target_ids} =
      try_shuffle_datasets(input_ids, target_ids, is_shuffle?)

    input_ids_stream =
      shuffled_input_ids
      |> Nx.stack()
      |> Nx.to_batched(batch_size)

    target_ids_stream =
      shuffled_target_ids
      |> Nx.stack()
      |> Nx.to_batched(batch_size)

    Stream.zip(input_ids_stream, target_ids_stream)
  end

  def try_shuffle_datasets(input_ids, target_ids, true) do
    Enum.zip(input_ids, target_ids)
    |> Enum.shuffle()
    |> Enum.unzip()
  end

  def try_shuffle_datasets(input_ids, target_ids, _is_shuffle?) do
    {input_ids, target_ids}
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, MyGPT.Dataset, <<70, 79, 82, 49, 0, 0, 17, ...>>, {:try_shuffle_datasets, 3}}
```

```elixir
context_length = gpt_config_124m[:context_length]

training_dataset =
  MyGPT.Dataset.build(train_data, tokenizer, context_length, context_length)

validation_dataset =
  MyGPT.Dataset.build(validation_data, tokenizer, context_length, context_length)
```

<!-- livebook:{"output":true} -->

```
#Function<73.53678557/2 in Stream.zip_with/2>
```

```elixir
Enum.at(training_dataset, 0)
```

<!-- livebook:{"output":true} -->

```
{#Nx.Tensor<
   s64[2][256]
   [
     [12657, 1604, 300, 11, 15753, 459, 6916, 79781, 3201, 11, 323, 1071, 25, 330, 2746, 499, 2559, 1618, 499, 649, 1120, 10299, 311, 1518, 433, 13, 358, 1047, 433, 927, 279, 26976, 301, 56964, 11, 719, 568, 8434, 956, 1095, 433, 4822, 2266, 9642, 313, 40, 1436, 1120, 10299, ...],
     ...
   ]
 >,
 #Nx.Tensor<
   s64[2][256]
   [
     [1604, 300, 11, 15753, 459, 6916, 79781, 3201, 11, 323, 1071, 25, 330, 2746, 499, 2559, 1618, 499, 649, 1120, 10299, 311, 1518, 433, 13, 358, 1047, 433, 927, 279, 26976, 301, 56964, 11, 719, 568, 8434, 956, 1095, 433, 4822, 2266, 9642, 313, 40, 1436, 1120, 10299, ...],
     ...
   ]
 >}
```

We used a relatively small batch size to reduce the computational resource demand
because we were working with a very small dataset. In practice, training LLMs with
batch sizes of 1,024 or larger is not uncommon.
