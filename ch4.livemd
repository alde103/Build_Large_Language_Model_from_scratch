<!-- livebook:{"persist_outputs":true} -->

# Chapter 4: Implementing a GPT model from scratch to generate text

```elixir
Mix.install([
  {:nx, "~> 0.5"},
  {:exla, "~> 0.5"},
  {:axon, "~> 0.5"},
  {:tiktoken, "~> 0.3.2"},
  {:table_rex, "~> 3.1.1"},
  {:kino_vega_lite, "~> 0.1.11"}
])
```

## 4.1 Coding an LLM architecture

LLMs, such as GPT (which stands for generative pretrained transformer), are large deep neural network architectures designed to generate new text one word (or token) at a time.

In the context of deep learning and LLMs like GPT, the term “parameters” refers
to the trainable weights of the model. These weights are essentially the internal variables of the model that are adjusted and optimized during the training process to
minimize a specific loss function. This optimization allows the model to learn from
the training data.

```elixir
gpt_config_124m = [
  attn_name: "attention_0",
  vocab_size: 50257,
  context_length: 1024,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0.1,
  qkv_bias: false
]
```

<!-- livebook:{"output":true} -->

```
[
  attn_name: "attention_0",
  vocab_size: 50257,
  context_length: 1024,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0.1,
  qkv_bias: false
]
```

```elixir
defmodule DummyGPTModel do
  def model(config \\ []) do
    Axon.input("sequence")
    |> Axon.embedding(config[:vocab_size], config[:emb_dim])
    |> Axon.embedding(config[:context_length], config[:emb_dim])
    |> Axon.dropout(rate: config[:drop_rate])
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, DummyGPTModel, <<70, 79, 82, 49, 0, 0, 8, ...>>, {:model, 1}}
```

```elixir
txt1 = "Every effort moves you"
txt2 = "Every day holds a"

# gpt2 not supported
{:ok, ids1} = Tiktoken.encode("gpt-3.5-turbo", txt1, [])
{:ok, ids2} = Tiktoken.encode("gpt-3.5-turbo", txt2, [])

tensors = Enum.map([ids1, ids2], &Nx.tensor/1)
Nx.stack(tensors)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][4]
  [
    [11769, 5149, 11031, 499],
    [11769, 1938, 10187, 264]
  ]
>
```

```elixir
batch = Nx.tensor([[6109, 3629, 6100, 345], [6109, 1110, 6622, 257]])
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][4]
  [
    [6109, 3629, 6100, 345],
    [6109, 1110, 6622, 257]
  ]
>
```

The model outputs, which are commonly referred to as logits.

## 4.2 Normalizing activations with layer normalization

Training deep neural networks with many layers can sometimes prove challenging
due to problems like vanishing or exploding gradients. These problems lead to unstable training dynamics and make it difficult for the network to effectively adjust its
weights, which means the learning process struggles to find a set of parameters
(weights) for the neural network that minimizes the loss function.

```elixir
key = Nx.Random.key(123)
Nx.Random.normal(key, shape: {2, 5}) |> IO.inspect()

batch_example =
  Nx.tensor([
    [-0.1115, 0.1204, -0.3696, -0.2404, -1.1969],
    [0.2093, -0.9724, -0.7550, 0.3239, -0.1085]
  ])
```

<!-- livebook:{"output":true} -->

```
{#Nx.Tensor<
   f32[2][5]
   [
     [-0.5154414772987366, -0.8975640535354614, 1.9826834201812744, -1.9789758920669556, -2.8818085193634033],
     [-0.6626349687576294, -0.03326578065752983, -0.1879543960094452, -0.6107876896858215, 0.16164331138134003]
   ]
 >,
 #Nx.Tensor<
   u32[2]
   [1896456402, 17229315]
 >}
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][5]
  [
    [-0.11150000244379044, 0.12039999663829803, -0.36959999799728394, -0.24040000140666962, -1.1969000101089478],
    [0.2092999964952469, -0.9724000096321106, -0.7549999952316284, 0.3239000141620636, -0.10849999636411667]
  ]
>
```

```elixir
model =
  Axon.input("input", shape: {nil, 5})
  |> Axon.dense(6)
  |> Axon.activation(:relu)

{init_fn, predict_fn} = Axon.build(model)
template = Nx.template({1, 5}, :f32)
params = init_fn.(template, %{})
result = predict_fn.(params, batch_example) 
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][6]
  [
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.4176269769668579],
    [0.0, 0.0, 0.3234621286392212, 0.22247157990932465, 0.0, 0.15489087998867035]
  ]
>
```

```elixir
Nx.mean(result, axes: [-1], keep_axes: true) |> IO.inspect(label: "Variance")
Nx.variance(result, axes: [-1], keep_axes: true) |> IO.inspect(label: "Variance")
```

<!-- livebook:{"output":true} -->

```
Variance: #Nx.Tensor<
  f32[2][1]
  [
    [0.06960449367761612],
    [0.1168041005730629]
  ]
>
Variance: #Nx.Tensor<
  f32[2][1]
  [
    [0.0242239311337471],
    [0.016042226925492287]
  ]
>
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][1]
  [
    [0.0242239311337471],
    [0.016042226925492287]
  ]
>
```

```elixir
Nx.add(1, Nx.tensor([1,2]))
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2]
  [2, 3]
>
```

```elixir
defmodule TransformerLayers.Norm do
  import Nx.Defn

  def normalization(%Axon{} = input, opts \\ []) do
    opts = Keyword.validate!(opts, [:name, :eps, :emb_dim])
    eps = Keyword.get(opts, :eps, 1.00e-5)
    scale = Axon.param("scale", {opts[:emb_dim]}, initializer: &ones(&1, type: &2))
    shift = Axon.param("shift", {opts[:emb_dim]}, initializer: &zeros(&1, type: &2))

    Axon.layer(
      &normalization_impl/4,
      [input, scale, shift],
      name: opts[:name],
      op_name: :normalization,
      eps: eps
    )
  end

  defp ones(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(1)
  end

  defp zeros(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(0)
  end

  defnp normalization_impl(input, scale, shift, opts \\ []) do
    mean = Nx.mean(input, axes: [-1], keep_axes: true)
    variance = Nx.variance(input, axes: [-1], keep_axes: true)
    denominator = variance |> Nx.add(opts[:eps]) |> Nx.sqrt()

    input
    |> Nx.subtract(mean)
    |> Nx.divide(denominator)
    |> Nx.multiply(scale)
    |> Nx.add(shift)
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, TransformerLayers.Norm, <<70, 79, 82, 49, 0, 0, 18, ...>>, true}
```

The variable `eps` is a small constant (epsilon) added to the variance to prevent division by zero
during normalization. The `scale` and `shift` are two trainable parameters (of the same dimension as the input) that the LLM automatically adjusts during training if it is determined that doing so would improve the model’s performance on its training task. This allows the model to learn appropriate scaling and shifting that best suit the data it is processing.

```elixir
model =
  Axon.input("input", shape: {nil, 5})
  |> Axon.dense(6)
  |> Axon.activation(:relu)
  |> TransformerLayers.Norm.normalization(emb_dim: 6, name: "norm")

{init_fn, predict_fn} = Axon.build(model)
template = Nx.template({1, 5}, :f32)
params = init_fn.(template, %{})
result = predict_fn.(params, batch_example) 
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][6]
  [
    [-0.8434630632400513, -0.5189403295516968, 1.1763477325439453, -0.8434630632400513, -0.5791576504707336, 1.6086761951446533],
    [1.720658540725708, -1.0076634883880615, -0.13643784821033478, -0.4525851309299469, -1.0076634883880615, 0.883691668510437]
  ]
>
```

```elixir
Nx.mean(result, axes: [-1], keep_axes: true) |> IO.inspect(label: "Variance")
Nx.variance(result, axes: [-1], keep_axes: true) |> IO.inspect(label: "Variance")
```

<!-- livebook:{"output":true} -->

```
Variance: #Nx.Tensor<
  f32[2][1]
  [
    [-2.9802322387695312e-8],
    [4.22199555316638e-8]
  ]
>
Variance: #Nx.Tensor<
  f32[2][1]
  [
    [0.9998692870140076],
    [0.9992994666099548]
  ]
>
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][1]
  [
    [0.9998692870140076],
    [0.9992994666099548]
  ]
>
```

```elixir
model =
  Axon.input("input", shape: {nil, 5})
  |> TransformerLayers.Norm.normalization(emb_dim: 5, name: "norm")

{init_fn, predict_fn} = Axon.build(model)
template = Nx.template({1, 5}, :f32)
params = init_fn.(template, %{})
result = predict_fn.(params, batch_example) 
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][5]
  [
    [0.5527316331863403, 1.0693719387054443, -0.02227856032550335, 0.26556071639060974, -1.86538565158844],
    [0.9086875319480896, -1.3767629861831665, -0.9563034772872925, 1.1303280591964722, 0.2940508723258972]
  ]
>
```

```elixir
Nx.mean(result, axes: [-1], keep_axes: true) |> IO.inspect(label: "Variance")
Nx.variance(result, axes: [-1], keep_axes: true) |> IO.inspect(label: "Variance")
```

<!-- livebook:{"output":true} -->

```
Variance: #Nx.Tensor<
  f32[2][1]
  [
    [1.527368986842248e-8],
    [0.0]
  ]
>
Variance: #Nx.Tensor<
  f32[2][1]
  [
    [0.9999502301216125],
    [0.9999626278877258]
  ]
>
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][1]
  [
    [0.9999502301216125],
    [0.9999626278877258]
  ]
>
```

## 4.3 Implementing a feed forward networkwith GELU activations

Historically, the ReLU activation function has been commonly used in deep learning
due to its simplicity and effectiveness across various neural network architectures.
However, in LLMs, several other activation functions are employed beyond the traditional ReLU. Two notable examples are GELU (Gaussian error linear unit) and SwiGLU
(Swish-gated linear unit).

GELU and SwiGLU are more complex and smooth activation functions incorporating Gaussian and sigmoid-gated linear units, respectively. They offer improved performance for deep learning models, unlike the simpler ReLU.

The GELU activation function can be implemented in several ways; the exact version is defined as GELU(x) = x⋅Φ(x), where Φ(x) is the cumulative distribution function of the standard Gaussian distribution.

```elixir
x = Nx.linspace(-3, 3, n: 100) 
y_gelu = Axon.Activations.gelu(x) |> Nx.to_flat_list
y_relu = Axon.Activations.relu(x) |> Nx.to_flat_list
x = Nx.to_flat_list(x)
```

<!-- livebook:{"output":true} -->

```
[-3.0, -2.939393997192383, -2.8787879943847656, -2.8181817531585693, -2.757575750350952,
 -2.696969747543335, -2.6363635063171387, -2.5757575035095215, -2.5151515007019043,
 -2.454545497894287, -2.39393949508667, -2.3333332538604736, -2.2727272510528564,
 -2.2121212482452393, -2.151515007019043, -2.090909004211426, -2.0303030014038086,
 -1.9696969985961914, -1.9090908765792847, -1.848484754562378, -1.7878787517547607,
 -1.7272727489471436, -1.6666666269302368, -1.60606050491333, -1.545454502105713,
 -1.4848484992980957, -1.424242377281189, -1.3636362552642822, -1.303030252456665,
 -1.2424242496490479, -1.1818181276321411, -1.1212120056152344, -1.0606060028076172, -1.0,
 -0.9393939971923828, -0.8787877559661865, -0.8181817531585693, -0.7575757503509521,
 -0.6969695091247559, -0.6363635063171387, -0.5757575035095215, -0.5151515007019043,
 -0.4545454978942871, -0.3939392566680908, -0.33333325386047363, -0.27272725105285645,
 -0.21212100982666016, -0.15151500701904297, -0.09090900421142578, -0.030303001403808594, ...]
```

```elixir
alias VegaLite, as: Vl
Vl.new(title: "GeLU vs ReLU", width: 400, height: 400)
|> Vl.data_from_values(x: x, relu: y_relu, gelu: y_gelu)
#|> Vl.mark(:line)

|> Vl.layers([
  Vl.new()
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "x", type: :quantitative)
  |> Vl.encode_field(:y, "relu", type: :quantitative),
  Vl.new()
  |> Vl.mark(:line)
  |> Vl.encode(:color, value: "#db646f")
  |> Vl.encode_field(:x, "x", type: :quantitative)
  |> Vl.encode_field(:y, "gelu", type: :quantitative)
])
```

<!-- livebook:{"output":true} -->

```vega-lite
{"$schema":"https://vega.github.io/schema/vega-lite/v5.json","data":{"values":[{"gelu":-0.0040496885776519775,"relu":0.0,"x":-3.0},{"gelu":-0.004833197221159935,"relu":0.0,"x":-2.939393997192383},{"gelu":-0.005746176932007074,"relu":0.0,"x":-2.8787879943847656},{"gelu":-0.006805408746004105,"relu":0.0,"x":-2.8181817531585693},{"gelu":-0.008028950542211533,"relu":0.0,"x":-2.757575750350952},{"gelu":-0.009435816667973995,"relu":0.0,"x":-2.696969747543335},{"gelu":-0.011046357452869415,"relu":0.0,"x":-2.6363635063171387},{"gelu":-0.012881461530923843,"relu":0.0,"x":-2.5757575035095215},{"gelu":-0.014962762594223022,"relu":0.0,"x":-2.5151515007019043},{"gelu":-0.017312245443463326,"relu":0.0,"x":-2.454545497894287},{"gelu":-0.01995168812572956,"relu":0.0,"x":-2.39393949508667},{"gelu":-0.02290244773030281,"relu":0.0,"x":-2.3333332538604736},{"gelu":-0.026184793561697006,"relu":0.0,"x":-2.2727272510528564},{"gelu":-0.029817499220371246,"relu":0.0,"x":-2.2121212482452393},{"gelu":-0.033817026764154434,"relu":0.0,"x":-2.151515007019043},{"gelu":-0.038196951150894165,"relu":0.0,"x":-2.090909004211426},{"gelu":-0.04296703264117241,"relu":0.0,"x":-2.0303030014038086},{"gelu":-0.048132624477148056,"relu":0.0,"x":-1.9696969985961914},{"gelu":-0.05369355529546738,"relu":0.0,"x":-1.9090908765792847},{"gelu":-0.05964341387152672,"relu":0.0,"x":-1.848484754562378},{"gelu":-0.06596875190734863,"relu":0.0,"x":-1.7878787517547607},{"gelu":-0.07264793664216995,"relu":0.0,"x":-1.7272727489471436},{"gelu":-0.07965058088302612,"relu":0.0,"x":-1.6666666269302368},{"gelu":-0.08693656325340271,"relu":0.0,"x":-1.60606050491333},{"gelu":-0.09445537626743317,"relu":0.0,"x":-1.545454502105713},{"gelu":-0.10214567929506302,"relu":0.0,"x":-1.4848484992980957},{"gelu":-0.10993465781211853,"relu":0.0,"x":-1.424242377281189},{"gelu":-0.1177377924323082,"relu":0.0,"x":-1.3636362552642822},{"gelu":-0.12545864284038544,"relu":0.0,"x":-1.303030252456665},{"gelu":-0.13298910856246948,"relu":0.0,"x":-1.2424242496490479},{"gelu":-0.1402096450328827,"relu":0.0,"x":-1.1818181276321411},{"gelu":-0.14698955416679382,"relu":0.0,"x":-1.1212120056152344},{"gelu":-0.1531880795955658,"relu":0.0,"x":-1.0606060028076172},{"gelu":-0.15865525603294373,"relu":0.0,"x":-1.0},{"gelu":-0.16323310136795044,"relu":0.0,"x":-0.9393939971923828},{"gelu":-0.16675716638565063,"relu":0.0,"x":-0.8787877559661865},{"gelu":-0.1690582036972046,"relu":0.0,"x":-0.8181817531585693},{"gelu":-0.169964000582695,"relu":0.0,"x":-0.7575757503509521},{"gelu":-0.16930150985717773,"relu":0.0,"x":-0.6969695091247559},{"gelu":-0.1668989062309265,"relu":0.0,"x":-0.6363635063171387},{"gelu":-0.16258789598941803,"relu":0.0,"x":-0.5757575035095215},{"gelu":-0.15620608627796173,"relu":0.0,"x":-0.5151515007019043},{"gelu":-0.14759916067123413,"relu":0.0,"x":-0.4545454978942871},{"gelu":-0.13662324845790863,"relu":0.0,"x":-0.3939392566680908},{"gelu":-0.12314710021018982,"relu":0.0,"x":-0.33333325386047363},{"gelu":-0.10705402493476868,"relu":0.0,"x":-0.27272725105285645},{"gelu":-0.08824368566274643,"relu":0.0,"x":-0.21212100982666016},{"gelu":-0.06663398444652557,"relu":0.0,"x":-0.15151500701904297},{"gelu":-0.04216200113296509,"relu":0.0,"x":-0.09090900421142578},{"gelu":-0.0147852199152112,"relu":0.0,"x":-0.030303001403808594},{"gelu":0.015517781488597393,"relu":0.030303001403808594,"x":0.030303001403808594},{"gelu":0.04874713718891144,"relu":0.09090924263000488,"x":0.09090924263000488},{"gelu":0.08488116413354874,"relu":0.15151524543762207,"x":0.15151524543762207},{"gelu":0.12387749552726746,"relu":0.21212124824523926,"x":0.21212124824523926},{"gelu":0.1656734049320221,"relu":0.27272748947143555,"x":0.27272748947143555},{"gelu":0.21018634736537933,"relu":0.33333349227905273,"x":0.33333349227905273},{"gelu":0.2573162317276001,"relu":0.3939394950866699,"x":0.3939394950866699},{"gelu":0.306946337223053,"relu":0.4545454978942871,"x":0.4545454978942871},{"gelu":0.35894539952278137,"relu":0.5151515007019043,"x":0.5151515007019043},{"gelu":0.41316983103752136,"relu":0.5757577419281006,"x":0.5757577419281006},{"gelu":0.46946483850479126,"relu":0.6363637447357178,"x":0.6363637447357178},{"gelu":0.5276682376861572,"relu":0.696969747543335,"x":0.696969747543335},{"gelu":0.587611973285675,"relu":0.7575759887695312,"x":0.7575759887695312},{"gelu":0.6491237878799438,"relu":0.8181819915771484,"x":0.8181819915771484},{"gelu":0.712030827999115,"relu":0.8787879943847656,"x":0.8787879943847656},{"gelu":0.7761608958244324,"relu":0.9393939971923828,"x":0.9393939971923828},{"gelu":0.8413447141647339,"relu":1.0,"x":1.0},{"gelu":0.9074179530143738,"relu":1.0606060028076172,"x":1.0606060028076172},{"gelu":0.9742224216461182,"relu":1.1212120056152344,"x":1.1212120056152344},{"gelu":1.0416089296340942,"relu":1.1818184852600098,"x":1.1818184852600098},{"gelu":1.1094354391098022,"relu":1.242424488067627,"x":1.242424488067627},{"gelu":1.1775718927383423,"relu":1.3030304908752441,"x":1.3030304908752441},{"gelu":1.245898723602295,"relu":1.3636364936828613,"x":1.3636364936828613},{"gelu":1.3143079280853271,"relu":1.4242424964904785,"x":1.4242424964904785},{"gelu":1.3827028274536133,"relu":1.4848484992980957,"x":1.4848484992980957},{"gelu":1.450999140739441,"relu":1.545454502105713,"x":1.545454502105713},{"gelu":1.5191245079040527,"relu":1.6060609817504883,"x":1.6060609817504883},{"gelu":1.5870164632797241,"relu":1.6666669845581055,"x":1.6666669845581055},{"gelu":1.6546250581741333,"relu":1.7272729873657227,"x":1.7272729873657227},{"gelu":1.7219102382659912,"relu":1.7878789901733398,"x":1.7878789901733398},{"gelu":1.7888414859771729,"relu":1.848484992980957,"x":1.848484992980957},{"gelu":1.8553974628448486,"relu":1.9090909957885742,"x":1.9090909957885742},{"gelu":1.9215643405914307,"relu":1.9696969985961914,"x":1.9696969985961914},{"gelu":1.9873359203338623,"relu":2.0303030014038086,"x":2.0303030014038086},{"gelu":2.0527119636535645,"relu":2.090909004211426,"x":2.090909004211426},{"gelu":2.1176984310150146,"relu":2.151515483856201,"x":2.151515483856201},{"gelu":2.1823041439056396,"relu":2.2121214866638184,"x":2.2121214866638184},{"gelu":2.2465426921844482,"relu":2.2727274894714355,"x":2.2727274894714355},{"gelu":2.3104310035705566,"relu":2.3333334922790527,"x":2.3333334922790527},{"gelu":2.3739876747131348,"relu":2.39393949508667,"x":2.39393949508667},{"gelu":2.4372332096099854,"relu":2.454545497894287,"x":2.454545497894287},{"gelu":2.5001888275146484,"relu":2.5151515007019043,"x":2.5151515007019043},{"gelu":2.5628764629364014,"relu":2.5757579803466797,"x":2.5757579803466797},{"gelu":2.6253178119659424,"relu":2.636363983154297,"x":2.636363983154297},{"gelu":2.6875340938568115,"relu":2.696969985961914,"x":2.696969985961914},{"gelu":2.749547004699707,"relu":2.7575759887695312,"x":2.7575759887695312},{"gelu":2.8113765716552734,"relu":2.8181819915771484,"x":2.8181819915771484},{"gelu":2.873041868209839,"relu":2.8787879943847656,"x":2.8787879943847656},{"gelu":2.934560775756836,"relu":2.939393997192383,"x":2.939393997192383},{"gelu":2.995950222015381,"relu":3.0,"x":3.0}]},"height":400,"layer":[{"encoding":{"x":{"field":"x","type":"quantitative"},"y":{"field":"relu","type":"quantitative"}},"mark":"line"},{"encoding":{"color":{"value":"#db646f"},"x":{"field":"x","type":"quantitative"},"y":{"field":"gelu","type":"quantitative"}},"mark":"line"}],"title":"GeLU vs ReLU","width":400}
```

The smoothness of GELU can lead to better optimization properties during training,
as it allows for more nuanced adjustments to the model’s parameters. In contrast,
ReLU has a sharp corner at zero, which can sometimes make opti
mization harder, especially in networks that are very deep or have complex architec
tures. Moreover, unlike ReLU, which outputs zero for any negative input, GELU
allows for a small, non-zero output for negative values. This characteristic means that
during the training process, neurons that receive negative input can still contribute to
the learning process, albeit to a lesser extent than positive inputs.

```elixir
emb_dim = 768

model =
  Axon.input("sequence", shape: {nil, 3, emb_dim})
  |> Axon.dense(4*emb_dim)
  |> Axon.activation(:gelu)
  |> Axon.dense(emb_dim)

template = Nx.template({2, 3, emb_dim}, :f32)
Axon.Display.as_graph(model, template)
```

<!-- livebook:{"output":true} -->

```mermaid
graph TD;
10[/"sequence (:input) {2, 3, 768}"/];
11["dense_0 (:dense) {2, 3, 3072}"];
12["gelu_0 (:gelu) {2, 3, 3072}"];
13["dense_1 (:dense) {2, 3, 768}"];
12 --> 13;
11 --> 12;
10 --> 11;
```

```elixir
{init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
params = init_fn.(template, %{})
#result = predict_fn.(params, batch_example)
```

<!-- livebook:{"output":true} -->

```
%{
  "dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65816>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65817>
      [
        [0.037968024611473083, -0.012486153282225132, 0.015026752837002277, 0.01819963939487934, 0.007542737759649754, -0.03456614539027214, 0.012388583272695541, 0.004984976723790169, 0.019064368680119514, -0.014172918163239956, -0.03860724717378616, 0.0235779769718647, -0.02216426283121109, 0.03397120535373688, -0.007344204932451248, -0.012921057641506195, 0.023069527000188828, -0.03688299283385277, -0.027895674109458923, 0.015103334560990334, -0.023312391713261604, 0.005816729739308357, -0.033038459718227386, -0.014718803577125072, -0.024361874908208847, 0.019959989935159683, -0.013312374241650105, -0.001127525931224227, -0.03036332130432129, -0.02446150779724121, -0.03258978947997093, 0.019698530435562134, -0.014758111909031868, 0.01861654222011566, -0.02646697498857975, -0.03687809035181999, -0.016737615689635277, 0.02523729018867016, -0.03103320114314556, -0.006445350591093302, 0.0019058996113017201, 0.037948127835989, -0.016367776319384575, -0.0030755051411688328, -0.016628792509436607, 0.013410283252596855, -0.026036877185106277, ...],
        ...
      ]
    >
  },
  "dense_1" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65818>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65819>
      [
        [-0.029239319264888763, 0.029721759259700775, 0.036452941596508026, 0.0376380980014801, 0.013831098563969135, 0.028412438929080963, -0.008997447788715363, 0.018069272860884666, -0.020647965371608734, 0.029761604964733124, 0.01238206122070551, 0.010547297075390816, 0.01969081163406372, -0.024214722216129303, 0.003753095166757703, -6.114689167588949e-4, -0.03053130954504013, -0.03389289975166321, -0.0012526997597888112, 0.03889542445540428, -0.014068902470171452, 0.03884967789053917, -0.027407729998230934, -0.011099684052169323, 0.004065237939357758, 0.024334684014320374, 0.018410291522741318, -6.344642606563866e-4, 0.029870212078094482, -0.027527494356036186, -0.028693150728940964, -0.0025397136341780424, 0.007348210550844669, 0.017935145646333694, 0.010013559833168983, -0.02276243455708027, -0.02389315515756607, -0.011101465672254562, 0.00159542472101748, 0.0024595409631729126, -0.005835408810526133, -0.01397021021693945, -0.011573162861168385, 0.007232526782900095, -0.017624802887439728, -9.504617773927748e-4, ...],
        ...
      ]
    >
  }
}
```

```elixir
{x, _new_key} = Nx.Random.normal(key, shape: {2,3,768})
result = predict_fn.(params, x)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][3][768]
  EXLA.Backend<host:0, 0.1366667826.1786118168.65821>
  [
    [
      [-0.09523515403270721, 0.27915674448013306, -0.20000025629997253, 0.1561533808708191, -1.305216670036316, 0.15284250676631927, -0.9481883645057678, 0.054448068141937256, 0.577552855014801, -0.32642990350723267, -0.051692649722099304, 0.2610037624835968, -0.04240375757217407, 0.14691637456417084, 0.1517961472272873, -0.31707102060317993, 0.21067015826702118, -0.10083290934562683, -0.4113229513168335, 0.23234695196151733, 0.955460786819458, 0.0024026483297348022, 0.07514913380146027, 0.8138859272003174, 0.08676305413246155, 0.052677154541015625, -0.31632715463638306, -0.49514293670654297, 1.238835334777832, -0.19202806055545807, 0.2576562464237213, -0.6490620970726013, 0.27537858486175537, -0.11180441081523895, 0.020343467593193054, -0.8215962052345276, 0.9358676671981812, 0.2972087860107422, 0.19441810250282288, -0.704413652420044, 0.08245468139648438, 0.3992760181427002, -0.6043437719345093, -0.3117981553077698, -0.6135468482971191, 0.19115760922431946, 0.2882792055606842, -0.128155916929245, -0.14062589406967163, 0.07104818522930145, ...],
      ...
    ],
    ...
  ]
>
```

```elixir
Nx.shape(result)
```

<!-- livebook:{"output":true} -->

```
{2, 3, 768}
```

The FeedForward module plays a crucial role in enhancing the model’s ability to learn
from and generalize the data. Although the input and output dimensions of this
module are the same, it internally expands the embedding dimension into a higher
dimensional space through the first linear layer.

This expansion is followed by a nonlinear GELU activation and then a contraction back to the original dimension with the second linear transformation. Such a design allows for the
exploration of a richer representation space.

shortcut connections that we insert between different layers of a neural network, which are important for improving the training
performance in deep neural network architectures.

## 4.4 Adding shortcut connections

The shortcut connections were proposed for deep networks in
computer vision (specifically, in residual networks) to mitigate the challenge of vanishing gradients. The vanishing gradient problem refers to the issue where gradients
(which guide weight updates during training) become progressively smaller as they
propagate backward through the layers, making it difficult to effectively train earlier
layers.

```elixir
defmodule LLM.Layer do
  def shortcut(x, layer_impl, opts \\ []) when is_function(layer_impl) do
    with {:arity, arity} <- Function.info(layer_impl, :arity),
          layer_output <- execute_layer(x, layer_impl, opts, arity),
          output <- shortcut_impl(x, layer_output, opts) do
      output
    end    
  end

  defp execute_layer(x, layer_impl, _opts, 1), do: layer_impl.(x)
  defp execute_layer(x, layer_impl, opts, _arity), do: layer_impl.(x, opts)
  defp shortcut_impl(x, layer_output, opts) do
    use_shortcut? = Keyword.get(opts, :use_shortcut, false)
    if use_shortcut?, 
      do: Axon.add(x, layer_output),
      else: layer_output
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, LLM.Layer, <<70, 79, 82, 49, 0, 0, 10, ...>>, {:shortcut_impl, 3}}
```

```elixir
model =
  Axon.input("input", shape: {nil, 2})
  #|>Axon.dense(2)
  |> LLM.Layer.shortcut(&Axon.dense(&1, 2, use_bias: false))

model_with_shortcut =
  Axon.input("input", shape: {nil, 2})
  |> LLM.Layer.shortcut(
    &Axon.dense(&1, 2, use_bias: false),
    use_shortcut: true
  )
{_init_fn, predict_with_short_fn} = Axon.build(model_with_shortcut)
{init_fn, predict_fn} = Axon.build(model)
template = Nx.template({1, 2}, :f32)

params = init_fn.(template, %{})
```

<!-- livebook:{"output":true} -->

```
%{
  "dense_0" => %{
    "kernel" => #Nx.Tensor<
      f32[2][2]
      [
        [0.6609197854995728, -1.0485293865203857],
        [-0.9395022392272949, 0.12859761714935303]
      ]
    >
  }
}
```

```elixir
predict_fn.(params, Nx.tensor([[103, 103]]))
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[1][2]
  [
    [-28.693992614746094, -94.75297546386719]
  ]
>
```

```elixir
predict_with_short_fn.(params, Nx.tensor([[103, 103]]))
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[1][2]
  [
    [74.3060073852539, 8.247024536132812]
  ]
>
```

In conclusion, shortcut connections are important for overcoming the limitations
posed by the vanishing gradient problem in deep neural networks. Shortcut connections are a core building block of very large models such as LLMs.

## 4.5 Connecting attention and linear layers in a transformer block

```elixir
defmodule Transformer.Layers do
  import Nx.Defn
  
  def attention(%Axon{} = input, opts \\ []) do
    #opts = Keyword.validate!(opts, [:name, :d_in, :d_out, :num_heads])
    head_dim = div(opts[:d_out], opts[:num_heads])
    w_query = Axon.param("w_query", fn _ -> {opts[:d_in], opts[:d_out]} end)
    w_key = Axon.param("w_key", fn _ -> {opts[:d_in], opts[:d_out]} end)
    w_value = Axon.param("w_value", fn _ -> {opts[:d_in], opts[:d_out]} end)
    out_proj = Axon.param("out_proj", fn _ -> {opts[:d_out], opts[:d_out]} end)

    Axon.layer(
      &attention_impl/6,
      [input, w_query, w_key, w_value, out_proj],
      name: opts[:name],
      op_name: :causal_attention,
      head_dim: head_dim,
      num_heads: opts[:num_heads]
    )
  end

  #defnp attention_impl(input, w_query, w_key, w_value, head_dim, num_heads, _opts \\ []) do
  defnp attention_impl(input, w_query, w_key, w_value, out_proj, opts \\ []) do
    {b, num_tokens, _d_in} = Nx.shape(input)
    keys = Nx.dot(input, w_key)
    queries = Nx.dot(input, w_query)
    values = Nx.dot(input, w_value)
    d_k = Nx.axis_size(keys, -1)

    keys_reshaped = 
      keys
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])
    
    queries_reshaped = 
      queries
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])
    
    values_reshaped = 
      values
      |> Nx.reshape({b, num_tokens, opts[:num_heads], opts[:head_dim]}) 
      |> Nx.transpose(axes: [0, 2, 1, 3])

    attn_score =
      keys_reshaped
      |> Nx.transpose(axes: [0, 1, 3, 2])
      |> then(&Nx.dot(queries_reshaped, [3], [0, 1], &1, [2], [0, 1]))

    simple_mask =
      attn_score
      |> then(&Nx.broadcast(Nx.Constants.infinity(), &1))
      |> Nx.triu(k: 1)

    masked = Nx.multiply(simple_mask, -1) |> Nx.add(attn_score)

    attn_weights =
      masked
      |> Nx.divide(Nx.pow(d_k, 0.5))
      |> Axon.Activations.softmax(axis: -1)
    
    context_vec =
      attn_weights
      |> Nx.dot([3], [0, 1], values_reshaped, [2], [0, 1])
      |> Nx.transpose(axes: [0, 2, 1, 3])

    context_vec
    |> Nx.reshape({b, num_tokens, opts[:num_heads] * opts[:head_dim]})
    |> Nx.dot(out_proj)
  end

  def shortcut(x, layer_impl, opts \\ []) when is_function(layer_impl) do
    with {:arity, arity} <- Function.info(layer_impl, :arity),
          layer_output <- execute_layer(x, layer_impl, opts, arity),
          output <- shortcut_impl(x, layer_output, opts) do
      output
    end    
  end

  defp execute_layer(x, layer_impl, _opts, 1), do: layer_impl.(x)
  defp execute_layer(x, layer_impl, opts, _arity), do: layer_impl.(x, opts)
  defp shortcut_impl(x, layer_output, opts) do
    use_shortcut? = Keyword.get(opts, :use_shortcut, false)
    if use_shortcut?, 
      do: Axon.add(x, layer_output),
      else: layer_output
  end

  def normalization(%Axon{} = input, opts \\ []) do
    #opts = Keyword.validate!(opts, [:name, :eps, :emb_dim])
    eps = Keyword.get(opts, :eps, 1.00e-5)
    scale = Axon.param("scale", {opts[:emb_dim]}, initializer: &ones(&1, type: &2))
    shift = Axon.param("shift", {opts[:emb_dim]}, initializer: &zeros(&1, type: &2))

    Axon.layer(
      &normalization_impl/4,
      [input, scale, shift],
      name: opts[:name],
      op_name: :normalization,
      eps: eps
    )
  end

  defp ones(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(1)
  end

  defp zeros(shape, opts) do
    opts = Keyword.validate!(opts, [:type])
    Nx.iota(shape, type: opts[:type]) |> Nx.fill(0)
  end

  defnp normalization_impl(input, scale, shift, opts \\ []) do
    mean = Nx.mean(input, axes: [-1], keep_axes: true)
    variance = Nx.variance(input, axes: [-1], keep_axes: true)
    denominator = variance |> Nx.add(opts[:eps]) |> Nx.sqrt()

    input
    |> Nx.subtract(mean)
    |> Nx.divide(denominator)
    |> Nx.multiply(scale)
    |> Nx.add(shift)
  end

  def pos_embedding(%Axon{} = x, vocab_size, embedding_size, opts \\ []) do
    opts = Keyword.validate!(opts, [:name, kernel_initializer: :uniform])

    kernel_shape = &Axon.Shape.embedding_kernel(&1, vocab_size, embedding_size)

    kernel = Axon.param("kernel", kernel_shape, initializer: opts[:kernel_initializer])

    Axon.layer(&pos_embedding_impl/3, [x, kernel], name: opts[:name], op_name: :pos_embedding)
  end

  defnp pos_embedding_impl(x, kernel, _opts \\ []) do
    {_batch_size, sequence_size} = Nx.shape(x)
    input = Nx.iota({1, sequence_size})
    Nx.take(kernel, input, axis: 0)
  end

  def feedforward(input, emb_dim) do
    input
    |> Axon.dense(4*emb_dim)
    |> Axon.activation(:gelu)
    |> Axon.dense(emb_dim)
  end

  def feedforward_block(input, opts) do
    input
    |> normalization(opts)
    |> feedforward(opts[:emb_dim])
    |> Axon.dropout(rate: opts[:drop_rate])
  end

  def attention_block(input, opts) do
    input
    |> normalization(opts)
    |> attention(d_in: opts[:emb_dim], d_out: opts[:emb_dim], num_heads: opts[:n_heads] )
    |> Axon.dropout(rate: opts[:drop_rate])
  end

  def block(input, opts \\ []) do
    input
    |> shortcut(&attention_block(&1, opts), use_shortcut: true)
    |> shortcut(&feedforward_block(&1, opts), use_shortcut: true)
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, Transformer.Layers, <<70, 79, 82, 49, 0, 0, 51, ...>>, {:block, 2}}
```

```elixir
gpt_config_124m
```

<!-- livebook:{"output":true} -->

```
[
  attn_name: "attention_0",
  vocab_size: 50257,
  context_length: 1024,
  emb_dim: 768,
  n_heads: 12,
  n_layers: 12,
  drop_rate: 0.1,
  qkv_bias: false
]
```

```elixir
model = 
  Axon.input("sequence", shape: {2,4,768})
  |> Transformer.Layers.block(gpt_config_124m)

{init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
template = Nx.template({2,4,768}, :f32)

params = init_fn.(template, %{})
```

<!-- livebook:{"output":true} -->

```
%{
  "causal_attention_0" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65838>
      [
        [-0.017055675387382507, -0.05560906231403351, -0.019379183650016785, 0.020813465118408203, 0.037009790539741516, -0.020269528031349182, 0.0020721256732940674, -0.027914151549339294, 0.015935853123664856, 2.067089080810547e-4, -0.05635488033294678, -0.055533573031425476, -0.03342193365097046, -0.02554383873939514, -0.03359082341194153, 0.04873090982437134, 0.021506890654563904, -0.0020672976970672607, -0.00862102210521698, -0.04165373742580414, -0.024758338928222656, -0.056420937180519104, 0.060397833585739136, -0.05870679020881653, -0.012030467391014099, 0.023493364453315735, 0.05974583327770233, -0.009156033396720886, -0.012084200978279114, -0.006214603781700134, 0.002186119556427002, -0.00652649998664856, -0.04390379786491394, 0.03679245710372925, -0.03484848141670227, -0.0213032066822052, 0.0619431734085083, 0.025688737630844116, 0.023337021470069885, -0.01645471155643463, 1.1357665061950684e-4, 0.010417252779006958, 0.05234363675117493, -0.0038494914770126343, -0.0032488852739334106, 0.00687958300113678, 0.038719549775123596, -0.04583287239074707, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65839>
      [
        [-0.002348765730857849, -0.03650796413421631, 0.02028842270374298, 0.06193816661834717, -0.0566706508398056, 0.014447882771492004, 0.008801773190498352, 0.021275296807289124, -0.007846981287002563, 0.04699990153312683, 0.0032503455877304077, -0.01081673800945282, 0.025894001126289368, 0.005909726023674011, -0.03927718102931976, -0.03289276361465454, -0.02614918351173401, -0.039582908153533936, 0.004212141036987305, 0.01372365653514862, 0.03460223972797394, 0.008477956056594849, 0.04732644557952881, 0.020453661680221558, -0.0025206804275512695, -0.033378660678863525, -0.0183325856924057, -0.05099174380302429, 0.057532668113708496, 0.03557977080345154, -0.038131386041641235, 0.05654503405094147, 0.04915773868560791, -0.017673134803771973, -0.03420086205005646, 0.006084516644477844, -0.049376532435417175, 0.058446720242500305, -0.03797507286071777, -0.011914357542991638, -0.0036140382289886475, 0.054548799991607666, -0.017836660146713257, -0.03590141236782074, -0.01226787269115448, -0.01665407419204712, -0.0463859885931015, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65840>
      [
        [6.971806287765503e-4, -0.04693162441253662, -0.05299992859363556, 0.014495819807052612, -0.04410955309867859, -0.05929063260555267, -0.029404416680336, -0.0010957270860671997, -0.006964057683944702, 0.03287510573863983, -0.006840154528617859, -0.04256640374660492, -0.04331699013710022, 0.03570355474948883, 0.0078507661819458, 0.04734465479850769, -0.02856200933456421, -0.0035919398069381714, 0.04171516001224518, 0.012145712971687317, 0.012641355395317078, -0.03027893602848053, 0.05941781401634216, -0.05464693903923035, 0.004931032657623291, 0.055503278970718384, -0.05257114768028259, -0.05464138090610504, -0.033219367265701294, -0.005591005086898804, -0.013449698686599731, 0.007006928324699402, 0.0034298449754714966, -0.006656378507614136, 0.03420865535736084, -0.01487763226032257, 0.04445567727088928, 0.006271347403526306, 0.014762535691261292, 0.054814279079437256, 0.01833440363407135, -0.007997468113899231, -0.032872363924980164, 0.045012205839157104, 0.033438295125961304, -0.03256125748157501, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65841>
      [
        [-0.05387073755264282, 0.02095372974872589, 0.03890807926654816, 0.020084381103515625, -0.014106959104537964, -0.04683855175971985, -0.05441248416900635, -0.02462802827358246, -0.01360994577407837, -0.006777554750442505, 0.05586250126361847, -0.023799315094947815, 0.034607261419296265, 0.0038211941719055176, 0.010451972484588623, -0.06238912045955658, 0.04693400859832764, -0.04039241373538971, 0.03657831251621246, -0.046022042632102966, -0.0047698915004730225, 0.00529894232749939, -0.03764241933822632, -0.013843074440956116, -0.03540053963661194, -0.02692975103855133, 0.04835839569568634, 0.018707051873207092, -0.01950201392173767, -0.0012510418891906738, 0.004051685333251953, -0.04815477132797241, 0.05056139826774597, 0.001290738582611084, -0.01760461926460266, -0.026766270399093628, 0.039468005299568176, 0.036657437682151794, -0.004719346761703491, 0.061759352684020996, 0.025929346680641174, -0.012859567999839783, 0.05477161705493927, -0.005533456802368164, -0.05752192437648773, ...],
        ...
      ]
    >
  },
  "dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65842>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65843>
      [
        [-0.027533451095223427, 0.0044858078472316265, 0.02855917438864708, 0.003196155419573188, 0.015076079405844212, 0.03884255141019821, 0.029037224128842354, -0.01614893414080143, 0.0023568158503621817, -0.02756693586707115, -0.03558918088674545, 0.03108099289238453, 0.013630756177008152, 0.001358346431516111, -0.0044000279158353806, 0.006195163354277611, 0.03413781896233559, 0.03822620213031769, -0.026583470404148102, -0.015296769328415394, -0.014641033485531807, -0.007005004677921534, 0.02142997644841671, -0.03193678706884384, -0.007418591063469648, -0.02272288128733635, 0.015344757586717606, -0.0033190955873578787, -0.010753595270216465, -0.023342076689004898, 0.0018807461019605398, 0.005561801604926586, -0.03299186751246452, -0.03680559992790222, -0.032190997153520584, 0.0049445368349552155, -0.006584152113646269, -0.02843247540295124, 0.021776095032691956, -0.0021626465022563934, -0.014385662972927094, 0.03343817591667175, -0.024596719071269035, -0.031156914308667183, 0.011814010329544544, -0.0040767076425254345, ...],
        ...
      ]
    >
  },
  "dense_1" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65844>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65845>
      [
        [0.03641606494784355, -0.022519173100590706, 9.436574182473123e-4, 0.01181397307664156, -0.016518019139766693, 0.01221673097461462, -0.018719589337706566, 0.03353619948029518, 0.030883703380823135, 0.03648868575692177, 0.023134581744670868, 0.03501499816775322, 0.014055736362934113, -0.031296443194150925, -0.01972683146595955, 0.03052552230656147, -0.020933380350470543, 0.027112532407045364, -0.03690613806247711, -0.005782066844403744, -0.02826591767370701, 0.01759728416800499, -0.02156953141093254, 0.0017705003265291452, 0.024123862385749817, 0.013020748272538185, 0.012895800173282623, 0.013805209659039974, -0.021699681878089905, 0.018714217469096184, 0.03266048803925514, 0.02612396702170372, 0.03899439796805382, 0.019422614946961403, -0.01705188862979412, 0.018684256821870804, 0.014426498673856258, 0.018955422565340996, -0.006344331428408623, 0.02105719782412052, -0.03650221973657608, -0.02486353926360607, -0.018425963819026947, -0.014551927335560322, 0.027874818071722984, ...],
        ...
      ]
    >
  },
  "normalization_0" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65846>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65847>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_1" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65848>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65849>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  }
}
```

```elixir
Axon.Display.as_graph(model, template)
```

<!-- livebook:{"output":true} -->

```mermaid
graph TD;
41[/"sequence (:input) {2, 4, 768}"/];
42["normalization_0 (:normalization) {2, 4, 768}"];
43["causal_attention_0 (:causal_attention) {2, 4, 768}"];
44["dropout_0 (:dropout) {2, 4, 768}"];
45["container_0 (:container) {{2, 4, 768}, {2, 4, 768}}"];
46["add_0 (:add) {2, 4, 768}"];
47["normalization_1 (:normalization) {2, 4, 768}"];
48["dense_0 (:dense) {2, 4, 3072}"];
49["gelu_0 (:gelu) {2, 4, 3072}"];
50["dense_1 (:dense) {2, 4, 768}"];
51["dropout_1 (:dropout) {2, 4, 768}"];
52["container_1 (:container) {{2, 4, 768}, {2, 4, 768}}"];
53["add_1 (:add) {2, 4, 768}"];
52 --> 53;
51 --> 52;
46 --> 52;
50 --> 51;
49 --> 50;
48 --> 49;
47 --> 48;
46 --> 47;
45 --> 46;
44 --> 45;
41 --> 45;
43 --> 44;
42 --> 43;
41 --> 42;
```

```elixir
key = Nx.Random.key(103)
{input, _new_key} = Nx.Random.normal(key, shape: {2,4,768})
result = predict_fn.(params, input)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][4][768]
  EXLA.Backend<host:0, 0.1366667826.1786118168.65851>
  [
    [
      [-0.716768205165863, -0.4204854965209961, -1.8959286212921143, 0.37171489000320435, -0.20300930738449097, 2.724903106689453, -0.4133290648460388, -0.30961093306541443, 0.24687054753303528, 1.410226583480835, -1.4018677473068237, -1.758493423461914, -1.3413493633270264, -0.46528956294059753, 0.24200332164764404, 0.9852171540260315, -0.42596209049224854, 1.9925718307495117, 0.5250499248504639, 0.35458439588546753, 1.0019404888153076, 0.18823081254959106, -0.13523443043231964, -1.5909684896469116, 1.1885206699371338, 1.9854960441589355, 2.420884370803833, -2.179537534713745, 2.465571403503418, 0.9325289726257324, -1.3916890621185303, 1.860776662826538, 0.06037481874227524, 1.2924396991729736, 1.666346788406372, -0.714210033416748, 0.5654738545417786, 1.7855122089385986, -1.270380973815918, 0.11856108903884888, 2.654468297958374, 0.7143635749816895, 1.0451276302337646, 0.23774230480194092, -2.40054988861084, 1.6369502544403076, 0.9113302230834961, -1.1185961961746216, 0.11834041774272919, 1.1322273015975952, ...],
      ...
    ],
    ...
  ]
>
```

The Transformer.Layers.block includes a multi-head
attention mechanism (MultiHeadAttention) and a feed forward network (Feed-Forward), both configured based on a provided configuration dictionary (cfg), such as GPT_CONFIG_124M.

Layer normalization (LayerNorm) is applied before each of these two components,
and dropout is applied after them to regularize the model and prevent overfitting. This is also known as Pre-LayerNorm. Older architectures, such as the original transformer model, applied layer normalization after the self-attention and feed forward networks instead, known as Post-LayerNorm, which often leads to worse training dynamics.

The module also implements the forward pass, where each component is followed by
a shortcut connection that adds the input of the block to its output. This critical feature helps gradients flow through the network during training and improves the learning of deep models.

The transformer block maintains the input dimensions in its output, indicating that the transformer architecture processes sequences of data without altering
their shape throughout the network.

<!-- livebook:{"break_markdown":true} -->

The preservation of shape throughout the transformer block architecture is not
incidental but a crucial aspect of its design. This design enables its effective applica-
tion across a wide range of sequence-to-sequence tasks, where each output vector
directly corresponds to an input vector, maintaining a one-to-one relationship. However, the output is a context vector that encapsulates information from the entire
input sequence. This means that while the physical dimensions of the
sequence (length and feature size) remain unchanged as it passes through the trans-
former block, the content of each output vector is re-encoded to integrate contextual
information from across the entire input sequence.

## 4.6 Coding the GPT model

The output from the final transformer block then goes through a final layer normal-
ization step before reaching the linear output layer. This layer maps the transformer’s
output to a high-dimensional space (in this case, 50,257 dimensions, corresponding to
the model’s vocabulary size) to predict the next token in the sequence.

```elixir
# Test to dynamically layers.
model =
  Axon.input("sequence", shape: {1, 2})

new_model =
  for _i <- 1..3, reduce: model do
    model_acc ->
      Axon.dense(model_acc, 6)
  end

template = Nx.template({1, 2}, :f32)
Axon.Display.as_graph(new_model, template)
```

<!-- livebook:{"output":true} -->

```mermaid
graph TD;
54[/"sequence (:input) {1, 2}"/];
55["dense_0 (:dense) {1, 6}"];
56["dense_1 (:dense) {1, 6}"];
57["dense_2 (:dense) {1, 6}"];
56 --> 57;
55 --> 56;
54 --> 55;
```

```elixir
defmodule MyGPT do
  @gpt_config_124m gpt_config_124m
  def model(input_shape \\ {2, 4, 768}, opts \\ @gpt_config_124m) do
    Axon.input("sequence", shape: input_shape)
    |> embedding_block(opts)
    |> Axon.dropout(rate: opts[:drop_rate])
    |> transformer_blocks(12, opts)
    |> Transformer.Layers.normalization(opts)
    |> Axon.dense(opts[:vocab_size], use_bias: false)
  end

  def embedding_block(input, opts) do
    token_emb = Axon.embedding(input, opts[:vocab_size], opts[:emb_dim])
    pos_emb = Transformer.Layers.pos_embedding(input, opts[:context_length], opts[:emb_dim])

    Axon.add(token_emb, pos_emb)
  end

  def transformer_blocks(input, n_blocks, transformer_opts) do
    for _n_block <- 1..n_blocks, reduce: input do
      model_acc ->
        Transformer.Layers.block(model_acc, transformer_opts)
    end
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, MyGPT, <<70, 79, 82, 49, 0, 0, 15, ...>>, {:transformer_blocks, 3}}
```

```elixir
batch
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][4]
  [
    [6109, 3629, 6100, 345],
    [6109, 1110, 6622, 257]
  ]
>
```

```elixir
template = Nx.template({1, 4}, :s64)
model = MyGPT.model()
```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"sequence" => {2, 4, 768}}
  outputs: "dense_24"
  nodes: 152
>
```

```elixir
{init_fn, predict_fn} = Axon.build(model, compiler: EXLA)
params = init_fn.(template, %{})
```

<!-- livebook:{"output":true} -->

```
%{
  "pos_embedding_0" => %{
    "kernel" => #Nx.Tensor<
      f32[1024][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.66001>
      [
        [0.00820946879684925, 0.009188241325318813, -0.0034671758767217398, -0.007448150776326656, -0.007996559143066406, -0.00552819250151515, -0.008458909578621387, 0.0015659808414056897, -0.009515397250652313, -0.0023298191372305155, -0.0063433838076889515, 0.007155895233154297, -0.007909640669822693, 0.009121849201619625, -0.0038319635204970837, 0.00977078452706337, 0.0013030886184424162, -9.236144833266735e-4, -0.0017825793474912643, 0.008658253587782383, 0.004096589051187038, -0.009104898199439049, 0.00883461907505989, 2.1013259538449347e-4, -0.0039931414648890495, 0.0012662267545238137, -0.00589345907792449, -1.7762422794476151e-4, 0.007725028786808252, 0.00836909469217062, -0.0021765350829809904, 0.0031562065705657005, 0.0010756277479231358, -0.0020445871632546186, -8.003711627679877e-6, 0.008890127763152122, 0.007651355117559433, 0.0061145662330091, -0.004479820840060711, 0.00866932887583971, -0.008535603992640972, 0.005303759593516588, -0.0029913424514234066, -0.008174783550202847, 0.006251899991184473, 0.008821689523756504, -0.00166055909357965, -0.005631952080875635, ...],
        ...
      ]
    >
  },
  "normalization_6" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65993>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65994>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_4" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65938>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65939>
      [
        [0.007951725274324417, -0.008591024205088615, 0.03084629774093628, 0.03919801861047745, -0.006465104408562183, 0.03587324172258377, -0.029273860156536102, 0.0013427963713184, 2.444763667881489e-4, -0.024390175938606262, -0.034954559057950974, -0.0323372446000576, 0.0014753305586054921, 0.007874681614339352, -0.031473711133003235, -0.030932558700442314, -0.037745844572782516, 0.01325751468539238, -0.0017783696530386806, 0.027555551379919052, -0.025321099907159805, -0.038646772503852844, 0.005787608679383993, 0.0187541376799345, 0.02014927752315998, -0.03415210545063019, -0.013058982789516449, 0.0022036044392734766, 5.003655678592622e-4, -0.0221744142472744, -0.002541174413636327, -0.03399861976504326, 0.016714544966816902, -0.011524014174938202, -0.012131176888942719, -0.038383882492780685, 0.016222171485424042, 0.03854641318321228, -0.03233107179403305, -0.036432698369026184, -0.03398247808218002, -0.025048643350601196, 0.02434637024998665, 0.03237614035606384, -0.004860387183725834, ...],
        ...
      ]
    >
  },
  "normalization_5" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65991>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65992>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_20" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65927>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65928>
      [
        [-0.008643423207104206, -0.03808677941560745, 0.03856589272618294, 0.0289661455899477, -0.039159614592790604, 0.009961207397282124, -0.03921467438340187, 0.00720088928937912, 0.023042816668748856, 0.0010641661938279867, -0.019540956243872643, -0.039042893797159195, -0.0366806797683239, 0.0011096857488155365, 0.003740136744454503, -0.030178753659129143, -0.028409432619810104, -0.014573565684258938, -0.03134012222290039, 0.01033230870962143, -0.038222573697566986, -0.02392405830323696, -0.029808038845658302, 0.02350245974957943, 0.004543343558907509, -0.020840145647525787, -0.0012748375302180648, 0.036794018000364304, -0.010731796734035015, -0.03439362347126007, -0.03502519428730011, 0.0040095215663313866, -0.02168966457247734, -0.026715749874711037, 0.004904756788164377, -0.028651166707277298, 0.011725619435310364, 0.0063535673543810844, 0.005658721551299095, -0.0079327542334795, 0.016678035259246826, -0.012191633693873882, -0.0018477326957508922, ...],
        ...
      ]
    >
  },
  "normalization_1" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65953>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65954>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_9" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65999>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.66000>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_22" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65931>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65932>
      [
        [-0.005695730913430452, 0.01940457709133625, -0.016799259930849075, -0.009635455906391144, 0.004453614354133606, 0.02737174741923809, 0.007082218304276466, 0.0016170063754543662, 0.03210758417844772, 0.028956137597560883, -0.02683628723025322, -0.014833912253379822, -0.0140641238540411, 0.01708773896098137, -0.03735227510333061, -0.028188431635499, 0.014741497114300728, -0.027338745072484016, 0.007070861756801605, 0.03213026002049446, -0.030906114727258682, -0.034542836248874664, -0.037251945585012436, -0.0022951713763177395, -0.03173783794045448, 0.0034601683728396893, 0.0025511831045150757, 0.023164816200733185, -0.0019491383573040366, -0.02549983188509941, -0.016073890030384064, 0.026647498831152916, 0.0013607025612145662, 0.039376188069581985, 0.025203324854373932, 0.014966342598199844, 0.036406517028808594, -0.02063322626054287, -0.02118971385061741, 0.03581114485859871, ...],
        ...
      ]
    >
  },
  "causal_attention_0" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65853>
      [
        [-0.05489400029182434, -0.039155200123786926, -0.009170278906822205, -0.021611839532852173, -0.01464468240737915, 0.021818622946739197, 0.05251871049404144, -0.05430804193019867, 0.0021059811115264893, -0.017595037817955017, -0.05499380826950073, 0.033547788858413696, -0.044628411531448364, -0.0522761195898056, 0.03932121396064758, -0.01695135235786438, -0.020284101366996765, -0.0028049200773239136, -0.013862058520317078, 0.0012287497520446777, 0.05986718833446503, -0.010002121329307556, 0.029883012175559998, 0.03109125792980194, -0.029560640454292297, -0.04171241819858551, -0.019969791173934937, 0.024976268410682678, -0.005772814154624939, 0.05854707956314087, 0.04195404052734375, 0.039050742983818054, 0.05545467138290405, -0.05645453929901123, 0.01080729067325592, -0.05919128656387329, 0.06138846278190613, 0.04838235676288605, 0.020340412855148315, -0.013968273997306824, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65854>
      [
        [0.04687102138996124, -0.03536757826805115, -0.007010817527770996, 0.042143821716308594, 0.06117507815361023, 0.009219691157341003, 0.050558462738990784, 0.007298022508621216, -9.268522262573242e-4, -0.003967806696891785, 0.015224486589431763, 0.03371243178844452, 0.05220791697502136, -0.03269970417022705, 0.05720898509025574, 0.04330742359161377, 0.0027159452438354492, -0.007316946983337402, -0.036986514925956726, 0.03676225244998932, 0.0434393435716629, 0.032708942890167236, -0.019815340638160706, -0.010256662964820862, -0.027735784649848938, -0.0401027649641037, 0.021295860409736633, 0.05721485614776611, 0.013380691409111023, -0.04448729753494263, 0.031398698687553406, 0.019680440425872803, 0.014919206500053406, 0.05950406193733215, -0.05872026085853577, 0.03292544186115265, 0.015416577458381653, 0.052167996764183044, 0.006425082683563232, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65855>
      [
        [0.022899866104125977, -0.033817097544670105, 0.059301987290382385, -0.04439030587673187, 0.012292608618736267, 0.039279863238334656, -0.05003109574317932, -0.02336028218269348, 0.04098793864250183, 0.03009355068206787, 0.012847885489463806, 0.042464762926101685, 9.96425747871399e-4, -0.05092477798461914, -0.045868054032325745, -0.012940824031829834, -0.03968289494514465, -0.036278724670410156, -0.03340412676334381, 0.024561360478401184, -0.013194680213928223, 0.03875914216041565, 0.059637561440467834, -0.03777608275413513, -0.017550170421600342, -0.055209681391716, 0.021982118487358093, 0.036332473158836365, 0.020841673016548157, 0.0036048144102096558, -0.026743724942207336, 0.029593050479888916, -0.03466331958770752, 0.05739566683769226, 0.03717690706253052, 0.05089336633682251, -0.002735033631324768, 0.0447123646736145, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65856>
      [
        [-0.02619999647140503, 0.048979252576828, 3.127157688140869e-4, -0.028897106647491455, 0.03259924054145813, -0.038410648703575134, 0.029967039823532104, 5.020499229431152e-4, 0.05025339126586914, 0.001332402229309082, 0.014239713549613953, -0.06118769943714142, -0.005514770746231079, 0.06032727658748627, 0.014304712414741516, -0.029770493507385254, -0.03880971670150757, 0.06235247850418091, 0.054254576563835144, -0.042912185192108154, -0.042275190353393555, 0.04345338046550751, 0.04867301881313324, -0.014384850859642029, 0.006365090608596802, -0.039435938000679016, -0.0261828750371933, 0.00685197114944458, -0.014525637030601501, 0.025676921010017395, 0.05117411911487579, -0.03469167649745941, -0.026622265577316284, -0.04466487467288971, 0.04095759987831116, -0.05895838141441345, -0.024648264050483704, ...],
        ...
      ]
    >
  },
  "normalization_14" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65963>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65964>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_7" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65995>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65996>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_11" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65957>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65958>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_2" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65975>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65976>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_12" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65909>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65910>
      [
        [-0.030212607234716415, 0.01017819344997406, 0.023311730474233627, 0.0391693115234375, -0.009699258022010326, -0.0331733338534832, 0.024538900703191757, 0.007583545055240393, 0.01462976261973381, -0.014602328650653362, -0.0029376179445534945, -0.007452735677361488, -0.013505741953849792, 0.027952220290899277, -0.009736993350088596, 0.03601047024130821, 0.023169782012701035, 0.01591755822300911, -0.015054394491016865, 0.015612625516951084, -0.03216945379972458, 0.02113960310816765, -0.006786813028156757, -0.03232434391975403, -0.008756335824728012, -0.007568060886114836, 0.03484826907515526, -0.0016728172777220607, 0.03853771463036537, 0.017834974452853203, 0.03739023581147194, 0.006592803634703159, -0.012812159024178982, -0.026464100927114487, ...],
        ...
      ]
    >
  },
  "dense_23" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65933>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65934>
      [
        [0.020444191992282867, -0.027403226122260094, 0.009465120732784271, 0.011801626533269882, -0.03225001320242882, -0.020963340997695923, -0.03514442965388298, -0.007892417721450329, 0.02807697094976902, -0.01127086766064167, 0.028419196605682373, 0.021006353199481964, -0.005180484149605036, 0.004865542054176331, -0.03541543707251549, 0.02198111079633236, 0.016260679811239243, 0.01586957834661007, 0.033852458000183105, -0.013914522714912891, -0.0057561215944588184, 0.017434582114219666, -0.03442095220088959, 0.03288452327251434, 0.03143324330449104, 0.0015610731206834316, 0.03612896054983139, 0.03294341638684273, 0.006717195268720388, 0.02621821127831936, -0.03397725522518158, 0.028073681518435478, -0.03619467839598656, ...],
        ...
      ]
    >
  },
  "embedding_0" => %{
    "kernel" => #Nx.Tensor<
      f32[50257][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65950>
      [
        [-0.0016090749995782971, -0.003907220438122749, -0.00360292661935091, -0.00231545208953321, -0.005603322759270668, 0.0032405112870037556, -0.0034749649930745363, -0.008328196592628956, -0.008334300480782986, 0.002380151767283678, 0.0019280958222225308, -0.006717686541378498, -0.009055950678884983, 0.008918508887290955, -0.007226414512842894, -0.004065058194100857, 0.009506313130259514, -0.008293678984045982, 8.306717500090599e-4, 0.006336223799735308, 0.004062929190695286, 0.004070937633514404, -2.814316831063479e-4, 9.565543732605875e-4, -0.00485666748136282, 0.001047842437401414, -0.00563220027834177, 0.003163895569741726, -0.007921133190393448, -0.008668815717101097, -0.00760646304115653, -0.006582675036042929, -0.004447436425834894, ...],
        ...
      ]
    >
  },
  "normalization_19" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65973>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65974>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_6" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65885>
      [
        [0.025701820850372314, -0.054504990577697754, 0.029997289180755615, -0.03686901926994324, 0.016721084713935852, -0.03375677764415741, 0.059069350361824036, 7.250607013702393e-4, -0.02984979748725891, 4.918873310089111e-4, -7.946044206619263e-4, 0.056285277009010315, 0.010786309838294983, 0.05521267652511597, 0.04236045479774475, -0.016745954751968384, -0.058286041021347046, -0.05879490077495575, 0.023886770009994507, -0.016313806176185608, 0.017728060483932495, 0.0613899827003479, 0.0061877816915512085, 0.005800962448120117, 0.01997123658657074, -0.03392757475376129, 0.02042210102081299, 0.019898176193237305, -0.048953741788864136, 0.030590444803237915, 0.01393859088420868, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65886>
      [
        [0.010096222162246704, 0.0012035369873046875, 0.017482370138168335, -0.054907336831092834, -0.034396275877952576, -0.031409040093421936, 0.03767158091068268, 0.00809420645236969, 0.047381192445755005, 0.02798573672771454, -0.040443405508995056, -0.05414016544818878, 0.005056798458099365, 0.03312613070011139, -0.030661195516586304, 0.007245868444442749, 0.0082969069480896, 0.018908783793449402, -0.021926403045654297, -0.0109795480966568, 0.031210750341415405, -0.033631905913352966, 0.019452661275863647, 0.009734466671943665, 0.04139360785484314, 0.008643284440040588, 0.03843680024147034, 0.030701294541358948, 0.027932196855545044, 0.054621800780296326, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65887>
      [
        [-0.03707754611968994, -0.030656009912490845, 0.03520679473876953, -0.04625687003135681, -0.0189407616853714, 0.02809925377368927, 0.03452543914318085, -0.04839430749416351, 0.05323837697505951, 0.0021147727966308594, 0.02971041202545166, -0.025895893573760986, 0.027443334460258484, -0.03392206132411957, -0.04972764849662781, -0.0307915061712265, 0.04374489188194275, 0.01891949772834778, -0.00454828143119812, -0.04370458424091339, 0.012373551726341248, -0.01682738959789276, 0.005775421857833862, -0.0018092989921569824, -0.05827032029628754, -0.013664931058883667, 0.0270087867975235, -0.034229978919029236, -0.0029068589210510254, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65888>
      [
        [0.052588433027267456, 0.05754421651363373, -0.042503178119659424, -0.04482130706310272, 0.029898464679718018, -0.048212021589279175, 0.05257728695869446, 0.0042043328285217285, 0.04159720242023468, 0.062173157930374146, -0.025318071246147156, 0.024036988615989685, -0.051172688603401184, -0.03796112537384033, -0.016400858759880066, -0.03468772768974304, -0.045705899596214294, 0.0405057817697525, 0.059305816888809204, -0.04508274793624878, -0.05889318883419037, 0.004644140601158142, -0.06178523600101471, -0.05705609917640686, 0.0390387624502182, -0.03353504836559296, -0.026936382055282593, 0.047242820262908936, ...],
        ...
      ]
    >
  },
  "causal_attention_7" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65889>
      [
        [-0.032045722007751465, 0.017456412315368652, -0.0242689847946167, 0.04675541818141937, 0.029787346720695496, -0.03577202558517456, -0.0022034794092178345, 0.03651021420955658, 0.02027672529220581, -0.02710777521133423, -0.00933249294757843, -0.03069135546684265, -0.057961657643318176, 0.02531592547893524, 0.022363126277923584, 0.04881356656551361, 0.04138445854187012, 0.010208293795585632, -0.008330345153808594, -0.041544973850250244, 0.015900418162345886, 0.006786465644836426, -0.020606979727745056, 0.0022400468587875366, 0.02052748203277588, -0.011774599552154541, -0.025713816285133362, -0.023647218942642212, 0.011612921953201294, -0.026715517044067383, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65890>
      [
        [-0.05895945429801941, -0.024802401661872864, 0.05039659142494202, 0.036231085658073425, 0.022191762924194336, -0.02228279411792755, -0.03547416627407074, -0.049903035163879395, 0.04348662495613098, -0.03179320693016052, -0.05164504051208496, 0.0015797168016433716, 0.06085902452468872, 0.05436211824417114, -0.022526323795318604, -0.038063883781433105, 0.027981683611869812, -0.010301768779754639, 0.022196829319000244, -0.0431160032749176, 0.024083688855171204, 0.04146072268486023, -0.009297430515289307, 0.026913568377494812, 0.040827974677085876, -0.01640072464942932, -0.027775421738624573, 0.01280316710472107, -0.015676349401474, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65891>
      [
        [-0.003850281238555908, 0.030075520277023315, -0.0247572660446167, -0.03283834457397461, -0.0576925128698349, 0.007954820990562439, 0.05890782177448273, -0.01030498743057251, 0.025150269269943237, -0.04736118018627167, 0.009444251656532288, -0.026661813259124756, 0.03734239935874939, -0.03330172598361969, -0.012048572301864624, 0.01416216790676117, 0.0496334433555603, 0.009033679962158203, 0.04660935699939728, -0.027820080518722534, 0.03103475272655487, 0.018427371978759766, -0.02513173222541809, 0.031223684549331665, -0.035366833209991455, -3.833472728729248e-4, -0.005494505167007446, 0.022209420800209045, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65892>
      [
        [0.02350783348083496, -0.02003483474254608, 0.04679706692695618, -0.04162248969078064, 0.03920908272266388, 0.006552442908287048, -0.04930463433265686, 0.024353966116905212, -0.024234965443611145, -0.016075626015663147, 0.017792314291000366, -0.040183261036872864, -0.05149658024311066, 0.03500549495220184, -0.0168725848197937, -0.05759905278682709, -0.036677464842796326, 0.039839357137680054, 0.056501612067222595, 0.01898530125617981, -0.015023767948150635, -0.008932814002037048, 0.04588139057159424, -0.05752365291118622, -0.047592490911483765, 0.012481942772865295, -0.05152970552444458, ...],
        ...
      ]
    >
  },
  "causal_attention_1" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65857>
      [
        [0.012421980500221252, -0.04269014298915863, -0.04550692439079285, -0.016208991408348083, 0.020465701818466187, 0.05221274495124817, 0.005325481295585632, -0.057037726044654846, 0.036669909954071045, 0.008155956864356995, -0.04294180870056152, 0.02440929412841797, 0.011539056897163391, -0.05979380011558533, -0.01832081377506256, 0.016922026872634888, -0.034844666719436646, 0.03192244470119476, -0.0049813538789749146, -0.04656209051609039, -0.03621731698513031, 0.05114838480949402, -0.023377642035484314, 0.041796475648880005, -0.04053215682506561, -0.017181262373924255, -0.03711695969104767, 0.03578770160675049, -0.04483543336391449, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65858>
      [
        [0.027674600481987, -0.057753339409828186, 0.05609412491321564, 0.04927493631839752, 0.037359803915023804, -0.0138387531042099, 0.03773191571235657, 0.04090070724487305, -0.03581881523132324, 0.04968537390232086, 0.03941449522972107, 0.008177310228347778, -0.04164418578147888, -0.017723917961120605, -0.032029956579208374, -0.034827858209609985, 0.015351071953773499, 0.05072504281997681, 0.012002795934677124, -0.04956841468811035, -0.05421432852745056, -0.007948070764541626, 0.057788386940956116, -0.01360715925693512, 0.04243507981300354, -0.038228392601013184, -0.02971363067626953, -0.055006951093673706, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65859>
      [
        [-0.02957746386528015, 0.03289474546909332, 0.05949847400188446, 0.010120987892150879, -0.01310354471206665, 0.004510313272476196, -0.015955954790115356, 0.06145139038562775, -0.014455825090408325, -0.05895638465881348, -0.026723697781562805, -0.04537688195705414, -0.04693858325481415, 0.007102593779563904, 0.012268990278244019, 0.02478422224521637, -0.0333857387304306, 0.0011792182922363281, -0.051901236176490784, 0.05027095973491669, -0.040482714772224426, 0.012476295232772827, 0.021930694580078125, -0.026617586612701416, 0.043517738580703735, -0.010764479637145996, 0.057726114988327026, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65860>
      [
        [0.019613072276115417, 0.051455721259117126, 0.03897149860858917, 0.007469534873962402, -0.0030021369457244873, 0.023965954780578613, -0.04122491180896759, 0.003679707646369934, 0.03143559396266937, 0.05365791916847229, -0.04962342977523804, 0.05203866958618164, -0.04326619207859039, -0.04479421675205231, 0.014022588729858398, -0.03217512369155884, 0.022234678268432617, -0.0034312456846237183, 0.0030553340911865234, -0.025083303451538086, -0.010746285319328308, 0.017215639352798462, 0.04503507912158966, -0.005856752395629883, -0.014508351683616638, 0.044021353125572205, ...],
        ...
      ]
    >
  },
  "dense_15" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65915>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65916>
      [
        [0.005395660176873207, 0.011839776299893856, -0.02832644246518612, 0.01453049574047327, -0.03146753087639809, -0.02135009691119194, 0.01870754361152649, -8.676031575305387e-5, -0.010343081317842007, 0.01302742026746273, 0.02643774077296257, 0.006407936103641987, -0.037305522710084915, -0.019868772476911545, -0.03678732365369797, -0.0359368734061718, 6.109505775384605e-4, 0.015419756062328815, 0.006048841401934624, 0.0058729080483317375, -0.02619294449687004, 0.012516112998127937, 0.013984186574816704, 0.035320863127708435, -0.010913054458796978, -0.006062120199203491, 0.015807265415787697, ...],
        ...
      ]
    >
  },
  "dense_9" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65948>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65949>
      [
        [0.012368207797408104, -0.03800829499959946, -0.0035753806587308645, 0.0033571417443454266, -0.014881703071296215, -0.009259303100407124, 0.01123113464564085, 0.018255770206451416, -0.03940468654036522, 0.017897212877869606, -0.003306599101051688, -0.0011907254811376333, -0.02017735317349434, -0.03826594352722168, 0.01460936851799488, -0.01519190426915884, 0.03060215152800083, -0.0058674984611570835, 0.03689923137426376, 0.0227354709059, 0.0329238623380661, 0.015255508944392204, 0.0027411491610109806, -0.032676443457603455, -0.01861805096268654, -0.03613306209445, ...],
        ...
      ]
    >
  },
  "normalization_8" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65997>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65998>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_10" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65861>
      [
        [-0.022798985242843628, -0.045337170362472534, 0.025168761610984802, -0.04957088828086853, -8.123666048049927e-4, 0.051955416798591614, 0.05026403069496155, -0.0477260947227478, -0.03661969304084778, -0.032279565930366516, 0.02437390387058258, 0.026948392391204834, -0.023699268698692322, -0.022593483328819275, 0.03326416015625, 0.023770049214363098, 0.028966262936592102, 0.06071507930755615, 0.04856109619140625, 0.030310213565826416, 0.0391174852848053, 0.03669564425945282, 0.02858544886112213, -0.013668075203895569, 0.04215233027935028, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65862>
      [
        [-0.03181988000869751, -0.04755681753158569, 0.03437581658363342, 0.053778424859046936, 0.05072203278541565, -0.04093801975250244, 0.058276742696762085, 0.02703551948070526, -0.02373218536376953, 0.05170321464538574, -0.020467787981033325, -0.012876242399215698, 0.038928136229515076, 0.028580963611602783, -0.035283222794532776, 0.03956948220729828, 0.020930737257003784, -0.0026922523975372314, 0.044234707951545715, 0.05327966809272766, -0.029353812336921692, 0.03557972609996796, 0.05551312863826752, -0.007851481437683105, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65863>
      [
        [-0.0056618452072143555, 0.03151094913482666, 0.03827774524688721, 0.046215325593948364, 0.05178867280483246, 0.027159005403518677, 0.05923083424568176, -0.014196738600730896, -0.0031314492225646973, -0.04665765166282654, 0.042712077498435974, 0.03776612877845764, 0.030311763286590576, -0.053914621472358704, -0.050126731395721436, -0.0330914705991745, 0.003892362117767334, -0.004208564758300781, -0.056755974888801575, 0.018028929829597473, 0.014910101890563965, 0.050630778074264526, 0.0035226047039031982, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65864>
      [
        [-0.002143353223800659, 0.06062677502632141, -0.006879165768623352, -0.0480877161026001, 0.039068520069122314, 0.011195480823516846, -0.00621400773525238, 0.028505608439445496, -0.01588299870491028, 0.0023775845766067505, -0.011070683598518372, 0.027731314301490784, -0.027953684329986572, 0.05115070939064026, -0.059734269976615906, -0.04799060523509979, 0.04361407458782196, 0.012062788009643555, 0.027975618839263916, -0.0035041719675064087, -0.04900294542312622, 0.05563957989215851, ...],
        ...
      ]
    >
  },
  "causal_attention_8" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65893>
      [
        [-0.025582104921340942, 0.023829326033592224, 0.00909799337387085, -0.011847391724586487, -0.020098283886909485, 0.025455951690673828, -0.034765854477882385, -0.060432299971580505, -0.04105794429779053, 0.006512001156806946, -0.043706014752388, -0.05092586576938629, 0.023198038339614868, 0.02756880223751068, -0.033042341470718384, 0.015856102108955383, 0.008182674646377563, 0.03012464940547943, -0.03707456588745117, -0.01469673216342926, -0.03442901372909546, -0.0204780250787735, 0.014245688915252686, -0.01791292428970337, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65894>
      [
        [0.05954828858375549, -0.018334031105041504, -0.053740084171295166, -0.04106515645980835, 0.04359300434589386, -0.052301377058029175, -0.05622832477092743, -0.011903241276741028, -0.020184949040412903, 0.030262917280197144, 0.016308650374412537, -0.041071027517318726, -0.009465128183364868, 0.043169617652893066, 0.052690088748931885, -0.02101065218448639, -0.02739103138446808, 0.033964574337005615, 0.011630713939666748, -0.012691468000411987, -0.026288464665412903, 0.06245419383049011, -0.06054665148258209, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65895>
      [
        [0.05136667191982269, 0.037590816617012024, -0.04500292241573334, -0.034925028681755066, 0.008359581232070923, -0.011601179838180542, 0.046158358454704285, -0.03811800479888916, -0.03293466567993164, 0.047059565782547, 0.0218227356672287, -0.009044930338859558, 0.05121052265167236, -0.05056823790073395, 0.03798666596412659, 0.03153999149799347, 0.026914402842521667, 0.03440725803375244, -0.005188554525375366, 0.04151977598667145, -0.049881115555763245, 0.03422388434410095, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65896>
      [
        [-0.02544592320919037, -0.03634065389633179, -0.018084004521369934, -0.04243233799934387, 0.04002797603607178, 2.098381519317627e-4, -2.989470958709717e-4, -0.057203203439712524, -0.03128752112388611, 0.038946688175201416, 0.060461074113845825, 0.035974353551864624, 0.003053322434425354, -0.0013038963079452515, -0.013969793915748596, -0.028209075331687927, -0.008393153548240662, 0.061665311455726624, 0.030390232801437378, 0.019174695014953613, 0.024785682559013367, ...],
        ...
      ]
    >
  },
  "normalization_12" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65959>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65960>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_3" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65936>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65937>
      [
        [-0.0366412028670311, -0.03651485964655876, 0.02650594525039196, -0.016402289271354675, -0.025654854252934456, 0.015297504141926765, -0.019247323274612427, 0.012388564646244049, -0.0240774005651474, -0.01869748905301094, -0.005119819659739733, 0.02205471508204937, 0.012353327125310898, 0.03934800624847412, 0.03082224726676941, 0.029741965234279633, -0.010925635695457458, 0.03131837025284767, 0.03803667798638344, 0.01707005873322487, 0.029323609545826912, ...],
        ...
      ]
    >
  },
  "dense_18" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65921>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65922>
      [
        [-0.022697916254401207, -0.01417359709739685, -0.03336319699883461, 0.015115143731236458, 0.015952371060848236, -0.01764185167849064, -0.021568890661001205, -0.01160652469843626, 0.007532644551247358, 0.013523111119866371, 0.018907152116298676, -0.023324472829699516, -0.025158587843179703, 0.036196835339069366, 0.02822321653366089, 0.0060785748064517975, -0.03328672796487808, 0.020602766424417496, -0.03298238664865494, -0.030606817454099655, ...],
        ...
      ]
    >
  },
  "dense_5" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65940>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65941>
      [
        [0.025756023824214935, -0.03596629574894905, -0.02284686639904976, 0.019689587876200676, 0.023602772504091263, 0.029920782893896103, -0.03038092516362667, -0.010648720897734165, -0.01590622030198574, 0.011320646852254868, 0.0022809687070548534, -0.02498069405555725, 0.022690394893288612, -0.03188413381576538, 0.03524188697338104, -0.01881878823041916, -0.03762465715408325, 0.03225862607359886, 0.02837536297738552, ...],
        ...
      ]
    >
  },
  "dense_11" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65907>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65908>
      [
        [-0.0037141256034374237, 0.034073393791913986, 0.013978814706206322, 0.0030279310885816813, -0.010822675190865993, -0.009056679904460907, 0.007703478913754225, 0.02177872322499752, -0.02680893801152706, 0.010488017462193966, 0.028833188116550446, -0.03287756070494652, -0.03475680947303772, 0.008495103567838669, 0.007366380654275417, 0.017278751358389854, -0.007913537323474884, -0.015227839350700378, ...],
        ...
      ]
    >
  },
  "normalization_18" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65971>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65972>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_6" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65942>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65943>
      [
        [0.02989180199801922, 0.030130190774798393, -0.022942213341593742, 0.03949263319373131, -0.030400875955820084, -0.019850393757224083, 0.030135562643408775, -0.031825728714466095, -0.03247269243001938, 0.026158630847930908, -0.0020208009518682957, 0.0016321230214089155, -0.009290647692978382, -0.004441353492438793, -0.004950558766722679, 0.023847494274377823, ...],
        ...
      ]
    >
  },
  "normalization_15" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65965>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65966>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "normalization_23" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65983>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65984>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "dense_10" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65905>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65906>
      [
        [-0.0249734278768301, 0.0143804419785738, 0.009133638814091682, -0.013027703389525414, 0.02458631433546543, 0.026299260556697845, -1.9839141168631613e-4, -0.011157785542309284, -0.0375479981303215, -0.033345937728881836, 0.004981668666005135, 0.03158210217952728, -0.02271103486418724, ...],
        ...
      ]
    >
  },
  "dense_13" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65911>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65912>
      [
        [-0.013052083551883698, -0.03876694291830063, -0.03504530340433121, 0.022804325446486473, -0.03920937702059746, -0.007452443242073059, 0.013561619445681572, -0.03840300440788269, 0.023222096264362335, -0.02473028004169464, 0.017051653936505318, 0.01958180032670498, ...],
        ...
      ]
    >
  },
  "dense_21" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65929>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65930>
      [
        [-0.014589134603738785, 0.024606434628367424, 0.03452145308256149, -0.020177079364657402, -0.030781080946326256, -0.0051908413879573345, -0.022325005382299423, -0.02352965995669365, 0.021398339420557022, 0.007469284813851118, -0.031778354197740555, ...],
        ...
      ]
    >
  },
  "dense_8" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65946>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65947>
      [
        [0.03523549810051918, 0.022907031700015068, 0.008606254123151302, 0.033233392983675, -0.0037005168851464987, -0.016019266098737717, 0.03216709941625595, -0.03141503781080246, -0.0033981846645474434, -0.019669579342007637, ...],
        ...
      ]
    >
  },
  "dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65901>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65902>
      [
        [-0.033898260444402695, 0.03424730896949768, -0.003590261796489358, -0.0370299257338047, -0.03892354667186737, -0.012673800811171532, -0.015667568892240524, -0.027449103072285652, 0.02314266748726368, ...],
        ...
      ]
    >
  },
  "dense_2" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65925>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65926>
      [
        [-0.021719539538025856, -0.012648873962461948, 0.018876560032367706, 0.024806635454297066, 0.019822290167212486, 0.01990167237818241, 0.017527807503938675, 0.00470435805618763, ...],
        ...
      ]
    >
  },
  "causal_attention_3" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65873>
      [
        [0.03307117521762848, 0.052388325333595276, -0.052469655871391296, 0.04993458092212677, -0.008502721786499023, 0.04863150417804718, -0.04397425055503845, 0.026126205921173096, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65874>
      [
        [3.547370433807373e-4, 0.012353941798210144, 0.020879730582237244, 2.934783697128296e-4, -0.03231169283390045, 0.04469521343708038, -0.01846630871295929, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65875>
      [
        [-0.00862903892993927, 0.047613129019737244, 0.01889754831790924, -0.043374285101890564, -0.0512593537569046, 0.01298445463180542, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65876>
      [
        [0.0029682815074920654, -0.031321972608566284, -0.003879234194755554, 0.05914776027202606, -0.035743147134780884, ...],
        ...
      ]
    >
  },
  "normalization_21" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65979>
      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65980>
      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]
    >
  },
  "causal_attention_5" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65881>
      [
        [0.027845636010169983, 0.04923565685749054, 0.013799235224723816, -0.004870876669883728, 0.05626256763935089, 0.045031070709228516, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65882>
      [
        [0.034384652972221375, -0.044549256563186646, 3.282874822616577e-4, 0.01728612184524536, -0.03978864848613739, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65883>
      [
        [-0.008495509624481201, -0.025550737977027893, -0.012447208166122437, -0.015201836824417114, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65884>
      [
        [-0.006098702549934387, -0.058861151337623596, -0.05091048777103424, ...],
        ...
      ]
    >
  },
  "dense_24" => %{
    "kernel" => #Nx.Tensor<
      f32[768][50257]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65935>
      [
        [0.0011196397244930267, -0.006019069813191891, -0.0032777772285044193, 0.0026513785123825073, -0.010327205993235111, ...],
        ...
      ]
    >
  },
  "dense_14" => %{
    "bias" => #Nx.Tensor<
      f32[3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65913>
      [0.0, 0.0, 0.0, 0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[768][3072]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65914>
      [
        [-0.002042062347754836, 0.007567929103970528, -0.02847537398338318, ...],
        ...
      ]
    >
  },
  "causal_attention_4" => %{
    "out_proj" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65877>
      [
        [-0.02169060707092285, 0.025045320391654968, 0.03465403616428375, ...],
        ...
      ]
    >,
    "w_key" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65878>
      [
        [0.0044701844453811646, 0.012541219592094421, ...],
        ...
      ]
    >,
    "w_query" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65879>
      [
        [0.02636946737766266, ...],
        ...
      ]
    >,
    "w_value" => #Nx.Tensor<
      f32[768][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65880>
      [
        ...
      ]
    >
  },
  "normalization_10" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65955>
      [1.0, 1.0, ...]
    >,
    "shift" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65956>
      [0.0, ...]
    >
  },
  "dense_7" => %{
    "bias" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65944>
      [0.0, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[3072][768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65945>
      [
        ...
      ]
    >
  },
  "normalization_22" => %{
    "scale" => #Nx.Tensor<
      f32[768]
      EXLA.Backend<host:0, 0.1366667826.1786118168.65981>
      [...]
    >,
    ...
  },
  "causal_attention_2" => %{...},
  ...
}
```

```elixir
logit = predict_fn.(params, batch)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][4][50257]
  EXLA.Backend<host:0, 0.1366667826.1786118168.66003>
  [
    [
      [0.2803703248500824, -0.07315270602703094, 0.3577398955821991, -0.07260004431009293, 0.1903536319732666, 0.07483126223087311, 0.2513326406478882, -0.11101536452770233, 0.17445151507854462, 0.10261347889900208, -0.12078019231557846, -0.049824073910713196, 0.18545812368392944, 0.013964533805847168, -0.13906230032444, 0.0896649956703186, 0.03434973955154419, -0.24493391811847687, 0.4062414765357971, 0.0967893898487091, 0.44506508111953735, 0.3618185222148895, 0.4185892939567566, -0.1302228718996048, 0.3377799987792969, 1.1286139488220215e-4, -0.1995621919631958, 0.10705672204494476, -0.06998956948518753, 0.43495500087738037, 0.06465739756822586, -0.044191308319568634, 0.042275916785001755, 0.34331750869750977, -0.015286875888705254, 0.3468380570411682, 0.007815178483724594, -0.2892349660396576, 0.10641936957836151, 0.15051062405109406, 0.27116501331329346, -0.07599429786205292, 0.16037455201148987, 0.023972883820533752, -0.22748763859272003, -0.011132504791021347, -0.06328065693378448, -0.09093485027551651, -0.1781986951828003, 0.19906549155712128, ...],
      ...
    ],
    ...
  ]
>
```

The forward method takes a batch of input token indices, computes their embeddings, applies the positional embeddings, passes the sequence through the transformer
blocks, normalizes the final output, and then computes the logits, representing the next
token’s unnormalized probabilities.

Weight tying reduces the overall memory footprint and computational complexity
of the model. However, in my experience, using separate token embedding and out-
put layers results in better training and model performance; hence, we use separate
layers in our GPTModel implementation.

## 4.7 Generating text

The step-by-step process by which an LLM generates text, one
token at a time. Starting with an initial input context (“Hello, I am”), the
model predicts a subsequent token during each iteration, appending it to the
input context for the next round of prediction. The first iteration
adds “a,” the second “model,” and the third “ready,” progressively building
the sentence.

In each step, the model
outputs a matrix with vectors representing potential next tokens. The vector corresponding to the next token is extracted and converted into a probability distribution via
the softmax function. Within the vector containing the resulting probability scores, the
index of the highest value is located, which translates to the token ID. This token ID is
then decoded back into text, producing the next token in the sequence. Finally, this
token is appended to the previous inputs, forming a new input sequence for the subsequent iteration. This step-by-step process enables the model to generate text sequentially, building coherent phrases and sentences from the initial input context.

The process begins by encoding the input text into token IDs, which are then fed into the
GPT model. The outputs of the model are then converted back into text and appended to the original input text.

```elixir
# Compute the next token id to be concatenated to the input.
predicted_new_token = 
  logit[[0..1, -1]] # Get last element of the vector.
  |> Axon.Layers.softmax(axis: -1)
  |> Nx.argmax(axis: -1)
  |> Nx.reshape({2, 1})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  s64[2][1]
  EXLA.Backend<host:0, 0.1366667826.1786118168.66023>
  [
    [26145],
    [20618]
  ]
>
```

```elixir
token_ids_tensor = Nx.concatenate([batch, predicted_new_token], axis: 1)
token_ids_list = Nx.to_list(token_ids_tensor)
```

<!-- livebook:{"output":true} -->

```
[[6109, 3629, 6100, 345, 26145], [6109, 1110, 6622, 257, 20618]]
```

```elixir
for token_ids <- token_ids_list do
  {:ok, text} = Tiktoken.decode("gpt-3.5-turbo", token_ids)
  text
end
```

<!-- livebook:{"output":true} -->

```
["Web oftenpite,\n%',\n", "WebCom seconds    535"]
```
